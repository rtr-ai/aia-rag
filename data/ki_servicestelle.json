{
  "id": "1",
  "date_created": 1733416387074,
  "last_modified": 1733416387074,
  "chunks": [
    {
      "id": "4a4e5d76-5052-4da8-b716-fbb0c5316035",
      "title": "KI-Servicestelle: FAQ - Was macht die KI-Servicestelle der RTR?",
      "content": "# Was macht die KI-Servicestelle der RTR?\n\nDie KI-Servicestelle bei der RTR, gilt als Ansprechpartner und Informationshub und steht dem österreichischen KI-Ökosystem bei der Vorbereitung auf den europäischen AI Act zur Verfügung. Folgende Aufgaben sind dabei im Mittelpunkt:\n\n-   Ein niedrigschwellig zugänglicher Service zu Information und Unterstützung über regulatorische Rahmenbedingungen beim Einsatz und der Entwicklung von KI;\n-   Die Förderung des Wissensaufbaus und des Wissensaustauschs zu KI, auch durch Fachveranstaltungen und Studien;\n-   Unterstützung für Medienunternehmen, um sie beim verantwortungsvollen und kontrollierten Einsatz von KI-Systemen zu begleiten;\n-   Die Betreuung des hochkarätig besetzten KI-Beirats, der die KI-Servicestelle und die Bundesregierung zu aktuellen Entwicklungen bei KI berät.\n\nWir empfehlen Ihnen, das Informationsangebot der KI-Servicestelle bei der RTR in Anspruch zu nehmen.",
      "keywords": [],
      "availableKeywords": [],
      "negativeKeywords": [],
      "relevantChunksIds": [],
      "parameters": []
    },
    {
      "id": "f63dfa65-68ef-47e1-a339-e0adfc260fb0",
      "title": "KI-Servicestelle: FAQ - Warum wird KI reguliert?",
      "content": "# Warum wird KI reguliert?\n\nKünstliche Intelligenz entwickelt sich rasch weiter und betrifft auch sensible Bereiche wie Gesundheit, Sicherheit und Grundrechte. Mit dem AI Act („Gesetz über Künstliche Intelligenz“) führt die EU umfassende gesetzliche Regelungen ein, um die Risiken in diesen Bereichen zu minimieren. Darüber hinaus soll der AI Act die Rechtsstaatlichkeit, die Demokratie und die Umwelt schützen.\n\nWeiteres Ziel des AI Act ist es, einheitliche Regelungen für Betroffene in der gesamten EU zu schaffen. Dabei sollen auch Rechtsunsicherheiten aus dem Weg geräumt werden, um Unternehmen zu motivieren, sich durch künstliche Intelligenz an Fortschritt und Innovation zu beteiligen.",
      "keywords": [],
      "availableKeywords": [],
      "negativeKeywords": [],
      "relevantChunksIds": [],
      "parameters": []
    },
    {
      "id": "bdaff5ed-d37e-4686-a1d9-f4b59cfb83ec",
      "title": "KI-Servicestelle: FAQ - Für wen gilt die KI-Regulierung?",
      "content": "# Für wen gilt die KI-Regulierung?\n\nDer AI Act wurde als Verordnung erlassen und ist damit direkt in den Mitliedstaaten anwendbar und reguliert sowohl den privaten als auch den öffentlichen Sektor. Betroffen sind Unternehmen in und außerhalb der EU, wenn sie KI-Systeme oder KI-Modelle in der Union in Verkehr bringen oder Menschen in der EU davon betroffen sind. Das reicht von reinen Anbietern von Tools, die auf künstliche Intelligenz zurückgreifen, bis zu Entwicklern von KI-Systemen mit hohem Risiko.\n\nMehr zu den [Akteuren](https://www.rtr.at/rtr/service/ki-servicestelle/ai-act/akteure.de.html \"Link zu den Akteuren im AI Act\") im AI Act",
      "keywords": [],
      "availableKeywords": [],
      "negativeKeywords": [],
      "relevantChunksIds": [],
      "parameters": []
    },
    {
      "id": "81c0b657-fac0-4b76-a86e-bfff22f75a63",
      "title": "KI-Servicestelle: FAQ - Ab wann gilt der AI Act?",
      "content": "# Ab wann gilt der AI Act?\n\nNach seiner Annahme durch das Europäische Parlament und den Rat wird der AI Act am zwanzigsten Tag nach seiner Veröffentlichung im Amtsblatt in Kraft treten. Es wird dann 24 Monate nach dem Inkrafttreten in vollem Umfang anwendbar sein, wobei das folgende abgestufte Verfahren gilt:\n\n-   6 Monate nach Inkrafttreten: Verbotene Praktiken dürfen nicht mehr angewandt werden;\n-   12 Monate: Die Verpflichtungen in Bezug auf “General Purpose AI“ werden anwendbar;\n-   24 Monate: Alle weiteren Vorschriften des AI Acts werden anwendbar, einschließlich der Verpflichtungen für Hochrisikosysteme, die in Anhang III (Liste der Anwendungsfälle mit hohem Risiko) festgelegt sind. Jene gemäß Anhang II sind zu diesem Zeitpunkt noch ausgenommen;\n-   36 Monate: Die Verpflichtungen für Hochrisikosysteme gemäß Anhang II (Liste der Harmonisierungsrechtsvorschriften der Union) werden anwendbar.\n\nMehr zum [zeitlichen Rahmen des AI Act](https://www.rtr.at/rtr/service/ki-servicestelle/ai-act/Zeitplan.de.html \"Link zum Zeitplan des AI Act\")",
      "keywords": [],
      "availableKeywords": [],
      "negativeKeywords": [],
      "relevantChunksIds": [],
      "parameters": []
    },
    {
      "id": "7f48a1de-637b-45ca-a910-f7a73ad90904",
      "title": "KI-Servicestelle: FAQ - In welche vier Risikostufen werden KI-Systeme eingeteilt?",
      "content": "# In welche vier Risikostufen werden KI-Systeme eingeteilt?\n\n-   Inakzeptables Risiko\n-   Hohes Risiko\n-   Begrenztes Risiko\n-   Minimales oder kein Risiko\n\nMehr zu den [Risikostufen von KI-Systemen](https://www.rtr.at/rtr/service/ki-servicestelle/ai-act/risikostufen_ki-systeme.de.html \"Link zu den Risikostufen von KI-Systemen\")",
      "keywords": [],
      "availableKeywords": [],
      "negativeKeywords": [],
      "relevantChunksIds": [],
      "parameters": []
    },
    {
      "id": "c778be50-e474-4992-ad36-c564a8bdad2c",
      "title": "KI-Servicestelle: FAQ - Wie bestimme ich das Risiko eines KI-Systems?",
      "content": "# Wie bestimme ich das Risiko eines KI-Systems?\n\nDie Einstufung hängt vom Verwendungszweck und den Anwendungsmodalitäten des KI-Systems ab. Im AI Act werden die verbotenen Praktiken und Anwendungsfälle von Hochrisiko-KI-Systeme (Anhang I und III) abschießend angeführt. Die EU-Kommission ist dazu ermächtigt, die Liste der Hochrisiko-KI-Systeme zu erweitern. Sie trägt dabei den Markt- und technologische Entwicklungen Rechnung und achtet auf Kohärenz. Immer als hochriskant gelten KI-Systeme, welche Profiling durchführen, das heißt das Erstellen von Persönlichkeitsprofilen natürlicher Personen.",
      "keywords": [],
      "availableKeywords": [],
      "negativeKeywords": [],
      "relevantChunksIds": [],
      "parameters": []
    },
    {
      "id": "be2475ee-b7ff-4afe-9eeb-97028800cf97",
      "title": "KI-Servicestelle: FAQ - Welche Verpflichtungen treffen Anbieter von Hochrisiko-KI-Systemen?",
      "content": "# Welche Verpflichtungen treffen Anbieter von Hochrisiko-KI-Systemen?\n\nDie Person, Behörde, Einrichtung oder sonstige Stelle, die ein Hochrisiko-KI-System entwickelt oder entwickeln lässt und diese auch unter ihrem eigenen Namen oder ihrer eigenen Marke in Verkehr bringt oder in Betrieb nimmt, treffen die umfangreichsten Verpflichtungen. Sie haben sicherzustellen, dass die an Hochrisiko-KI-Systeme gestellten Anforderungen erfüllt sind. Zu den Verpflichtungen zählen unter anderem:\n\n-   Einrichtung von Risikomanagementsystemen;\n-   Erfüllen der Anforderungen an die Data Governance;\n-   Dokumentationspflichten in technischer Hinsicht;\n-   Aufzeichnungspflichten;\n-   Transparenzpflichten in Bezug auf Anwender:innen;\n-   Ausreichende Implementierung menschlicher Überwachungstools;\n-   Sicherstellung der Genauigkeit, Robustheit und Cybersicherheit.\n\nMehr über die [Anbieterverpflichtungen](https://www.rtr.at/rtr/service/ki-servicestelle/ai-act/Anbieterverpflichtungen.de.html \"Link zu den Anbieterverpflichtungen\")",
      "keywords": [],
      "availableKeywords": [],
      "negativeKeywords": [],
      "relevantChunksIds": [],
      "parameters": []
    },
    {
      "id": "c7be8215-ad70-4bd9-a020-4e5efeff7cca",
      "title": "KI-Servicestelle: FAQ - Wie wird der AI Act durchgesetzt?",
      "content": "# Wie wird der AI Act durchgesetzt?\n\nJeder Mitgliedstaat errichtet oder benennt mindestens eine notifizierende Behörde und mindestens eine Marktüberwachungsbehörde für die Zwecke dieser Verordnung als zuständige nationale Behörden. Diese nationalen zuständigen Behörden üben ihre Befugnisse unabhängig, unparteiisch und unvoreingenommen aus.\n\nDarüber hinaus wurde durch die Kommission ein neues Europäisches [AI Office](https://digital-strategy.ec.europa.eu/en/policies/ai-office \"Link zum AI Office\") innerhalb der Kommission eingerichtet, das General Purpose AI-Modelle überwachen soll.\n\nFerner wird es auch ein AI Board, ein Scientific Panel und ein Advisory Forum geben, denen beratende und unterstützende Funktion zukommen soll.\n\nMehr zu den [Behörden und Einrichtungen auf EU-Ebene](https://www.rtr.at/rtr/service/ki-servicestelle/ai-act/Behoerden_Einrichtungen.de.html \"Link zu den Behörden und Einrichtungen\")",
      "keywords": [],
      "availableKeywords": [],
      "negativeKeywords": [],
      "relevantChunksIds": [],
      "parameters": []
    },
    {
      "id": "e3368f8d-8bb5-46c1-873f-4af231bce512",
      "title": "KI-Servicestelle: FAQ - Welche Sanktionen sind bei Verstößen vorgesehen?",
      "content": "# Welche Sanktionen sind bei Verstößen vorgesehen?\n\nFür den Fall, dass KI-Systeme in Verkehr gebracht oder in Betrieb genommen werden, die den Anforderungen der Verordnung nicht genügen, müssen die Mitgliedstaaten wirksame, verhältnismäßige und abschreckende Sanktionen, einschließlich Geldbußen, festlegen und diese der Kommission mitteilen.\n\nDafür werden in der Verordnung bestimmte Schwellenwerte festgelegt:\n\n-   bis zu 35 Mio. EUR oder 7 Prozent des gesamten weltweiten Vorjahresumsatzes (je nachdem, welcher Wert höher ist) bei Verstößen durch verbotene Praktiken oder Verletzungen von Datenanforderungen;\n-   bis zu 15 Mio. EUR oder 3 Prozent des gesamten weltweiten Vorjahresumsatzes bei Verstößen gegen andere Anforderungen oder Verpflichtungen aus der Verordnung, auch bei Verletzungen der Vorschriften für General Purpose AI Models;\n-   bis zu 7,5 Mio. EUR oder 1,5 Prozent des gesamten weltweiten Vorjahresumsatzes bei falschen, unvollständigen oder irreführenden Angaben in angeforderten Auskünften an benannte Stellen und zuständige nationale Behörden;\n-   Bei allen Kategorien von Verstößen wäre der Schwellenwert jeweils der niedrigere der beiden Beträge für KMU und der höhere für andere Unternehmen.\n\nZur Harmonisierung der nationalen Vorschriften und Verfahren bei der Festsetzung von Geldbußen wird die Kommission anhand von Empfehlungen des Ausschusses Leitlinien ausarbeiten.\n\nDa die Organe, Einrichtungen und sonstigen Stellen der EU mit gutem Beispiel vorangehen sollten, werden auch sie den Vorschriften und möglichen Sanktionen unterworfen. Der bzw. die Europäische Datenschutzbeauftragte wird befugt sein, Geldbußen gegen sie zu verhängen.",
      "keywords": [],
      "availableKeywords": [],
      "negativeKeywords": [],
      "relevantChunksIds": [],
      "parameters": []
    },
    {
      "id": "0ca3b298-b05b-490f-aded-9c6476a13580",
      "title": "KI-Servicestelle: FAQ - Ich bin von einem Verstoß gegen die Vorschriften betroffen. Was kann ich tun?",
      "content": "# Ich bin von einem Verstoß gegen die Vorschriften betroffen. Was kann ich tun?\n\nDer AI Act sieht das Recht von natürlichen und juristischen Personen vor, bei einer nationalen Behörde Beschwerde einzulegen. Auf dieser Grundlage können nationale Behörden eine Marktüberwachung nach den Verfahren der Marktüberwachungsverordnungen einleiten.\n\nDarüber hinaus soll die [vorgeschlagene KI-Haftungsrichtlinie](https://eur-lex.europa.eu/legal-content/DE/TXT/?uri=CELEX%3A52022PC0496 \"Link zum Vorschlag über eine KI-Haftungsrichtlinie\") den Personen, die Entschädigungen für durch Hochrisiko-KI-Systeme verursachte Schäden beantragen wollen, wirksame Mittel an die Hand geben, um möglicherweise haftende Personen zu ermitteln und einschlägige Beweise für eine Schadensersatzklage zu sichern. Dazu sieht die vorgeschlagene Richtlinie die Offenlegung von Nachweisen über bestimmte Hochrisiko-KI-Systeme vor, bei denen der Verdacht besteht, dass sie Schäden verursacht haben.\n\nÜberdies wird die [derzeit in Überarbeitung befindliche Produkthaftungsrichtlinie](https://eur-lex.europa.eu/legal-content/DE/TXT/?uri=CELEX:52022PC0495 \"Link zur Produkthaftungsrichtlinie\") dafür sorgen, dass Personen, die in der Union durch ein fehlerhaftes Produkt getötet oder verletzt werden oder Sachschäden erleiden, eine Entschädigung erhalten. Es wird klargestellt, dass KI-Systeme und Produkte, die ihrerseits KI-Systeme enthalten, ebenfalls unter die bestehenden Vorschriften fallen.",
      "keywords": [],
      "availableKeywords": [],
      "negativeKeywords": [],
      "relevantChunksIds": [],
      "parameters": []
    },
    {
      "id": "de47fa95-324c-4d75-89c4-ddb875707ef3",
      "title": "KI-Servicestelle: FAQ - Brauche ich einen „KI-Beauftragten“ im Unternehmen?",
      "content": "# Brauche ich einen „KI-Beauftragten“ im Unternehmen?\n\nDer AI Act verpflichtet nicht dazu, einen KI-Beauftragten zu bestellen oder eine KI-Rechtsvertretung zu beauftragen. Er verpflichtet aber unabhängig von der Risikostufe Anbieter und Betreiber von KI-Systemen dazu, Maßnahmen zu ergreifen, dass ihr Personal und andere Personen, die in ihrem Auftrag mit dem Betrieb und der Nutzung von KI-Systemen befasst werden, ausreichende Kompetenzen darin haben.",
      "keywords": [],
      "availableKeywords": [],
      "negativeKeywords": [],
      "relevantChunksIds": [],
      "parameters": []
    },
    {
      "id": "cf7337ff-5e03-49da-beec-ed1fafaf88b7",
      "title": "KI-Servicestelle: FAQ - Was versteht man unter maschinellem Lernen (Machine Learning)?",
      "content": "# Was versteht man unter maschinellem Lernen (Machine Learning)?\n\nVon maschinellem Lernen (Machine Learning) spricht man dann, wenn Algorithmen die Fähigkeit besitzen, ihre Leistung bei der Lösung von Problemen mit immer mehr Erfahrung oder Daten zu verbessern. Die Wurzeln des maschinellen Lernens liegen in der Statistik. Was den Prozess des Lernens betrifft, lassen sich unterschiedliche Formen von maschinellem Lernen unterscheiden.\n\nÜberwachtes Lernen (Supervised Learning) benötigt für das Training einen mit sogenannten Labeln gekennzeichneten Datensatz. Eine Anwendung ist die Krebsdiagnostik, wo mittels maschinellem Lernen Röntgenbilder ausgewertet werden. Vereinfacht gesagt besteht hier der Trainingsdatensatz aus Röntgenbildern, die zuvor von medizinischem Fachpersonal mit den Labeln \"Krebs\" bzw. \"Kein Krebs\" versehen wurden. Beim Training erkennt das KI-Modell dann durch Mustererkennung in den Bilddaten, welche Merkmale typisch für bösartige und welche für gutartige Gewebe sind. Dieses gelernte Wissen kann das KI-Modell dann auf neue Röntgenbilder anwenden. Überwachtes Lernen kommt also für solche Aufgaben in Frage, wo es eine korrekte Antwort bzw. ein Label gibt und die Aufgabe des Algorithmus für maschinelles Lernen besteht darin, ein Modell zu finden, das dies auf der Grundlage der Eingabedaten vorhersagt.\n\nIm Unterschied dazu kann unüberwachtes Lernen (Unsupervised Learning) für Aufgaben verwendet werden, wo eine Struktur in Eingabedaten erkannt werden soll. So können etwa Cluster von Elementen identifiziert werden, die einander ähnlich sind, sich aber von den Daten in anderen Clustern unterscheiden. Ein Anwendungsbeispiel ist die Anomalieerkennung in Maschinendaten, wo ein Fertigungsunternehmen Ausfälle oder ungewöhnliches Verhalten in seinen Produktionsmaschinen frühzeitig erkennen möchte, um Wartungen rechtzeitig durchzuführen und Produktionsausfälle zu vermeiden. Der Trainingsdatensatz besteht aus verschiedenen Sensordaten der Maschinen, die während des normalen Betriebs gesammelt werden. Dabei werden diese Sensordaten ohne spezifische Labels gesammelt. Durch die Anwendung spezieller Algorithmen lernt das KI-Modell Muster des normalen Maschinenbetriebs und identifiziert Datenpunkte, die stark von diesen Normalwerten abweichen.\n\nVon bestärkendem bzw. verstärkendem Lernen (Reinforcement Learning) spricht man, wenn das KI-Modell durch Interaktionen mit einer Umgebung lernt und Belohnungen oder Strafen basierend auf seinen Aktionen erhält. Dies ist besonders nützlich für Aufgaben, bei denen unmittelbares Feedback verfügbar ist, wie zum Beispiel in Computerspielen oder bei der Robotersteuerung.",
      "keywords": [],
      "availableKeywords": [],
      "negativeKeywords": [],
      "relevantChunksIds": [],
      "parameters": []
    },
    {
      "id": "8ff10fba-b55e-4c99-b089-7971806ebee8",
      "title": "KI-Servicestelle: FAQ - Was versteht man unter Deep Learning und was sind neuronale Netzwerke?",
      "content": "# Was versteht man unter Deep Learning und was sind neuronale Netzwerke?\n\nDeep Learning ist ein spezieller Teilbereich des maschinellen Lernens. Hier sind künstliche neuronale Netzwerke in der Lage, aus riesigen Mengen unstrukturierter Daten zu lernen und komplexe Muster zu erkennen. Das Training stellt hohe Anforderungen an die Rechenleistung.\n\nDie künstlichen neuronalen Netze bestehen aus künstlichen Neuronen, deren Aufbau von biologischen Neuronen inspiriert ist. Die künstlichen Neuronen sind in hierarchischen Schichten angeordnet, die untereinander verbunden sind. Die Architektur beinhaltet eine Eingabeschicht, mehrere versteckte Schichten (hidden layers) und eine Ausgabeschicht. Die zahlreichen Schichten können es schwierig machen, die Entscheidungsfindung des KI-Modells nachzuvollziehen. Von der Verwendung tiefer (mehrschichtiger) neuronaler Netzwerke leitet sich auch die Bezeichnung \"Deep\" Learning ab.\n\nTypische Anwendungsbereiche sind die Spracherkennung bei der automatischen Übersetzung, bei der Umwandlung von gesprochener Sprache in Text oder in Sprachassistenten (z.B. Siri oder Alexa). Weitere Beispiele sind die Vorhersage von Markttrends im Finanzsektor und das autonome Fahren. Deep Fakes sind mittels Deep Learning erstellte oder manipulierte Videos, Audioaufnahmen oder Bilder, die wirklichen Personen, Gegenständen, Orten, Einrichtungen oder Ereignissen ähneln und einer Person fälschlicherweise als echt oder wahrheitsgemäß erscheinen würden. Der Begriff Deep Fake selbst ist eine Kombination aus \"Deep Learning\" und \"Fake\".\n\nDeep Learning ist also eine leistungsstarke und hochentwickelte Technologie mit einem breiten Anwendungsspektrum. Allerdings bringt es auch Herausforderungen in Bezug auf Daten- und Rechenanforderungen sowie die Erklärbarkeit und Nachvollziehbarkeit der Modelle mit sich.",
      "keywords": [],
      "availableKeywords": [],
      "negativeKeywords": [],
      "relevantChunksIds": [],
      "parameters": []
    },
    {
      "id": "73d6d9b2-be6d-4359-8896-2c0277c9026b",
      "title": "KI-Servicestelle: FAQ - Was ist ein „KI-System“?",
      "content": "# Was ist ein „KI-System“?\n\nFür die rechtliche Behandlung von Künstlicher Intelligenz ist die gesetzliche Definition des AI Act von Relevanz. Sie stellt das Einfallstor zum Anwendungsbereich der Verordnung dar. Diese Definition lautet gemäß Art. 3 Ziffer 1 AIA wie folgt:\n\n„KI-System“ ein maschinengestütztes System, das für einen in unterschiedlichem Grade autonomen Betrieb ausgelegt ist und das nach seiner Betriebsaufnahme anpassungsfähig sein kann und das aus den erhaltenen Eingaben für explizite oder implizite Ziele ableitet, wie Ausgaben wie etwa Vorhersagen, Inhalte, Empfehlungen oder Entscheidungen erstellt werden, die physische oder virtuelle Umgebungen beeinflussen können.\n\nKI-Systeme, sind Computersysteme, die in der Lage sind, Aufgaben auszuführen, die normalerweise menschliche Intelligenz erfordern. Diese Systeme können Informationen verarbeiten, Muster erkennen, Schlussfolgerungen ziehen und sogar lernen, um ihre Leistung zu verbessern. KI-Systeme basieren auf Algorithmen und Daten, die es ihnen ermöglichen, komplexe Probleme zu lösen und Entscheidungen zu treffen. Beispiele für KI-Systeme sind Chatbots, Gesichtserkennungstechnologien, selbstfahrende Autos und personalisierte Empfehlungssysteme. Die Intention des Unionsgesetzgebers ist nicht, einfachere traditionelle Softwareanwendungen oder Programmieransätze zu erfassen, welche auf ausschließlich von natürlichen Personen definierten Regeln zur automatischen Ausführung von Vorgängen beruhen.",
      "keywords": [],
      "availableKeywords": [],
      "negativeKeywords": [],
      "relevantChunksIds": [],
      "parameters": []
    },
    {
      "id": "780d67fe-08bc-4789-a2f1-df4d30ef1de3",
      "title": "KI-Servicestelle: FAQ - Was ist generative KI?",
      "content": "# Was ist generative KI?\n\nGenerative KI sind KI-Systeme, die es ermöglichen, basierend auf Nutzereingaben neue entsprechende Informationen, einschließlich Text, Audio und Bilder, zu erzeugen. Durch den weiten Anwendungsbereich werden derartige KI-Systeme in den verschiedensten Kontexten verwendet, wie z. B. für Übersetzungen, bei der Beantwortung von Fragen und bei Chatbots.",
      "keywords": [],
      "availableKeywords": [],
      "negativeKeywords": [],
      "relevantChunksIds": [],
      "parameters": []
    },
    {
      "id": "7e5b0065-efed-4c70-933f-0da191a391ef",
      "title": "KI-Servicestelle: FAQ - Was ist ein „Prompt“?",
      "content": "# Was ist ein „Prompt“?\n\nDer englische Begriff „Prompt“ wird in der IT als Anweisung an eine:n Nutzer:in zur Vornahme einer Eingabe bezeichnet. Generative KI funktioniert durch die Eingabe von „Prompts“. Um ein Bild, Text oder Video zu generieren (Output), braucht das KI-System eine Eingabe (Input). Je nach KI-System kann ein Prompt text-, bild- oder audiobasiert sein. Ein textbasierter Prompt kann aus Wörtern, Sonderzeichen und Zahlen bestehen wie z. B.: „_Ein Bild mit 3 Katzen, die auf der Fensterbank sitzen und schlafen._“\n\nDie Bedeutung der Prompts hat schon zur Entwicklung von Prompt-Marktplätzen geführt.",
      "keywords": [],
      "availableKeywords": [],
      "negativeKeywords": [],
      "relevantChunksIds": [],
      "parameters": []
    },
    {
      "id": "8f0aacde-27ab-460f-a731-735f3ea78739",
      "title": "KI-Servicestelle: FAQ - Was ist ein \"RAG\"-System und wie funktioniert es?",
      "content": "# Was ist ein \"RAG\"-System und wie funktioniert es?\n\nDie Abkürzung \"RAG\" steht für Retrieval-Augmented-Generation. Bei RAG-Systemen werden zwei Techniken miteinander kombiniert, und zwar der Informationsabruf (Information Retrieval) und die Generierung von Text (Generation). Dadurch können Large Language Models (LLMs) um eine zusätzliche externe Wissensquelle (z. B. eine Datenbank) erweitert werden, ohne dass das LLM aufwändig neu mit diesen zusätzlichen Daten trainiert werden muss. Die Anfangsbuchstaben RAG stehen für die einzelnen Arbeitsschritte, die ein RAG-System durchläuft, um eine Antwort auf eine Benutzeranfrage zu generieren.\n\nFür den Abruf (Retrieval) relevanter Informationen wird die jeweilige Anfrage mit der externen Wissensquelle abgeglichen. So ruft etwa das System auf die Frage \"Wie ist die Budgetübersicht des letzten Quartals\" die relevanten Dokumente der externen Wissensquelle (Quartalsberichte etc.) auf. Der nächste Schritt ist die Erweiterung (Augmentation) der Benutzeranfrage um die zuvor identifizierten relevanten Dokumente der externen Wissensquelle. Erst in dieser erweiterten Form wird die Anfrage dann an das LLM für die Generierung (Generation) der Antwort übergeben.\n\nRAG-Systeme bieten Vorteile gegenüber reinen LLM-Systemen. So ist es nicht nötig, ein LLM aufwändig neu zu trainieren, wenn die Wissensbasis erweitert werden soll. Die Antworten eines RAG-Systems sind präziser und relevanter. Zudem lassen sich durch die externe Wissensquelle sogenannten \"Halluzinationen\" eingrenzen, die unter anderem dann entstehen, wenn relevante Informationen nicht in der Wissensbasis des LLM-Systems vorhanden sind.\n\nRAG-Systeme ermöglichen es etwa, interne Wissensbestände effizient zu durchsuchen und zu nutzen. Andere Anwendungsbeispiele für RAG-Systeme sind Chatbots im Kundensupport, Produktempfehlungen im Onlinehandel oder das Wissensmanagement in Unternehmen.",
      "keywords": [],
      "availableKeywords": [],
      "negativeKeywords": [],
      "relevantChunksIds": [],
      "parameters": []
    },
    {
      "id": "c961ad84-cbd5-4b03-9ab7-3a7593855c66",
      "title": "KI-Servicestelle: FAQ - Was sind Large Language Models (LLMs)",
      "content": "# Was sind Large Language Models (LLMs)\n\n\"Large Language Models\" sind computerlinguistische Sprachmodelle, die Texte generieren. Dabei wird in einem gegebenen Kontext das jeweils nächste Wort aufgrund einer vorher im Algorithmus definierten Wahrscheinlichkeit ausgewählt. \"Groß\" werden diese Modelle in Bezug auf den Umfang ihrer Trainingsdaten und die Anzahl der Parameter genannt. Überspitzt formuliert wird davon gesprochen, dass diese Modelle mit dem „gesamten Internet“ trainiert werden.\n\nLLMs basieren auf dem sogenannten Transformer Modell, einer besonderen Art des künstlichen neuronalen Netzes. Damit fallen sie in den Bereich des Deep Learning. Die Einsatzgebiete sind vielfältig: das Erstellen von Texten, die Beantwortung von Fragen (Chatbots, virtuelle Assistenten), das Generieren von Code, die Erstellung von Content für Marketing und Websites sowie die Übersetzung zwischen verschiedenen Sprachen, um nur einige Möglichkeiten aufzuzählen. Zu den bekanntesten Beispielen für Large Language Models zählen die GPT-Modellreihe von OpenAI, Meta LLama oder die Mistral-Reihe der Firma Mistral AI.\n\nLLMs können unter Umständen zu den General Purpose AIs zählen. Auf jeden Fall ist zu beachten, dass sie nicht perfekt sind. Auch erfordern sie menschliche Überwachung, da sie manchmal Fehler machen können oder in Fragen der Ethik und Fairness Herausforderungen aufwerfen.",
      "keywords": [],
      "availableKeywords": [],
      "negativeKeywords": [],
      "relevantChunksIds": [],
      "parameters": []
    },
    {
      "id": "b2735701-dd85-4e80-a648-baff0e065612",
      "title": "KI-Servicestelle: FAQ - Ist für das Trainieren von KI-Modellen stets eine große Menge an Daten notwendig?",
      "content": "# Ist für das Trainieren von KI-Modellen stets eine große Menge an Daten notwendig?\n\nDie benötigte Datenmenge für das Trainieren eines KI-Modells kann stark variieren und hängt von mehreren Faktoren ab. Es ist schwer, allgemeine Zahlen zu geben, da dies stark vom Anwendungsfall, der Komplexität des Modells und den spezifischen Anforderungen des Projekts abhängt. Dennoch können einige grobe Richtwerte und Beispiele hilfreich sein, um ein Gefühl dafür zu bekommen.\n\nEine Faustregel besagt, dass man mindestens 10 bis 100 Mal mehr Trainingsdatensätze als Modellparameter benötigt, um ein gut generalisierendes Modell zu trainieren. Für eine einfache Aufgabe wie die E-Mail-Spam-Filterung, wo eine Klassifikation mit nur wenigen Klassen stattfindet, können einige hundert bis tausend E-Mails für das Training des Modells genügen.\n\nEin Beispiel für eine moderate Aufgabe ist die Klassifikation von handgeschriebenen Ziffern mit dem MNIST-Datensatz. Der Trainingsdatensatz besteht aus 60.000 Bildern von handgeschriebenen Ziffern (0-9), dazu kommt noch ein Testdatensatz mit 10.000 Bildern.\n\nKomplexe Aufgaben können Datensätze in der Größe von Hunderttausenden bis Millionen an Trainingsdaten erfordern. Ein Beispiel dafür ist die Klassifikation von Objekten in hochauflösenden Bildern mittels Deep Learning und neuronalen Netzen. Ein konkretes Anwendungsbeispiel hierfür ist die Erkennung und Diagnose von Krankheiten auf medizinischen Bildern wie Röntgenaufnahmen, CT-Scans und MRT-Bildern.\n\nErheblich mehr Trainingsdaten werden von Large Language Models (LLMs) benötigt. Das von Meta als Open Source veröffentlichte LLama-3-Modell wurde mit 15T Token Text trainiert, das sind 15 Billionen Token (T steht hier für das englische „Trillion“, also 1.000.000.000.000).\n\nBei der Entwicklung und dem Testen von autonom fahrenden Autos schließlich werden Petabytes an Daten ausgewertet, wie z. B. Tesla oder NVIDIA bekannt gegeben haben (1 Petabyte (PB) entspricht 1.000.000 Gigabyte (GB)).\n\nMan sieht also, dass sich diese Frage nicht generell mit „Ja“ oder „Nein“ beantworten lässt und stehts vom konkreten Anwendungsfall anhängig ist.",
      "keywords": [],
      "availableKeywords": [],
      "negativeKeywords": [],
      "relevantChunksIds": [],
      "parameters": []
    },
    {
      "id": "aa88e918-3fa9-4093-85a6-8dea72a863e7",
      "title": "KI-Servicestelle: FAQ - Was bedeutet es, wenn ein KI-System „halluziniert“?",
      "content": "# Was bedeutet es, wenn ein KI-System „halluziniert“?\n\nGeneriert ein KI-Modell Informationen, die nicht auf Trainingsdaten oder realen Fakten basieren, dann spricht man davon, dass es „halluziniert“. Solche Halluzinationen kennt man besonders von Large Language Models (LLMs). Sie können wie echte, plausible Antworten erscheinen, sind aber in Wirklichkeit inkorrekt oder unzuverlässig. Dabei lassen sich abhängig vom Kontext der Anfrage unterschiedliche Formen von Halluzinationen unterscheiden.\n\nJe nachdem, ob die Bezugsgröße Daten sind, die dem KI-System zur Verfügung gestellt worden sind, oder reales, überprüfbares Wissen ist, spricht man im ersten Fall von Treue oder aber im zweiten Fall von Faktizität. Halluzinationen können grundsätzlich aus verschiedenen Gründen auftreten. Wenn die Trainingsdaten unvollständig, fehlerhaft oder verzerrt sind, kann das KI-Modell falsche Schlüsse ziehen.\n\nGenerative KI-Modelle, die aus Wahrscheinlichkeiten Vorhersagen machen, können halluzinieren, wenn sie versuchen, logische oder zusammenhängende Antworten zu geben. Die wahrscheinlichste Antwort muss nicht immer korrekt sein.\n\nWie lässt sich diesem Problem begegnen? Faktische Halluzinationen lassen sich durch Retrieval-Augmented-Generation (RAG) eingrenzen. Dabei wird eine zusätzliche externe Wissensquelle (z. B. eine Datenbank) hinzugefügt, aus der relevante Dokumente oder Informationen auf der Basis der jeweiligen Benutzeranfrage identifiziert und extrahiert werden. Diese Retrieval (Abruf-) Komponente ist die Basis für die nachfolgende Generation (Erzeugungs-) Komponente des RAG-Systems. Weitere Strategien sind verbesserte Trainingsdaten und die Entwicklung von Mechanismen, um generierte Informationen durch externe Quellen zu validieren und zu verifizieren.\n\nNicht zuletzt sind Bewusstseinsbildung und Schulung der Benutzer:innen wichtig. Es ist wichtig, die Antworten eines KI-Systems kritisch zu hinterfragen und, wenn möglich, mit verlässlichen Quellen zu validieren. Dies gilt insbesondere bei wichtigen oder sensiblen Informationen.",
      "keywords": [],
      "availableKeywords": [],
      "negativeKeywords": [],
      "relevantChunksIds": [],
      "parameters": []
    },
    {
      "id": "81a9f3e6-f4ca-4e67-a8ae-771d3ffe3b01",
      "title": "KI-Servicestelle: FAQ - Müssen Inhalte (Texte oder Bilder) gekennzeichnet werden, die mit einer generativen KI erstellt wurden?",
      "content": "# Müssen Inhalte (Texte oder Bilder) gekennzeichnet werden, die mit einer generativen KI erstellt wurden?\n\nWenn Sie als Unternehmen eine am Markt angebotene KI nutzen, d. h. im Sinne des AI Act („AIA“) Betreiber und nicht Anbieter sind, gilt Folgendes: Unberührt von anderen unionsrechtlichen oder nationalen Transparenzpflichten, müssen Betreiber eines KI-Systems, das Bild-, Ton- oder Videoinhalte erzeugt oder manipuliert, die ein Deep-Fake sind, gemäß Art. 50 Abs. 4 AIA offenlegen, dass die Inhalte künstlich erzeugt oder manipuliert wurden.\n\nEin „Deep Fake“ im Sinne des AI Act ist ein durch ein KI erzeugter oder manipulierter Bild-, Ton- oder Videoinhalt, der wirklichen Personen, Gegenständen, Orten, Einrichtungen oder Ereignissen ähnelt und einer Person fälschlicherweise als echt oder wahrheitsgemäß erscheinen würde (siehe Art. 3 Ziffer 60 AIA). Z. B. ein Video einer politisch aktiven Person, welche ein Interview gibt und dies als echt erscheint, jedoch nicht ist.\n\nHandelt es sich bei den erzeugten Bildern um keine „Deep Fakes“, entstehen für Sie keine Transparenzpflichten, d. h., Sie müssen KI-generierte Bilder dann nicht als solche ausweisen. Auch für künstlerische, kreative, satirische oder fiktionale Darstellungen bestehen Ausnahmen von der Transparenzpflicht (Art. 50 Abs. 4 AIA).\n\nBei mit KI erzeugten und manipulierten Texten gelten die Transparenzpflichten nicht, wenn diese von einem Menschen überprüft wurden oder es einen redaktionellen Verantwortlichen gibt. Ist dies nicht der Fall und es sich um Texte von öffentlichem Interesse handelt, sind diese als KI-generiert offenzulegen.\n\nFalls eine Kennzeichnung erforderlich ist, hat diese in klarer und eindeutiger Weise zu erfolgen und muss den geltenden Barrierefreiheitsanforderungen entsprechen (siehe Art. 50 Abs. 5 AIA).\n\nDabei ist auch zu beachten, dass der AI Act schrittweise seine Verpflichtungen entfaltet, er ist zwar bereits am 1. August 2024 in Kraft getreten, jedoch gibt es [Übergangsregelungen](https://www.rtr.at/rtr/service/ki-servicestelle/ai-act/Zeitplan.de.html). Die Bestimmungen zu [Transparenzpflichten](https://www.rtr.at/rtr/service/ki-servicestelle/ai-act/Transparenzpflichten.de.html) sind ab 2. August 2026 verpflichtend anzuwenden.",
      "keywords": [],
      "availableKeywords": [],
      "negativeKeywords": [],
      "relevantChunksIds": [],
      "parameters": []
    },
    {
      "id": "64ec31a3-f49d-403d-8234-753a1abb695d",
      "title": "KI-Servicestelle: FAQ - Kann ich Anbieter sein, wenn ich ein KI-System für den rein internen Gebrauch entwickle?",
      "content": "# Kann ich Anbieter sein, wenn ich ein KI-System für den rein internen Gebrauch entwickle?\n\nEin \"Anbieter\" ist laut Art. 3 Z. 3 AIA eine natürliche oder juristische Person, Behörde, Einrichtung oder sonstige Stelle, die ein KI-System oder ein KI-Modell mit allgemeinem Verwendungszweck entwickelt oder entwickeln lässt und es unter ihrem eigenen Namen oder ihrer Handelsmarke in Verkehr bringt oder das KI-System unter ihrem eigenen Namen oder ihrer Handelsmarke in Betrieb nimmt, sei es entgeltlich oder unentgeltlich.  \n\"Inbetriebnahme\" ist gem. Art. 3 Z. 11 AIA die Bereitstellung eines KI-Systems in der Union zum Erstgebrauch direkt an den Betreiber oder zum Eigengebrauch entsprechend seiner Zweckbestimmung.  \nWenn ein Anbieter ein KI-System oder KI-Modell mit allgemeinem Verwendungszweck entwickelt oder entwickeln lässt und es zum Eigengebrauch in Betrieb nimmt, treffen ihn weiterhin die Anbieterpflichten. Auf eine \"Benennung\" des KI-Systems kommt es nicht an.",
      "keywords": [],
      "availableKeywords": [],
      "negativeKeywords": [],
      "relevantChunksIds": [],
      "parameters": []
    },
    {
      "id": "d8d0a3eb-4dfd-4643-a565-aacee640088d",
      "title": "KI-Servicestelle: FAQ - Gibt es bereits eine behördliche Zuständigkeit im Zusammenhang mit [Sektor]?",
      "content": "# Gibt es bereits eine behördliche Zuständigkeit im Zusammenhang mit [Sektor]?\n\nDie Benennung der national für die Umsetzung zuständigen Behörden hat im Wesentlichen bis 2.8.2025 zu erfolgen ([https://www.rtr.at/rtr/service/ki-servicestelle/ai-act/Zeitplan.de.html](https://www.rtr.at/rtr/service/ki-servicestelle/ai-act/Zeitplan.de.html \"Link zum Zeitplan\")).\n\nDerzeit gibt es noch keine nationale Umsetzung der Zuständigkeiten des AI Acts in Österreich. Das betrifft sowohl die Marktüberwachungsbehörden als auch die notifizierenden Behörde.",
      "keywords": [],
      "availableKeywords": [],
      "negativeKeywords": [],
      "relevantChunksIds": [],
      "parameters": []
    },
    {
      "id": "c3154f04-5972-4c94-bb49-33de0cc3c6c2",
      "title": "KI-Servicestelle: FAQ - Ich entwickle mein eigenes KI-System, dass ich danach auch ausschließlich intern einsetze. Das System wird nie für andere Marktteilnehmer zur Verfügung gestellt. Das System wäre als Hochrisiko-KI-System iSd Anh. III einzustufen. Unterliege ich einer Regulierung?",
      "content": "# Ich entwickle mein eigenes KI-System, dass ich danach auch ausschließlich intern einsetze. Das System wird nie für andere Marktteilnehmer zur Verfügung gestellt. Das System wäre als Hochrisiko-KI-System iSd Anh. III einzustufen. Unterliege ich einer Regulierung?\n\nAnhang III sieht hier keine spezielle Aufgaben- oder Rollenverteilung vor, sondern definiert, welche KI-Systeme als hochriskant iSd Art. 6 Abs. 2 gelten. Ein Unternehmen, das ihr eigenes KI-System entwickelt und selbst in Betrieb nimmt, wird einerseits selbst die Rolle des Anbieters innehaben, als auch die Rolle des Betreibers. Es werden damit sowohl die Verpflichtungen des Anbieters ([https://www.rtr.at/rtr/service/ki-servicestelle/ai-act/Anbieterverpflichtungen.de.html](https://www.rtr.at/rtr/service/ki-servicestelle/ai-act/Anbieterverpflichtungen.de.html \"Link zu den Anbieterverpflichtungen\")) als auch die des Betreibers ([https://www.rtr.at/rtr/service/ki-servicestelle/ai-act/Betreiberverpflichtungen.de.html](https://www.rtr.at/rtr/service/ki-servicestelle/ai-act/Betreiberverpflichtungen.de.html \"Link zu den Betreiberverpflichtungen\")) schlagend.",
      "keywords": [],
      "availableKeywords": [],
      "negativeKeywords": [],
      "relevantChunksIds": [],
      "parameters": []
    },
    {
      "id": "26604e5a-bcad-4972-8e6f-a2007c1d4761",
      "title": "KI-Servicestelle: FAQ - Wie werden Unternehmensgruppen behandelt, wenn konzernintern KI-Systeme entwickelt, und durch andere Unternehmen innerhalb des Konzerns genutzt werden?",
      "content": "# Wie werden Unternehmensgruppen behandelt, wenn konzernintern KI-Systeme entwickelt, und durch andere Unternehmen innerhalb des Konzerns genutzt werden?\n\nWird ein Hochrisiko-KI-System in einem Teilunternehmen des Konzerns entwickelt, und in einem anderen Teilunternehmen des Konzerns eingesetzt, gestalten sich die Pflichten für Anbieter und Betreiber je nach Einzelfall.",
      "keywords": [],
      "availableKeywords": [],
      "negativeKeywords": [],
      "relevantChunksIds": [],
      "parameters": []
    },
    {
      "id": "e3a3782a-9936-4a26-902c-d07af5bfb88e",
      "title": "KI-Servicestelle: FAQ - Ich möchte KI-generierte Videos von einem Anbieter beziehen und auf meiner eigenen Plattform veröffentlichen, was muss ich aus Sicht des AI Acts beachten?",
      "content": "# Ich möchte KI-generierte Videos von einem Anbieter beziehen und auf meiner eigenen Plattform veröffentlichen, was muss ich aus Sicht des AI Acts beachten?\n\nWenn Sie als Unternehmer KI-Systeme Dritter einsetzen, ohne eine Änderung daran vorzunehmen, sind sie in der KI-Wertschöpfungskette in der Regel als Betreiber einzustufen, d.h. für Sie gelten die Betreiberverpflichtungen. Im Fall von KI-generierten Videos handelt es sich um ein KI-System mit begrenztem Risiko, bei welchem ab 2.8.2026 Transparenzpflichten gelten.\n\nDas heißt, wenn es sich bei Ihren Videos um \"Deep Fakes\" im Sinne des AI Acts handelt, trifft sie eine Kennzeichnungspflicht. Andernfalls ergeben sich für die Videos keine gesonderten Verpflichtungen aus dem AI Act. Nähere Informationen dazu finden Sie auf unserer Website: [https://www.rtr.at/rtr/service/ki-servicestelle/ai-act/Transparenzpflichten.de.html](https://www.rtr.at/rtr/service/ki-servicestelle/ai-act/Transparenzpflichten.de.html \"Link zu den Transparenzpflichten\")",
      "keywords": [],
      "availableKeywords": [],
      "negativeKeywords": [],
      "relevantChunksIds": [],
      "parameters": []
    },
    {
      "id": "8fea4ada-f7cc-4b5f-92b7-495865c95467",
      "title": "KI-Servicestelle: FAQ - Ich möchte KI-generierte Fotos von einem Anbieter beziehen und auf meiner eigenen Plattform veröffentlichen. Ist dies urheberrechtlich zulässig?",
      "content": "# Ich möchte KI-generierte Fotos von einem Anbieter beziehen und auf meiner eigenen Plattform veröffentlichen. Ist dies urheberrechtlich zulässig?\n\nOb gesonderte Ansprüche des KI-Anbieters bestehen, werden Sie in der Regel in dessen AGB oder anderen vertraglichen Vereinbarungen finden. Anbieter von GPAI-Modellen, wie es ein System zur synthetischen Generierung von Text, Bildern und Videos sein kann, haben nach den Verpflichtungen des AI Acts ab 2.8.2025 eine Strategie zur Einhaltung des Urheberrechts (Art. 53 Abs. 1 lit. c AIA) bereitzustellen.\n\nManche Anbieter bieten eine solche bereits jetzt an und beschränken die Trainingsdaten des Modells auf lizenzierten Content. Einige Anbieter gewährleisten auch die unbedenkliche Nutzung der generierten Inhalte mit einer Garantie der Schad- und Klagloshaltung. Hier wäre eine Prüfung der konkreten privatrechtlich vereinbarten Zusicherungen ratsam.",
      "keywords": [],
      "availableKeywords": [],
      "negativeKeywords": [],
      "relevantChunksIds": [],
      "parameters": []
    },
    {
      "id": "146330a8-dcb0-4f24-a51b-6c90354ad5e3",
      "title": "KI-Servicestelle: FAQ - Was muss ich beachten, wenn ich Videos mit KI-Avataren bzw. digitalen Zwillingen erstelle?",
      "content": "# Was muss ich beachten, wenn ich Videos mit KI-Avataren bzw. digitalen Zwillingen erstelle?\n\nWenn Sie als Unternehmer KI-Systeme Dritter, ohne eine Änderung daran vorzunehmen, sind Sie in der [KI-Wertschöpfungskette](https://www.rtr.at/rtr/service/ki-servicestelle/ai-act/akteure.de.html \"Link öffnet die Übersicht der Akteure\") in der Regel als Betreiber einzustufen, d.h. für Sie gelten die [Betreiberverpflichtungen](https://www.rtr.at/rtr/service/ki-servicestelle/ai-act/Betreiberverpflichtungen.de.html \"Link zu den Betreiberverpflichtungen\"). Im Fall von KI-generierten Videos und Audio handelt es sich um ein KI-System mit begrenztem Risiko, bei welchem ab 2.8.2026 [Transparenzpflichten](https://www.rtr.at/rtr/service/ki-servicestelle/ai-act/Transparenzpflichten.de.html \"Link zu den Transparenzpflichten\") gelten.\n\nWelche Pflichten jeweils gelten ist davon abhängig, ob es sich bei diesen Avataren um fotorealistische oder illustrative Avatare handelt.\n\nDas heißt, wenn es sich bei Ihren Videos um \"Deep Fakes\" im Sinne des AI Acts handelt (etwa weil das Avatar Sie fotorealistisch als Person darstellen soll), trifft sie eine Kennzeichnungspflicht. Dies gilt ebenso bei illustrativen Avataren, welche Ihre Stimme KI-generiert wiedergeben, obwohl Sie diesen Text nicht gesprochen haben.\n\nAndernfalls ergeben sich für die Videos keine gesonderten Verpflichtungen aus dem AI Act, da bei illustrativen Avataren hervorgeht, dass es sich nicht um die eigentliche Person handelt, welche Inhalte vermeintlich wiedergibt.",
      "keywords": [],
      "availableKeywords": [],
      "negativeKeywords": [],
      "relevantChunksIds": [],
      "parameters": []
    },
    {
      "id": "fd982bdd-fd66-49a7-9fb1-5551eb202552",
      "title": "KI-Servicestelle: FAQ - Ich möchte gerne ein KI-System im Bereich der kritischen Infrastruktur verwenden. Ab wann handelt es sich um ein Hochrisiko-KI-System? Was ist ein Sicherheitsbauteil?",
      "content": "# Ich möchte gerne ein KI-System im Bereich der kritischen Infrastruktur verwenden. Ab wann handelt es sich um ein Hochrisiko-KI-System? Was ist ein Sicherheitsbauteil?\n\nEin KI-System stellt ein Hochrisiko-KI-System dar, wenn es im Bereich der kritischen Infrastruktur als Sicherheitsbauteil verwendet wird, Anhang III Z. 2 AIA:\n\n-   im Rahmen der Verwaltung und des Betriebs\n-   kritischer digitaler Infrastruktur,\n-   des Straßenverkehrs oder\n-   der Wasser-, Gas-, Wärme- oder Stromversorgung\n\nIm Bereich der Hochrisiko-KI-Systeme wird in Art. 6 Abs. 1 lit. a AIA darauf verweisen, dass ein KI-System als hochriskant eingestuft wird, wenn\n\n-   es als Sicherheitsbauteil eines in Anhang I genannten Produkts dienen soll, oder\n-   wenn das KI-System in Anhang III genannt wird (Art. 6 Abs. 2 AIA).\n\nGrundsätzlich gehört die kritische Infrastruktur zu einer kritischen Einrichtung. In der Definition in Art. 3 Z. 62 AIA wird bzgl. des Begriffes \"kritische Infrastruktur\" auf Art. 2 Z. 4 der [RL (EU) 2022/2557](https://eur-lex.europa.eu/eli/dir/2022/2557/oj?locale=de \"Link öffnet die Richtlinie 2022/2557\") (\"Richtlinie über die Resilienz kritischer Infrastruktur\", \"critical entities resilience directive\", \"CER\") verwiesen. Laut Art. 2 Z. 1, 4 und 5 CER muss diese \"kritische Einrichtung\", also eine öffentliche oder private Einrichtung, vom jeweiligen Mitgliedstaat als solche eingestuft werden.\n\nZur dazugehörigen konkreten \"kritischen Infrastruktur\" zählen demnach:\n\n-   Objekte, Anlagen, Ausrüstung, Netze oder Systeme oder\n-   Teile eines Objekts, einer Anlage, Ausrüstung,\n-   eines Netzes oder eines Systems,\n\ndie für die Erbringung eines wesentlichen Dienstes erforderlich ist. Ein solcher Dienst ist wesentlich, wenn er von entscheidender Bedeutung ist\n\n-   für die Aufrechterhaltung wichtiger gesellschaftlicher Funktionen,\n-   wichtiger wirtschaftlicher Tätigkeiten,\n-   der öffentlichen Gesundheit und Sicherheit oder\n-   der Erhaltung der Umwelt.\n\nIn Art. 2 der aufgrund der CER ergangenen [Delegierten Verordnung 2023/2450](https://eur-lex.europa.eu/eli/reg_del/2023/2450/oj?locale=de \"Link zur Delegierten Verordnung 2023/2450\") der Europäischen Kommission, ist eine nicht erschöpfende Liste von wesentlichen Diensten genannt.\n\nDer Begriff des \"Sicherheitsbauteil\" wird in Art. 3 Z 14 AIA folgendermaßen definiert:\n\n\"ein […] Bestandteil eines Produkts oder KI-Systems, der eine Sicherheitsfunktion für dieses Produkt oder KI-System erfüllt oder dessen Ausfall oder Störung die Gesundheit und Sicherheit von Personen oder Eigentum gefährdet\"\n\nSpeziell zu Kritischer Infrastruktur wird der Gesetzgeber in ErwG 55 AIA etwas deutlicher:\n\n„(55) […] Sicherheitsbauteile kritischer Infrastruktur, einschließlich kritischer digitaler Infrastruktur, sind Systeme, die verwendet werden, um die physische Integrität kritischer Infrastruktur oder die Gesundheit und Sicherheit von Personen und Eigentum zu schützen, die aber nicht notwendig sind, damit das System funktioniert. Ausfälle oder Störungen solcher Komponenten können direkt zu Risiken für die physische Integrität kritischer Infrastruktur und somit zu Risiken für die Gesundheit und Sicherheit von Personen und Eigentum führen. Komponenten, die für die ausschließliche Verwendung zu Zwecken der Cybersicherheit vorgesehen sind, sollten nicht als Sicherheitsbauteile gelten. Zu Beispielen von Sicherheitsbauteilen solcher kritischen Infrastruktur zählen etwa Systeme für die Überwachung des Wasserdrucks oder Feuermelder-Kontrollsysteme in Cloud-Computing-Zentren.“\n\nOb eine Ausnahme davon iSd einer der Ausnahmegründen des Art. 6 Abs. 3 AIA vorliegt, wird auf die Ausgestaltung im konkreten Einzelfall ankommen.",
      "keywords": [],
      "availableKeywords": [],
      "negativeKeywords": [],
      "relevantChunksIds": [],
      "parameters": []
    },
    {
      "id": "30977cbc-3e3a-469b-823d-7859b1113c51",
      "title": "KI-Servicestelle: FAQ - Ich möchte gerne KI-Reallabore nutzen. Ab wann ist dies möglich und wie genau funktionieren diese?",
      "content": "# Ich möchte gerne KI-Reallabore nutzen. Ab wann ist dies möglich und wie genau funktionieren diese?\n\nIn KI-Reallaboren oder auch Regulatory Sandboxes genannt, können darin beaufsichtigte Tests unter Realbedingungen durchgeführt werden.\n\nArt. 57 AIA sieht vor, dass Mitgliedstaaten dafür sorgen, dass ihre zuständigen Behörden mindestens ein KI-Reallabor auf nationaler Ebene einrichten, [das bis zum 2. August 2026 einsatzbereit sein muss](https://www.rtr.at/rtr/service/ki-servicestelle/ai-act/Zeitplan.de.html \"Link zum Zeitplan\"). Dieses Reallabor kann auch gemeinsam mit den zuständigen Behörden anderer Mitgliedstaaten eingerichtet werden. Die Kommission kann technische Unterstützung, Beratung und Instrumente für die Einrichtung und den Betrieb von KI-Reallaboren bereitstellen.\n\nIn KI-Reallaboren erhalten Entwickler eine kontrollierte Umgebung, um neue KI-Systeme für einen begrenzten Zeitraum zu testen und weiterzuentwickeln, bevor diese auf den Markt kommen. Dabei einigen sich die Entwickler und die Behörden auf einen Plan, der den Ablauf der Tests regelt.\n\nDer Vorteil dieser Reallabore ist, dass die zuständigen Behörden Unterstützung und Aufsicht bieten, um Risiken zu minimieren. Dies betrifft vor allem die Einhaltung von Grundrechten, Gesundheits- und Sicherheitsstandards sowie andere gesetzliche Anforderungen. Dazu wird es Leitfäden zu regulatorischen Erwartungen und zur Erfüllung der Anforderungen geben.\n\nZudem kann der Anbieter auf Anfrage einen schriftlichen Nachweis für die im Reallabor durchgeführten Tätigkeiten erhalten. Außerdem erstellt die Behörde einen Bericht, der die durchgeführten Aktivitäten und deren Ergebnisse beschreibt. Diesen können die Anbieter im Rahmen des Konformitätsbewertungsverfahrens nutzen.\n\nDie Einrichtung von KI-Reallaboren soll zu den folgenden Zielen beitragen:\n\n-   Verbesserung der Rechtssicherheit\n-   Förderung des Austauschs bewährter Verfahren durch Zusammenarbeit mit den am KI-Reallabor beteiligten Behörden\n-   Förderung von Innovation und Wettbewerbsfähigkeit sowie Erleichterung der Entwicklung eines KI-Ökosystems\n-   Leisten eines Beitrags zum evidenzbasierten regulatorischen Lernens\n-   Erleichterung und Beschleunigung des Zugangs von KI-Systemen zum Binnenmarkt\n\nDie am KI-Reallabor beteiligten Anbieter bleiben nach geltendem Recht der Union und nationalem Haftungsrecht für Schäden haftbar, die Dritten infolge der Erprobung im Reallabor entstehen.",
      "keywords": [],
      "availableKeywords": [],
      "negativeKeywords": [],
      "relevantChunksIds": [],
      "parameters": []
    },
    {
      "id": "0e7c7bb9-4047-4ca7-80d7-09d34f8783b1",
      "title": "KI-Servicestelle: FAQ - Unser Unternehmen hat seinen Sitz in der EU und möchte Hochrisiko-KI-Systeme entwickeln, die ausschließlich außerhalb der EU eingesetzt werden sollen. Gilt der AI Act für diese KI-Systeme?",
      "content": "# Unser Unternehmen hat seinen Sitz in der EU und möchte Hochrisiko-KI-Systeme entwickeln, die ausschließlich außerhalb der EU eingesetzt werden sollen. Gilt der AI Act für diese KI-Systeme?\n\nGrundsätzlich gilt für die Anwendbarkeit des AIA das Marktortprinzip, d.h. es gelten die Regelungen, welche für den jeweiligen Markt, auf welchem das Produkt in Verkehr gebracht wird, und zwar unabhängig vom Niederlassungsort. Dabei ist ausschlaggebend, dass das KI-System oder KI-Modell in einem Mitgliedsstaat der Europäischen Union bereitgestellt oder in Betrieb genommen wird (Art. 2 Abs. 1 lit. a AIA).\n\nHier hat das Unternehmen zwar seinen Sitz in der EU, möchte aber Hochrisiko-KI-Systeme entwickeln, die ausschließlich außerhalb der EU vertrieben und eingesetzt werden sollen, somit auf einem anderen Markt. Daher gilt der AIA nicht für Anbieter, die ein Produkt ausschließlich exportieren.\n\nJedoch könnte das Unternehmen trotzdem dazu verpflichtet sein, die Betreiberpflichten einzuhalten, da es seinen Sitz in der EU hat (Art. 2 Abs. 1 lit. b AIA). Dafür ist Voraussetzung, dass das Unternehmen das KI-System aber auch in der EU betreibt. Dies ist hier nicht der Fall und der AIA deshalb nicht anwendbar.\n\nFerner darf das KI-System gem. Art. 2 Abs. 1 lit. c AIA aber auch nicht so genutzt werden, dass Ergebnisse in die EU gelangen. Wenn auch die Nutzungen ausschließlich außerhalb der EU erfolgen, ist der AIA nicht anwendbar.\n\nZu beachten ist, dass die Regelungen des AIA gem. Art. 2 Abs. 1 lit. g AIA Anwendung finden können, wenn es betroffene Personen geben kann, die sich in der EU befinden. Deren Betroffenenrechte, z.B. in Art. 86 AIA und auch Erwägungsgrund 22, sehen vor, dass die Daten in der Union rechtmäßig erhoben worden sein müssen. D.h. weitergehende Regelungen, – auch aus anderen Gesetzen – welche die Rechtmäßigkeit der Datenerhebung, insbesondere von betroffenen natürlichen Personen betreffen, um dieses KI-System zu entwickeln, müssen trotzdem beachtet werden.",
      "keywords": [],
      "availableKeywords": [],
      "negativeKeywords": [],
      "relevantChunksIds": [],
      "parameters": []
    },
    {
      "id": "e419d565-51f0-41b6-92b6-c80be68c2956",
      "title": "KI-Servicestelle: Akteure",
      "content": "### Übersicht: Die Akteure im AI Act\n\nDer AI Act sieht viele Rollen in der KI-Wertschöpfungskette vor. Die verschiedenen Akteure sind dabei keineswegs unbekannt, der Unionsgesetzgeber orientierte sich dabei in vielerlei Hinsicht an den EU-Produktrechtsnormen (siehe etwa die [Produktsicherheitsverordnung](https://eur-lex.europa.eu/legal-content/DE/TXT/?uri=CELEX%3A32023R0988 \"Link zur Produktsicherheitsverordnung\"), [Medizinprodukteverordnung](https://eur-lex.europa.eu/legal-content/DE/TXT/?uri=CELEX%3A32017R0745 \"Link zur Medizinprodukteverordnung\")).\n\nZu den Akteuren im AI Act zählen gemäß Art. 3 Ziffer 8:\n\n-   Anbieter („Provider“);\n-   Produkthersteller („Product Manufacturer“);\n-   Bevollmächtigter („Authorised Representative“);\n-   Einführer („Importer“);\n-   Händler („Distributor“);\n-   Betreiber („Deployer“).\n\nFerner kommen auch noch Nutzer und „betroffene Personen“ vor. Diese werden aber nicht als Akteure im Sinne des AI Act bezeichnet.",
      "keywords": [],
      "availableKeywords": [],
      "negativeKeywords": [],
      "relevantChunksIds": [],
      "parameters": []
    },
    {
      "id": "0a3fb82e-b170-41b1-bce4-6271864f0212",
      "title": "KI-Servicestelle: Akteure",
      "content": "### Inverkehrbringen, Bereitstellen, Inbetriebnahme\n\nDie verschiedenen Akteure übernehmen verschiedene Tätigkeiten in der KI-Wertschöpfungskette. Unterschieden wird dabei in „Inverkehrbringen“, „Bereitstellen“ und der „Inbetriebnahme“, die im AI Act auch legaldefiniert werden. Diese Begriffe sind nicht neu, kommen sie doch bereits im EU-Produktrecht vor.\n\nMit „Inverkehrbringen“ ist gemäß Art. 3 Ziffer 9 AIA „die erstmalige Bereitstellung eines KI-Systems oder eines [GPAI-Modell](https://www.rtr.at/rtr/service/ki-servicestelle/ai-act/risikostufen_ki-modelle.de.html \"Link zum Beitrag über KI-Modelle mit allgemeinem Verwendungszweck (GPAI)\") auf dem Unionsmarkt“ gemeint. Laut Definition erfasst das Inverkehrbringen zugleich die „Bereitstellung auf dem Markt“, was wiederum „die entgeltliche oder unentgeltliche Bereitstellung eines KI-Systems oder eines KI-Modells mit allgemeinem Verwendungszweck zum Vertrieb oder zur Verwendung auf dem Unionsmarkt im Rahmen einer Geschäftstätigkeit“ bezeichnet (Art. 3 Ziffer 10 AIA).\n\nDer Unterschied zwischen „Inverkehrbringen“ und „Bereitstellen“ liegt darin, dass beim Inverkehrbringen die Bereitstellung auf dem Markt erstmalig erfolgt. Das Inverkehrbringen übernimmt innerhalb der EU in der Regel der Hersteller des Produkts bzw. im Falle des KI-Systems/GPAI-Modell der Anbieter; bei Produkten bzw. KI-Systemen außerhalb der EU der Importeur. Ist die erstmalige Bereitstellung erfolgt, wird die weitere Bereitstellung (umgangssprachlich als „Vertrieb“ bezeichnet) für gewöhnlich vom Händler übernommen, die typische Tätigkeiten wie den Verkauf, die Lagerung, den Transport (etwa bei in physischen Produkten integrierte Hochrisiko-KI-Systeme), die Kundenbetreuung oder die Wartung übernehmen.\n\nDiese Form der Lieferkette stellt vor allem den traditionellen Weg einer Lieferkette dar, wo das Produkt vom Hersteller über den Importeur und (Zwischen-)Händler ihren Weg zum Endkunden findet. Mit dem Fernabsatz haben sich auch neue Vertriebsformen entwickelt. Anbieter und Händler aus Drittstaaten können ihre Produkte durch Online-Schnittstellen am Unionsmarkt anbieten, was vor allem Anbieter auch das Ausklammern bestimmter Akteure (z. B. Händler) ermöglicht. Gerade bei digitalen Produkten wie Software-Anwendungen, welche durch einen simplen Download erworben werden können, spielt diese Form des Absatzes eine bedeutsame Rolle.\n\nAuf die Veränderungen der Absatzformen hat auch der Unionsgesetzgeber in der [Marktüberwachungsverordnung](https://eur-lex.europa.eu/legal-content/DE/TXT/PDF/?uri=CELEX:32019R1020 \"Link zur Marktüberwachungsverordnung\") (Erwägungsgründe 15) reagiert: Wird ein Produkt online oder über eine andere Form des Fernabsatzes angeboten, so sollte das Produkt als auf dem Markt bereitgestellt gelten, wenn sich das Verkaufsangebot an Endnutzer in der Union richtet. Ob ein solches Verkaufsangebot an Endnutzer vorliegt, ist eine Einzelfallentscheidung und hat unter Berücksichtigung von Kriterien wie etwa die geografischen Gebiete, in die geliefert werden kann, die für das Angebot oder für die Bestellung verfügbaren Sprachen und die Zahlungsarten zu erfolgen. Die bloße Zugänglichkeit der Website des Akteurs reicht für sich alleine nicht aus, eine Bereitstellung auf dem Unionsmarkt anzunehmen.\n\nMit „Inbetriebnahme“ wird gemäß Art. 3 Ziffer 11 AIA „die Bereitstellung eines KI-Systems durch den Anbieter in der Union zum Erstgebrauch direkt an den Betreiber oder zum Eigengebrauch entsprechend seiner Zweckbestimmung“ bezeichnet. Mit „Zweckbestimmung“ wird kurzgefasst die Verwendung, für die ein KI-System laut Anbieter bestimmt oder propagiert wird (vgl. Art. 3 Ziffer 12 AIA).",
      "keywords": [],
      "availableKeywords": [],
      "negativeKeywords": [],
      "relevantChunksIds": [],
      "parameters": []
    },
    {
      "id": "18cba04a-f269-4f84-b97c-fbbbe2ef300f",
      "title": "KI-Servicestelle: Akteure",
      "content": "### Die einzelnen Akteure\n\nJe nachdem, um welchen Akteur und welches KI-System oder GPAI-Modell es sich handelt, sind unterschiedlich weitreichende Verpflichtungen einzuhalten. Es ist daher von fundamentaler Bedeutung, in den einzelnen Verpflichtungsadressaten zu unterscheiden. In bestimmten Situationen kann ein Akteur auch mehrere Rollen gleichzeitig übernehmen. Die folgenden Erläuterungen und die Grafik sollen einen Überblick geben.",
      "keywords": [],
      "availableKeywords": [],
      "negativeKeywords": [],
      "relevantChunksIds": [],
      "parameters": []
    },
    {
      "id": "4353602b-f09f-41e8-b609-864a7ea1a448",
      "title": "KI-Servicestelle: Akteure",
      "content": "### Wer ist Anbieter?Laut Art. 3 Ziffer 3 AIA ist ein Anbieter\n\n> _eine natürliche oder juristische Person, Behörde, Einrichtung oder sonstige Stelle, die ein KI-System oder ein KI-Modell mit allgemeinem Verwendungszweck entwickelt oder entwickeln lässt und es unter ihrem eigenen Namen oder ihrer Handelsmarke in Verkehr bringt oder das KI-System unter ihrem eigenen Namen oder ihrer Handelsmarke in Betrieb nimmt, sei es entgeltlich oder unentgeltlich._\n\nBeim Anbieter handelt es sich um jenes Glied in der KI-Wertschöpfungskette, das das KI-System oder GPAI-Modell entwickelt. Typischerweise handelt es sich dabei um Personen und Einrichtungen, die in den einzelnen Entwicklungsphasen – Datenvorbereitung, Modelltraining, Evaluierung und Optimierung – von KI-Systemen oder GPAI-Modellen beteiligt sind.\n\nDa die Entwicklung eines KI-Systems oder GPAI-Modells meist mehrere Berufsdisziplinen umfasst, arbeiten oft mehrere Fachleute wie Datenwissenschaftler, Ingenieure, Domänenexperten und Designer zusammen. Von einem Anbieter wird daher auch dann ausgegangen, wenn diese das KI-System oder ein GPAI-Modell entwickeln lässt (mit anderen Worten „in Auftrag gibt“), um es in der Folge selbst [in den Verkehr zu bringen](https://www.rtr.at/rtr/service/ki-servicestelle/ai-act/akteure.de.html#heading__heading_Inverkehrbringen__Bereitstellen__InbetriebnahmeInverkehrbringen__Bereitstellen__Inbetriebnahme \"Sprung zu Wer ist der Einführer?\") oder das System unter dem eigenen Namen oder ihrer eigenen Marke – entgeltlich oder unentgeltlich [in Betrieb zu nehmen](https://www.rtr.at/rtr/service/ki-servicestelle/ai-act/akteure.de.html#heading__heading_Inverkehrbringen__Bereitstellen__InbetriebnahmeInverkehrbringen__Bereitstellen__Inbetriebnahme \"Sprung zu Wer ist der Betreiber?\"). Anbieter können auch bestimmte Instrumente, Dienstleistungen, Komponenten oder Prozesse, wie z.B. Trainieren, Neutrainieren, Testen und Bewerten von Modellen, die Integration in Software oder andere Aspekte der Modellentwicklung auslagern. Die Verpflichtungen im Zusammenhang mit dem AI Act treffen allerdings weitergehend die Anbieter.\n\nHinweis: Um die Anwendung des AI Act auch in diesen Situationen sicherzustellen, gilt es die Pflichten vertraglich zu regeln. Das AI Office wird diesbezüglich ermächtigt, Mustervertragsbestimmungen zu erstellen und zur Verfügung zu stellen (Art. 25 Abs. 4 AI Act).\n\nVon einem Anbieter ist auch dann die Rede, wenn diese ein KI-Modell in ihr KI-System oder GPAI-System integriert. Irrelevant ist dabei, ob das Modell von ihm selbst bereitgestellt und vertikal integriert wird oder von jemand anderem stammt. In diesem Fall wird von einem „nachgelagerten Anbieter“ gesprochen (siehe Art. 3 Ziffer 68 AIA)\n\nDurch die Regel in Art. 25 Abs. 1 AIA werden auch Einführer, Händler, Betreiber und sonstige Dritte als Anbieter behandelt, wenn sie:\n\n-   ein bereits in Verkehr gebrachtes oder in Betrieb genommenes Hochrisiko-KI-System mit ihrem Namen oder ihrer Handelsmarke versehen, unbeschadet vertraglicher Vereinbarungen, die eine andere Aufteilung der Pflichten vorsieht. Der jeweilige Akteur tritt somit als Anbieter eines KI-Systems auf obwohl dieses nicht selbst entwickelt wurde („Quasi-Hersteller“);\n-   eine wesentliche Änderung an einem Hochrisiko-KI-System, das bereits in Verkehr gebracht oder in Betrieb genommen wurde, so vornehmen, dass es weiterhin ein Hochrisiko-KI-System im Sinne von Art. 6 AIA bleibt;\n-   die Zweckbestimmung eines KI-Systems, einschließlich eines GPAI-Systems, das nicht als hochriskant eingestuft wurde und bereits in Verkehr gebracht oder in Betrieb genommen wurde, so verändern, dass das betreffende KI-System zu einem Hochrisiko-KI-System im Sinne von Art. 6 AIA wird.",
      "keywords": [],
      "availableKeywords": [],
      "negativeKeywords": [],
      "relevantChunksIds": [],
      "parameters": []
    },
    {
      "id": "125e0d9e-7308-4567-a0ec-8a82fa1b0d33",
      "title": "KI-Servicestelle: Akteure",
      "content": "### Wer ist Produkthersteller?\n\nProdukthersteller werden zwar als Akteure aufgezählt, eine entsprechende Definition fehlt allerdings im AI Act. Da im Anhang I des AI Acts auf unionsrechtliche Normen des Produktrechts verwiesen wird, ist als Produkthersteller im AI Act der Hersteller des jeweiligen Produkts gemeint.\n\nBeispielshaft wird als Hersteller im Sinne der Aufzüge-Richtlinie „jede natürliche oder juristische Person, die ein Sicherheitsbauteil für Aufzüge herstellt bzw. entwickeln oder herstellen lässt und es unter ihrem eigenen Namen oder ihrer eigenen Handelsmarke vermarktet“ (Art. 2 Ziffer 8 [Aufzüge-Richtlinie](https://eur-lex.europa.eu/legal-content/DE/TXT/PDF/?uri=CELEX:32014L0033&from=LV \"Link zur Aufzüge-Richtlinie\")).\n\nWird ein KI-System als Sicherheitskomponente in ein Produkt eingebaut, hat der Produkthersteller die im AI Act festgelegten Pflichten eines Anbieters eines KI-Systems zu erfüllen. Der Produkthersteller wird in diesen Fällen als Anbieter behandelt.",
      "keywords": [],
      "availableKeywords": [],
      "negativeKeywords": [],
      "relevantChunksIds": [],
      "parameters": []
    },
    {
      "id": "aecae742-1970-41a4-aaa5-7d2389209d72",
      "title": "KI-Servicestelle: Akteure",
      "content": "### Wer ist Bevollmächtigter?\n\nGemäß Art. 3 Z 5 AIA ist ein Bevollmächtigter\n\n> _eine in der Union befindliche oder niedergelassene natürliche oder juristische Person, die vom Anbieter eines KI-Systems oder eines KI-Modells mit allgemeinem Verwendungszweck schriftlich dazu bevollmächtigt wurde und sich damit einverstanden erklärt hat, in seinem Namen die in dieser Verordnung festgelegten Pflichten zu erfüllen bzw. Verfahren durchzuführen._\n\nEin Bevollmächtigter wird notwendig, wenn die Anbieter des KI-Systems bzw. des GPAI-Modells nicht innerhalb der Union niedergelassen ist. Damit die Einhaltung der unionsrechtlichen Anforderungen an KI-Systeme bzw. GPAI-Modelle sichergestellt wird, ist die Bestellung eines Bevollmächtigten vorgesehen, der im Namen der Anbieter des KI-Systems bzw. des GPAI-Modells für die Einhaltung der im AI Act festgelegten Pflichten sorgt und auch Verfahren führt. Diese Verpflichtung gilt nicht für Anbieter von ausgenommenen Open-Source-Modellen und -Systemen im Sinne des Art. 2 Abs. 12 AIA.",
      "keywords": [],
      "availableKeywords": [],
      "negativeKeywords": [],
      "relevantChunksIds": [],
      "parameters": []
    },
    {
      "id": "fe38e634-50f1-4fcd-972e-428ed0b00086",
      "title": "KI-Servicestelle: Akteure",
      "content": "### Wer ist Einführer?\n\nArt 3 Z 6 AIA definiert einen Einführer als\n\n> _eine in der Union befindliche oder niedergelassene natürliche oder juristische Person, die ein KI-System, das den Namen oder die Handelsmarke einer in einem Drittland niedergelassenen natürlichen oder juristischen Person trägt, in der Union in Verkehr bringt._\n\nDer Einführer, auch als Importeur bezeichnet, stellt jenes Glied in der KI-Wertschöpfungskette dar, das ein KI-System eines ausländischen Anbieters in der Union [in Verkehr bringt](https://www.rtr.at/rtr/service/ki-servicestelle/ai-act/akteure.de.html#heading__heading_Inverkehrbringen__Bereitstellen__InbetriebnahmeInverkehrbringen__Bereitstellen__Inbetriebnahme). Der Importeur spielt also nur eine Rolle bei KI-Systemen aus Drittländern. In gewissen Situationen kann die Rolle des Einführers mit jener des Händlers zusammenfallen, und zwar dann, wenn der Einführer das KI-System vom Anbieter bezieht und gleichzeitig bereitstellt.\n\nUnter Umständen kann der Einführer auch als Anbieter behandelt werden (siehe Art. 25 Abs. 1 AIA).",
      "keywords": [],
      "availableKeywords": [],
      "negativeKeywords": [],
      "relevantChunksIds": [],
      "parameters": []
    },
    {
      "id": "5258a087-d836-41b0-b6ce-6df5f13bedc9",
      "title": "KI-Servicestelle: Akteure",
      "content": "### Wer ist Händler?\n\nGemäß Art 3 Z 7 AIA wird ein Händler wie folgt legaldefiniert:\n\n> _Eine natürliche oder juristische Person in der Lieferkette, die ein KI-System auf dem Unionsmarkt bereitstellt, mit Ausnahme des Anbieters oder des Einführers._\n\nBeim Händler handelt es sich um jene Person in der KI-Wertschöpfungskette, die ein KI-System auf dem Unionsmarkt [bereitstellt](https://www.rtr.at/rtr/service/ki-servicestelle/ai-act/akteure.de.html#heading__heading_Inverkehrbringen__Bereitstellen__InbetriebnahmeInverkehrbringen__Bereitstellen__Inbetriebnahme). Die reine Bereitstellung kommt in zeitlicher Hinsicht nach dem Inverkehrbringen.\n\nUnter Umständen kann der Händler auch als Anbieter behandelt werden (siehe Art. 25 Abs. 1 AIA).",
      "keywords": [],
      "availableKeywords": [],
      "negativeKeywords": [],
      "relevantChunksIds": [],
      "parameters": []
    },
    {
      "id": "54902079-8fec-477d-81b8-12abdae3a221",
      "title": "KI-Servicestelle: Akteure",
      "content": "### Wer ist Betreiber?\n\nGemäß Art. 3 Ziffer 4 AIA ist ein Betreiber\n\n> _eine natürliche oder juristische Person, Behörde, Einrichtung oder sonstige Stelle, die ein KI-System in eigener Verantwortung verwendet, es sei denn, das KI-System wird im Rahmen einer persönlichen und nicht beruflichen Tätigkeit verwendet._\n\nAls Betreiber wird jenes Glied in der KI-Wertschöpfungskette bezeichnet, das ein KI-System in eigener Verantwortung verwendet. Beispielhaft werden die Organe, Einrichtungen und sonstigen Stellen der Union genannt (Erwägungsgründe 23). In der KI-Wertschöpfungskette sind sie den Anbietern nachgelagert, sie führen das KI-System in der Praxis aus. Betreiber ist jene Person, Behörde, etc. die entscheidet, ob und wie ein KI-System eingesetzt wird und trägt dafür auch die Verantwortung. Ausgenommen ist vom Betreiber-Begriff die rein private Nutzung von KI-Systemen.\n\nUnter Umständen kann der Betreiber auch als Anbieter behandelt werden (siehe Art. 25 Abs. 1 AIA).",
      "keywords": [],
      "availableKeywords": [],
      "negativeKeywords": [],
      "relevantChunksIds": [],
      "parameters": []
    },
    {
      "id": "356bb808-a31d-4d14-9273-1da6952a312a",
      "title": "KI-Servicestelle: Akteure",
      "content": "### Wer ist Nutzer?\n\nDer Begriff „Nutzer“ kommt im AI Act zwar vor, wird aber nicht legaldefiniert. Der Begriff Nutzer wird an verschiedenen Stellten des AI Act genannt, z. B. im Anhang XIII zu finden als „Endnutzer“ und „gewerblicher Nutzer“ oder in verschiedenen Erwägungsgründen (siehe Erwägungsgründe 16: „um es den Nutzern zu ermöglichen“; Erwägungsgründe 102: „Software und Daten, einschließlich Modellen […] die Nutzer kostenlos abrufen, nutzen, verändern und weiter verteilen können“, „wenn sie es den Nutzern ermöglicht“). In der vom Parlament abgestimmten Fassung wurde dieser Begriff teilweise mit dem Betreiber gleichgestellt.",
      "keywords": [],
      "availableKeywords": [],
      "negativeKeywords": [],
      "relevantChunksIds": [],
      "parameters": []
    },
    {
      "id": "7336e729-b4b4-4470-8d51-db20970705cc",
      "title": "KI-Servicestelle: Akteure",
      "content": "### „Betroffene“ Personen\n\nJe nach Art des KI-Systems kann sich dessen Verwendung auf andere Personen als den Betreiber auswirken (Erwägungsgründe 13 AIA). Damit sind jene Personen gemeint, die Gegenstand des Einsatzes des KI-Systems sind oder in anderweitiger Weise von der Nutzung eines KI-Systems tangiert werden.\n\nBeispiele hierfür sind auch im AI Act zu finden, wie z. B. die Nutzung eines Chatbot oder die Herstellung künstlicher Audio-, Bild-, Video- oder Textinhalte wie Deepfakes (siehe Art. 50 Abs. 1 und 2 AIA), die Nutzung eines Emotionserkennungssystems oder eines Systems zur biometrischen Kategorisierung (siehe Art. 50 Abs. 3 AIA), die Verwendung eines biometrischen Echtzeit-Fernidentifizierungssystems (Art. 5 Abs. 2 AIA) oder die Inbetriebnahme oder Verwendung eines Hochrisiko-KI-Systems am Arbeitsplatz (Art. 26 Abs. 7 AIA).",
      "keywords": [],
      "availableKeywords": [],
      "negativeKeywords": [],
      "relevantChunksIds": [],
      "parameters": []
    },
    {
      "id": "9be93838-5d82-4573-a63f-81a708c77fa7",
      "title": "KI-Servicestelle: Behörden & Einrichtungen",
      "content": "## Was ist und macht das Europäische Büro für Künstliche Intelligenz („AI Office“)?\n\nDas [AI Office](https://digital-strategy.ec.europa.eu/de/policies/ai-office \"Link zum AI Office\") wurde durch [Beschluss der Kommission](https://digital-strategy.ec.europa.eu/de/library/commission-decision-establishing-european-ai-office \"Link zum Beschluss der Europäischen Kommission\") eingerichtet und ist bei Kommission in der [Generaldirektion Kommunikationsnetze, Inhalte und Technologien](https://commission.europa.eu/about-european-commission/departments-and-executive-agencies/communications-networks-content-and-technology_en?prefLang=de \"Link zur DG Connect\") (DG CNCT) angesiedelt. Über das AI Office soll die Kommission die Sachkenntnis und Fähigkeiten der Union auf dem Gebiet der Künstlichen Intelligenz entwickeln (Art. 64 AIA). Die übertragenen Tätigkeiten werden von bereits mit diesen Aufgaben betrauten Beamt:innen übernommen. Die dem AI Office übertragenen Aufgaben können daher bereits wahrgenommen werden.\n\nDas AI Office übernimmt eine Fülle von Aufgaben. Diese sind einerseits im AI Act festgeschrieben, andererseits auch im Beschluss der Kommission spezifiziert. Bei der Durchführung ihrer Aufgaben hat das AI Office mit relevanten Stakeholdern (Wissenschaft, KI-Entwicklern, Zivilgesellschaft, Sozialpartner, etc.), den unionsrechtlichen und nationalen Behörden und Stellen zusammenzuarbeiten.\n\nZu den im Beschlussaufgelisteten Aufgaben gehören unter anderem:\n\n-   Überwachung der Umsetzung und Anwendung des AI Act ganz allgemein auf Unionsebene. Dazu zählen insbesondere folgende Aufgaben:\n    -   Unterstützung der Kommission bei der Vorbereitung einschlägiger Kommissionsentscheidungen, und von Durchführungs- und delegierten Rechtsakten; Ausarbeitung von Anleitungen und Leitlinien zur Unterstützung der praktischen Umsetzung des AI Act; Vorbereitung von Normungsaufträgen, Bewertung bestehender Normen und der Ausarbeitung gemeinsamer Spezifikationen;\n    -   Beitrag zur Bereitstellung von technischer Unterstützung, Beratung und Instrumenten für die Einrichtung und den Betrieb von KI-Reallaboren;\n    -   Durchführung von Bewertungen und Überprüfungen sowie Erstellung von Berichten;\n    -   Koordinierung der Einrichtung eines wirksamen Governance-Systems, unter anderem durch Vorbereitung der Einsetzung von Beratungsgremien auf Unionsebene;\n    -   Bereitstellung des Sekretariats für den AI Board und seine Unterausschüsse, sowie administrative Unterstützung des Advisory Forums und des Scientific Panels;\n    -   Förderung und Erleichterung der Ausarbeitung von Verfahrens- und Verhaltenskodizes.\n\n-   Überwachung der Umsetzung und Anwendung des AI Act im Zusammenhang mit KI-Modellen mit allgemeinem Verwendungszweck („General Purpose AI“, GPAI). Dazu zählen insbesondere folgende Aufgaben:\n    -   Marktüberwachungsbehörde bei GPAI-Systemen, wo das Modell und das System vom gleichen Anbieter stammen (Art 75 AIA);\n    -   Entwicklung von Werkzeugen, Methoden und Benchmarks zur Bewertung der Fähigkeiten von GPAI, insbesondere für sehr große GPAI mit systemischen Risiken;\n    -   Überwachung des Auftretens unvorhergesehener Risiken, die sich aus GPAI-Modellen ergeben, unter anderem durch Reaktion auf Warnungen des wissenschaftlichen Gremiums;\n    -   Koordinierung der Überwachung und Durchsetzung von Rechtsvorschriften, für die die Kommission Aufsichts- und Durchsetzungsbefugnisse hat (z. B. Digital Services Act oder Digital Markets Act);\n    -   Unterstützung der Umsetzung der Vorschriften über verbotene KI-Praktiken und Hochrisiko-KI-Systeme in Abstimmung mit den nach den sektoralen Rechtsvorschriften zuständigen Stellen, einschließlich der Erleichterung des Informationsaustauschs und der Zusammenarbeit zwischen den nationalen Behörden, der Sammlung von Meldungen und der Einrichtung von Informationsplattformen und Datenbanken, insbesondere wenn ein GPAI-Modell in ein Hochrisiko-KI-System integriert wird.  \n          \n          \n        \n\n-   Zusammenarbeit mit Stakeholdern, Überwachung der Umsetzung und Anwendung des AI Act;\n-   Internationale Kooperation mit Drittstaaten und internationalen Organisationen, um einen Beitrag zu einem strategischen, kohärenten und wirksamen Ansatz der Union im Bereich der KI in Abstimmung mit den Mitgliedstaaten und im Einklang mit den Standpunkten und Politiken der Union sicherzustellen;\n-   Die Förderung der sektorenübergreifenden Zusammenarbeit innerhalb der Kommission;\n-   Unterstützung der Entwicklung, Einführung und Nutzung vertrauenswürdiger KI-Systeme und -Anwendungen, die gesellschaftliche und wirtschaftliche Vorteile bringen und zur Wettbewerbsfähigkeit und zum Wirtschaftswachstum der Union beitragen. Insbesondere die Förderung der Innovationsökosysteme durch die Zusammenarbeit mit den einschlägigen öffentlichen und privaten Akteuren und der Startup-Community;\n-   Marktbeobachtung der KI-Märkte und -Technologien.",
      "keywords": [],
      "availableKeywords": [],
      "negativeKeywords": [],
      "relevantChunksIds": [],
      "parameters": []
    },
    {
      "id": "73b4b412-4437-4a0a-a3de-75077b666509",
      "title": "KI-Servicestelle: Behörden & Einrichtungen",
      "content": "## Was ist und macht das Europäische Gremium für künstliche Intelligenz (\"AI Board\")?\n\nDas AI Board setzt sich zusammen aus je einem Repräsentanten jedes Mitgliedstaates, dem Europäischen Datenschutzbeauftragten und des AI Office, wobei der Europäische Datenschutzbeauftragter dabei die Position des Beobachters übernimmt und das AI Office bei Abstimmungen nicht teilnimmt. Andere nationale und europäische Behörden, Stellen oder Experten können bei relevanten Themen eingeladen werden. Den Vorsitz bildet ein Repräsentant eines Mitgliedstaates (Art. 65 Abs. 2 AIA).\n\nRepräsentanten werden von den Mitgliedstaaten auf drei Jahre gewählt und können einmal wiedergewählt werden. Bei der Wahl des Repräsentanten sind folgende Kriterien zu berücksichtigen(Art. 65 Abs. 4 AIA):\n\n-   Jeder Repräsentant muss innerstaatlich über die nötigen Kompetenzen verfügen, um die Aufgaben des AI Board umsetzen zu können;\n-   Jeder Repräsentant muss Befugnisse haben, die Durchführung dieser Verordnung zu erleichtern, etwa durch Erhebung einschlägiger Daten;\n-   Jeder Repräsentant hat als zentrale Kontaktstelle zwischen Mitgliedstaat und AI Board zu dienen; gegebenenfalls soll dieser auch als Ansprechpartner für Stakeholder in ihrem Mitgliedstaat dienen.\n\nDie Objektivität und Unparteilichkeit des AI Board ist zu gewährleisten.\n\nDas AI Board übernimmt gemäß Art. 66 AIA unter anderem folgende Aufgaben:\n\n-   Beitrag zur Koordinierung zwischen den für die Anwendung dieser Verordnung zuständigen nationalen Behörden und Unterstützung der Marktüberwachungsbehörden;\n-   Zusammenarbeit mit anderen Organen, Einrichtungen, Ämtern und Agenturen der Union sowie zuständigen Behörden von Drittländern und internationalen Organisationen;\n-   Sammlung und Austausch von technischem und regulatorischem Fachwissen und bewährten Verfahren unter den Mitgliedstaaten;\n-   Beratung bei der Durchführung dieser Verordnung, insbesondere in Bezug auf die Durchsetzung der Vorschriften über GPAI;\n-   Beitrag zur Harmonisierung der Verwaltungspraxis (Konformitätsbewertungsverfahren, KI-Reallabore und Tests unter realen Bedingungen) in den Mitgliedstaaten;\n-   Empfehlungen und schriftliche Stellungnahmen zu allen relevanten Fragen im Zusammenhang mit der Durchführung und Anwendung dieser Verordnung.\n\nDas AI Board besteht aus zwei ständigen Unterausschüssen, welche die Zusammenarbeit und den Austausch zwischen den Marktüberwachungsbehörden und den notifizierenden Behörden sicherstellen sollen. Zur Bewältigung der Aufgaben können weitere ständige oder temporäre Unterausschüsse gebildet werden.\n\nDas AI Office übernimmt die Verwaltungsaufgaben für das AI Board.\n\nNicht zu verwechseln ist das Advisory Forum mit dem [KI-Beirat](https://www.digitalaustria.gv.at/Themen/KI/AI-Advisory-Board.html \"Link zum österreichischen KI-Beirat\") (oft auch als AI Advisory Board bezeichnet) in Österreich!",
      "keywords": [],
      "availableKeywords": [],
      "negativeKeywords": [],
      "relevantChunksIds": [],
      "parameters": []
    },
    {
      "id": "e8636770-3900-45b1-a25d-a32616c51a42",
      "title": "KI-Servicestelle: Behörden & Einrichtungen",
      "content": "## Wer ist und was macht der Beratungsforum („Advisory Forum“)?\n\nDas Advisory Forum gemäß Art. 67 AIA dient als Beratungsgremium in technischen Angelegenheiten für die Kommission und das AI Board und besteht aus Stakeholdern aus Industrie, Start-ups, KMU-Sektor, Wissenschaft, Think Tanks und Zivilgesellschaft. Die Zusammensetzung bestimmt die Kommission, wobei sie auf ein ausgewogenes Verhältnis zwischen kommerziellen und nicht-kommerziellen Interessen zu achten hat. Die [Agentur für Grundrechte](http://fra.europa.eu/ \"Link zur FRA\") (FRA), die [Agentur der Europäischen Union für Cybersicherheit](https://www.enisa.europa.eu/ \"Link zur ENISA\") (ENISA), das [Europäische Komitee für elektrotechnische Normung](https://www.cencenelec.eu/ \"Link zum CENELEC\") (CENELEC) und das [Europäische Institut für Telekommunikationsnormen](https://www.etsi.org/ \"Link zum ETSI\") (ETSI) sind ständige Mitglieder des Beratungsgremiums.\n\nDie Mitglieder müssen ausgewiesene Kompetenzen auf dem Gebiet der Künstlichen Intelligenz haben. Die Mandatszeit beträgt zwei Jahre und kann um höchstens vier Jahre verlängert werden. Das Advisory Forum tritt mindestens zweimal im Jahr zusammen und hat einen jährlichen Tätigkeitsbericht zu verfassen, der zu veröffentlichen ist.\n\nDem Advisory Forum kommt gemäß Art. 67 Abs. 8 AIA als Aufgabe die Erstellung von\n\n-   Stellungnahmen,\n-   Empfehlungen und\n-   Schriftliche Stellungnahmen zu.\n\nZur Bewältigung der Aufgaben können ständige oder temporäre Unterausschüsse gebildet werden.\n\nNicht zu verwechseln ist das Advisory Forum mit dem [KI-Beirat](https://www.digitalaustria.gv.at/Themen/KI/AI-Advisory-Board.html \"Link zum österreichischen KI-Beirat\") (oft auch als AI Advisory Board bezeichnet) in Österreich!",
      "keywords": [],
      "availableKeywords": [],
      "negativeKeywords": [],
      "relevantChunksIds": [],
      "parameters": []
    },
    {
      "id": "7f776c36-7b5f-47d2-b5bc-43cf3bc74d3e",
      "title": "KI-Servicestelle: Behörden & Einrichtungen",
      "content": "## Wer ist und was macht das wissenschaftliche Gremium unabhängiger Sachverständiger („Scientific Panel“)?\n\nDie Kommission wird gemäß Art. 68 Abs. 1 AIA im Wege eines Durchführungsrechtsakts ein Scientific Panel von unabhängigen Experten einrichten, das zur Unterstützung der Durchsetzungsmaßnahmen im Rahmen dieser Verordnung eingesetzt wird.\n\nDie Kommission wählt die Mitglieder auf der Grundlage aktueller wissenschaftlicher oder technischer Fachkenntnisse auf dem Gebiet der Künstlichen Intelligenz aus, die für die dem Scientific Panel übertragenen Aufgaben erforderlich sind. Die Anzahl der Mitglieder bestimmt die Kommission in Abstimmung mit dem AI Board auf Basis des erforderlichen Bedarfs. Sie nimmt bei der Bestellung auf eine ausgewogene geschlechtliche und geografische Vertretung Rücksicht.\n\nExperten müssen gemäß Art. 68 Abs. 2 AIA folgende Kriterien erfüllen:\n\n-   Besondere Sachkenntnis und Kompetenz sowie wissenschaftliches oder technisches Fachwissen auf dem Gebiet der Künstlichen Intelligenz;\n-   Unabhängigkeit von allen Anbietern von KI-Systemen oder GPAI-Modellen;\n-   Fähigkeit zur sorgfältigen, genauen und objektiven Ausführung der Tätigkeiten.\n\nDas Scientific Panel übernimmt gemäß Art. 68 Abs. 3 AIA folgende Beratungs- und Unterstützungsleistungen:\n\n-   Durchführung und Durchsetzung dieser Verordnung, vor allem in Bezug auf GPAI-Modelle, wozu im Besonderen folgende Tätigkeiten zählen:\n    -   Warnungen des AI Office vor möglichen Systemrisiken bei GPAI-Modellen auf Unionsebene;\n    -   Beitrag zur Entwicklung von Instrumenten und Methoden zur Bewertung der Fähigkeiten von GPAI-Modellen, auch durch Benchmarks;\n    -   Beratung bei der Einstufung von GPAI mit systemischem Risiko;\n    -   Beratung bei der Klassifizierung verschiedener GPAI;\n    -   Beitrag zur Entwicklung von Instrumenten und Vorlagen;\n-   Unterstützung der Arbeit der nationalen Marktaufsichtsbehörden auf deren Ersuchen;\n-   Unterstützung der grenzüberschreitenden Marktüberwachungstätigkeiten;\n-   Unterstützung des AI Office im Rahmen des „Schutzklauselverfahrens“ gemäß Art 81 AIA.\n\nDie Mitglieder des Scientific Panel erfüllen ihre Aufgaben weisungsungebunden, unparteiisch und objektiv. Sie gewährleisten die Vertraulichkeit der Informationen und Daten, die sie bei der Wahrnehmung ihrer Aufgaben und Tätigkeiten erhalten. Jedes Mitglied gibt eine Interessenerklärung ab, welche öffentlich zugänglich gemacht wird.\n\nDas AI Office führt Systeme und Verfahren ein, um potenzielle Interessenkonflikte aktiv zu bewältigen und zu verhindern.",
      "keywords": [],
      "availableKeywords": [],
      "negativeKeywords": [],
      "relevantChunksIds": [],
      "parameters": []
    },
    {
      "id": "8ce6bcf0-99b5-4801-a15c-e73a5c5355f4",
      "title": "KI-Servicestelle: Anbieterverpflichtungen",
      "content": "### Die einzelnen Akteure und deren Verpflichtungen\n\nWie im AI Act bereits in den Erwägungsgründen festgehalten wird, ist es angesichts des Wesens und der Komplexität der [KI-Wertschöpfungskette](https://www.rtr.at/rtr/service/ki-servicestelle/ai-act/akteure.de.html \"Link zu den Akteuren im AI Act\") und im Einklang mit dem neuen Rechtsrahmen von wesentlicher Bedeutung, Rechtssicherheit zu gewährleisten und die Einhaltung dieser Verordnung zu erleichtern. Daher müssen die Rollen und die spezifischen Pflichten der relevanten Akteure entlang der Wertschöpfungskette präzisiert werden. Der Kern des AI Act betrifft Verpflichtungen in Zusammenhang mit KI-Systemen bzw. KI-Modellen entsprechend ihrer Risikoklassifizierung.\n\nIn bestimmte Situationen können verschiedene Rollen der KI-Wertschöpfungskette in einer Person oder Organisation zusammenfallen. Folgende Konstellationen sind z.B. möglich:\n\n-   Ein Anbieter von KI-Modellen oder GPAI-Modellen kann gleichzeitig auch ein Anbieter eines KI-Systems sein (Art. 75 AIA).\n-   Ein Einführer kann auch die Rolle eines Händlers übernehmen (siehe Erwägungsgründe 83)",
      "keywords": [],
      "availableKeywords": [],
      "negativeKeywords": [],
      "relevantChunksIds": [],
      "parameters": []
    },
    {
      "id": "e1c5a1de-3024-4178-a191-283ad1525b65",
      "title": "KI-Servicestelle: Anbieterverpflichtungen",
      "content": "### Welche Pflichten treffen Anbieter?\n\nGanz allgemein treffen Anbieter von KI-Systemen jeder Art die Pflicht, sicherzustellen, dass eingesetztes Personal und anderen Personen, welche mit den KI-Systemen betraut sind ein ausreichendes Maß an KI-Kompetenz aufweisen (Art. 4 AIA). Das umfasst die Fähigkeiten, die Kenntnisse und das Verständnis, die es Anbietern unter Berücksichtigung ihrer jeweiligen Rechte und Pflichten im Rahmen des AI Act ermöglichen, KI-Systeme sachkundig einzusetzen sowie sich der Chancen und Risiken von KI und möglicher Schäden, die sie verursachen kann, bewusst zu werden (Art. 3 Ziffer 56 AIA).",
      "keywords": [],
      "availableKeywords": [],
      "negativeKeywords": [],
      "relevantChunksIds": [],
      "parameters": []
    },
    {
      "id": "f707c5a0-6873-4780-802e-51814906b167",
      "title": "KI-Servicestelle: Anbieterverpflichtungen",
      "content": "#### Hochrisiko-KI-Systeme\n\nDabei handelt es sich um KI-Systeme, die ein hohes Risiko aufweisen. Sie sind zwar nicht verboten, aber dafür sind zum Teil weitreichende Pflichten einzuhalten. Die Pflichten der Anbieter von Hochrisiko-KI-Systemen werden in Art. 16 AIA normiert. Zu den Pflichten zählt die Sicherstellung der Anforderungen an Hochrisiko-KI-Systeme gemäß Art. 16 Buchstabe a iVm. Kapitel III Abschnitt 2:",
      "keywords": [],
      "availableKeywords": [],
      "negativeKeywords": [],
      "relevantChunksIds": [],
      "parameters": []
    },
    {
      "id": "0d630708-202b-4ce7-84f0-930e77637a94",
      "title": "KI-Servicestelle: Anbieterverpflichtungen",
      "content": "-   Risikomanagementsystem\n    \n    Ein Risikomanagementsystem ist einzurichten, anzuwenden, zu dokumentieren und aufrechtzuerhalten (siehe Art. 9 Abs. 1 AIA). Das Risikomanagement versteht sich als ein kontinuierlicher iterativer, also sich wiederholender, Prozess während des gesamten Lebenszyklus. Den Anbieter von Hochrisiko-KI-Systeme treffen Risikobewertungs- und minderungspflichten. Bekannte und vernünftigerweise vorhersehbare Risiken in Bezug auf Gesundheit, Sicherheit oder Grundrechte sind zu ermitteln, zu analysieren und zu bewerten. Neben möglicher Risiken entsprechend der Zweckbestimmung des KI-Systems sind auch vernünftige vorhersehbare Fehlanwendungen zu bewerten. Risiken, die sich erst nach dem Inverkehrbringen, gemäß Art. 72 AIA zeigen, sind auch zu bewerten. Auf Basis der ermittelten Risiken sind „geeignete und gezielte“ Risikomanagementmaßnahmen zu ergreifen. Das Risikomanagementsystem erfordert auch, dass Hochrisiko-KI-Systeme während des gesamten Entwicklungsprozesses getestet werden (etwa durch Tests unter Realbedingungen außerhalb von KI-Reallaboren gemäß Art. 60 AIA).",
      "keywords": [],
      "availableKeywords": [],
      "negativeKeywords": [],
      "relevantChunksIds": [],
      "parameters": []
    },
    {
      "id": "9cf28dba-9ed8-4cfb-ada5-5eb80160e94e",
      "title": "KI-Servicestelle: Anbieterverpflichtungen",
      "content": "-   Daten und Daten-Governance\n    \n    KI-Systeme basieren in der Regel auf [KI-Modellen](https://www.rtr.at/rtr/service/ki-servicestelle/ai-act/risikostufen_ki-modelle.de.html \"Link zu den Risikostufen von KI-Modellen\"). Sofern die in Hochrisiko-KI-Systemen verwendeten KI-Modelle mit Daten trainiert wurden, müssen Trainings-, Validierungs- und Testdatensätze entwickelt werden, welche den Qualitätsanforderungen des Art. 10 Abs. 2 bis 5 AIA entsprechen (siehe Art. 10 Abs. 1 AIA). Unter anderem sind diese Datensätze auf Verfügbarkeit, Menge und Eignung zu bewerten, mögliche Verzerrungen sind zu prüfen (Bias), Datenlücken oder Mängel sind zu ermitteln. Datensätze haben hinreichend repräsentativ, soweit möglich fehlerfrei und vollständig zu sein. Es müssen Datensätze eingesetzt werden, die den geografischen, kontextuellen, verhaltensbezogenen oder funktionalen Rahmenbedingungen, unter denen das Hochrisiko-KI-System bestimmungsgemäß verwendet werden soll, typisch sind; z.B. autonome Fahrsysteme – diese Systeme müssen stark auf sicherheitskritische Entscheidungen vorbereitet sein und in einer breiten Palette von geografischen und kontextuellen Situationen (z. B. ungünstigen Wetterbedingungen) funktionieren.",
      "keywords": [],
      "availableKeywords": [],
      "negativeKeywords": [],
      "relevantChunksIds": [],
      "parameters": []
    },
    {
      "id": "aea615d8-72d9-4ae1-9dac-351e485258fc",
      "content": "-"
    },
    {
      "id": "65ecc4bf-ac73-4860-a566-328ac49a6c41",
      "title": "KI-Servicestelle: Anbieterverpflichtungen",
      "content": "Technische Dokumentation\n    \n    Die technische Dokumentation gemäß Art. 11 AIA ist vor [Inverkehrbringen oder Inbetriebnahme](https://www.rtr.at/rtr/service/ki-servicestelle/ai-act/akteure.de.html \"Link zu den Akteuren im AI Act\") eines Hochrisiko-KI-Systems zu erstellen. Die Mindestangaben für eine technische Dokumentation sind in Anhang IV aufgezählt. Die technische Dokumentation hat so zu erfolgen, dass daraus der Nachweis hervorgeht, dass die Anforderungen an Hochrisiko-KI-Systeme erfüllt werden. Sie muss zuständige Behörden und notifizierte Stellen in die Lage versetzen, zu beurteilen, ob das KI-System die geforderten Anforderungen erfüllt.  \n    KMU, einschließlich Start-up-Unternehmen, können die in Anhang IV aufgeführten Elemente der technischen Dokumentation in vereinfachter Weise bereitstellen.\n    \n    In Bezug auf Produkte gemäß Anhang I Abschnitt A angeführte [Harmonisierungsvorschriften](https://www.rtr.at/rtr/service/ki-servicestelle/ai-act/risikostufen_ki-systeme.de.html \"Link zu den Risikostufen der KI-Systeme\") kann eine einzige technische Dokumentation erstellt werden, die neben der allgemeinen Dokumentation auch die Erfordernisse des AI Acts abdeckt. Z.B. wird in der Medizinprodukteverordnung auch die Pflicht normiert, dass Hersteller von Produkten eine technische Dokumentation erstellen müssen (Art. 10 Abs. 4 MDR).",
      "keywords": [],
      "availableKeywords": [],
      "negativeKeywords": [],
      "relevantChunksIds": [],
      "parameters": []
    },
    {
      "id": "4de289ef-a262-4a5c-a5da-b85a80d53dc7",
      "title": "KI-Servicestelle: Anbieterverpflichtungen",
      "content": "-   Aufzeichnung von Ereignissen – „Protokollierung“\n    \n    Hochrisiko-KI-Systeme müssen technisch so konzipiert und entwickelt sein, dass sie die automatische Aufzeichnung von Ereignissen – sog „Protokollierung“ – ermöglichen (siehe Art. 12 AIA). Diese Protokollierung dient zu Dokumentationszwecken, vor allem, um zu ermitteln, ob das Hochrisiko-KI-System ein Risiko im Sinne des Art. 79 Abs. 1 AIA birgt oder eine „wesentliche Änderung“ vorgenommen wurde.\n    \n    Die in Anhang III Nummer 1 Buchstabe a AIA genannten Hochrisiko-KI-Systeme (Biometrische Fernidentifizierungssysteme) müssen besondere Protokollierungsfunktionen erfüllen.\n    \n-   Transparenz und Bereitstellung von Information für nachgelagerte Akteure\n    \n    Hochrisiko-KI-Systeme sind transparent zu konzipieren und zu entwickeln, damit [Betreiber](https://www.rtr.at/rtr/service/ki-servicestelle/ai-act/akteure.de.html#heading_Wer_ist_Betreiber_ \"Link zu den Akteuren im AI Act\") im Sinne des Art. 3 Ziffer 4 AIA die Ausgaben angemessen interpretieren und anwenden können (siehe Art. 13 AIA). Diese Pflicht umfasst im Besonderen die Erstellung einer Betriebsanleitung, die präzise, vollständige, korrekte und eindeutige Informationen für die Betreiber bereitstellt. Betriebsanleitung hat unter anderem folgende Information zu enthalten:\n    \n    -   Namen und die Kontaktangaben des Anbieters (ggf. auch Bevollmächtigter);\n    -   Merkmale, Fähigkeiten und Leistungsgrenzen des Hochrisiko-KI-Systems;\n    -   etwaige Änderungen des Hochrisiko-KI-Systems und seiner Leistung;\n    -   Maßnahmen zur Gewährleistung der menschlichen Aufsicht;\n    -   erforderlichen Rechen- und Hardware-Ressourcen etc.",
      "keywords": [],
      "availableKeywords": [],
      "negativeKeywords": [],
      "relevantChunksIds": [],
      "parameters": []
    },
    {
      "id": "23225ccc-255f-4ebf-841a-ba906dbf896d",
      "title": "KI-Servicestelle: Anbieterverpflichtungen",
      "content": "-   Menschliche Aufsicht\n    \n    Hochrisiko-KI-Systeme müssen so konzipiert und entwickelt sein, dass diese während der Dauer ihrer Verwendung von natürlichen Personen wirksam beaufsichtigt werden können (siehe Art. 14 AIA). Zweck dieser Anforderung ist, Risiken für Gesundheit, Sicherheit und Grundrechte zu verhindern oder zu minimieren, da es nicht ausgeschlossen ist, dass Risiken trotz Einhaltung aller Anforderungen des Kapitels III Abschnitt 2 fortbestehen.\n    \n    Entsprechend den Risiken, dem Grad der Autonomie und dem Kontext der Nutzung des Hochrisiko-KI-Systems sind angemessene Aufsichtsmaßnahmen zu treffen. Dies können Vorkehrungen technischer Natur sein, die in das Hochrisiko-KI-System eingebaut werden oder/und Vorkehrungen sein, die vom Betreiber umzusetzen sind.",
      "keywords": [],
      "availableKeywords": [],
      "negativeKeywords": [],
      "relevantChunksIds": [],
      "parameters": []
    },
    {
      "id": "9a15e8cd-db82-492d-8897-c2b4ef6d9039",
      "title": "KI-Servicestelle: Anbieterverpflichtungen",
      "content": "-   Genauigkeit, Robustheit und Cybersicherheit\n    \n    Hochrisiko-KI-Systeme müssen so konzipiert und entwickelt sein, dass ein angemessenes Maß an Genauigkeit, Robustheit und Cybersicherheit während des gesamten Lebenszyklus erreicht wird (siehe Art. 15 AIA).\n    \n    Die „Genauigkeit“ („Accuracy“) bezieht sich auf das Ausmaß, in dem die Vorhersagen oder Klassifizierungen eines Modells mit den tatsächlichen Daten übereinstimmen. Es ist ein Maß dafür, wie gut das Modell in der Lage ist, die richtigen Vorhersagen zu treffen.\n    \n    „Robustheit“ beschreibt die Widerstandsfähigkeit von Hochrisiko-KI-Systeme; diese müssen so widerstandsfähig wie möglich gegenüber Fehlern, Störungen oder Unstimmigkeiten sein, die innerhalb des Systems oder der Umgebung, in der das System betrieben wird, insbesondere wegen seiner Interaktion mit natürlichen Personen oder anderen Systemen, auftreten können (ErwG 75).\n    \n    „Cybersicherheit“ spielt eine entscheidende Rolle, wenn es darum geht, sicherzustellen, dass KI-Systeme widerstandsfähig gegenüber Versuchen böswilliger Dritter sind, unter Ausnutzung der Schwachstellen der Systeme deren Verwendung, Verhalten, Leistung zu verändern oder ihre Sicherheitsmerkmale zu beeinträchtigen.\n    \n    Bei den Anforderungen an Genauigkeit, Robustheit und Cybersicherheit handelt es sich großteils um technische Aspekte, weshalb diese Messungen anhand von zu entwickelnden Benchmarks und Messmethoden sichergestellt werden sollen. Neben technischen sind auch organisatorische Maßnahmen zu ergreifen.\n    \n    Als mögliche Maßnahmen werden Sicherungs- oder Störungssicherheitspläne (siehe Art. 15 Abs. 4 Unterabs. 2 AIA), Maßnahmen zur Risikominderung von sog „Rückkoppelungsschleifen“ sowie Maßnahmen (siehe Art. 15 Abs. 4 Unterabs. 3 AIA), um Angriffe, mit denen versucht wird, eine Manipulation des Trainingsdatensatzes („data poisoning“) oder vortrainierter Komponenten, die beim Training verwendet werden („model poisoning“), vorzunehmen, Eingabedaten, die das KI-Modell zu Fehlern verleiten sollen („adversarial examples“ oder „model evasions“) (siehe Art. 15 Abs. 5 AIA) werden exemplarisch genannt.\n    \n\nGem. Art. 16 Buchstabe a bis l AIA treffen den Anbieter auch noch weitere folgende Pflichten. Dabei handelt es sich nicht um Anforderungen an das Hochrisiko-KI-System selbst, sondern um „sonstige“ Pflichten.",
      "keywords": [],
      "availableKeywords": [],
      "negativeKeywords": [],
      "relevantChunksIds": [],
      "parameters": []
    },
    {
      "id": "2ef9a966-cbd1-46a6-b276-cf7bfbbff1df",
      "title": "KI-Servicestelle: Anbieterverpflichtungen",
      "content": "-   Qualitätsmanagement\n    \n    Anbieter von Hochrisiko-KI-Systemen haben ein Qualitätsmanagementsystem einzurichten, das die Einhaltung dieser Verordnung gewährleistet. Es sind Regeln, Verfahren und Anweisungen zu dokumentieren (siehe Art. 17 AIA). Dieses System hat unter anderem ein Konzept zu enthalten, wie Regulierungsvorschriften und Konformitätsbewertungsverfahren eingehalten werden sollen.",
      "keywords": [],
      "availableKeywords": [],
      "negativeKeywords": [],
      "relevantChunksIds": [],
      "parameters": []
    },
    {
      "id": "acd0edef-f67f-4d8f-9c99-76bc6ebe0092",
      "title": "KI-Servicestelle: Anbieterverpflichtungen",
      "content": "-   Kennzeichnung\n    \n    Anbieter von Hochrisiko-KI-Systemen haben am KI-System selbst oder, falls dies nicht möglich ist, auf seiner Verpackung oder beigefügten Dokumentation, ihren Namen, ihren eingetragenen Handelsnamen bzw. ihre Handelsmarke sowie ihre Kontaktanschrift anzuführen (siehe Art. 16 Buchstabe b AIA)",
      "keywords": [],
      "availableKeywords": [],
      "negativeKeywords": [],
      "relevantChunksIds": [],
      "parameters": []
    },
    {
      "id": "4052397b-e75f-463d-8380-06bb7be621a1",
      "title": "KI-Servicestelle: Anbieterverpflichtungen",
      "content": "-   Aufbewahrung von bestimmten Unterlagen und Protokollereignissen\n    \n    Für einen Zeitraum von zehn Jahren ab Inverkehrbringen oder Inbetriebnahme Dokumente wie die technische Dokumentation gemäß Art. 11 AIA, die Dokumentation im Sinne des Art. 18 AIA, Dokumentation über von den notifizierten Stellen genehmigte Änderungen, gegebenenfalls von den notifizierten Stellen ausgestellte Entscheidungen und sonstige Dokumente sowie die EU-Konformitätserklärung gemäß Art. 47 AIA aufzubewahren (siehe Art. 18 AIA).\n    \n    Für einen Zeitraum von sechs Monaten sind die automatisch erzeugten Protokolle gemäß Art. 12 Abs. 1 AIA aufzubewahren (siehe Art. 19 AIA).",
      "keywords": [],
      "availableKeywords": [],
      "negativeKeywords": [],
      "relevantChunksIds": [],
      "parameters": []
    },
    {
      "id": "006419f7-d820-4171-aa0a-bc6e78eff100",
      "title": "KI-Servicestelle: Anbieterverpflichtungen",
      "content": "-   Registrierung des KI-Systems\n    \n    Vor dem Inverkehrbringen oder der Inbetriebnahme von Hochrisiko-KI-Systemen im Sinne des Anhangs III (ausgenommen ist Ziffer 2: Kritische Infrastruktur) muss der Anbieter das Hochrisiko-KI-System in der EU-Datenbank im Sinne des Art. 71 AIA registrieren (siehe Art. 49 Abs. 1 AIA)",
      "keywords": [],
      "availableKeywords": [],
      "negativeKeywords": [],
      "relevantChunksIds": [],
      "parameters": []
    },
    {
      "id": "ee52640d-4f93-446a-9a94-aa8b1225ddb9",
      "title": "KI-Servicestelle: Anbieterverpflichtungen",
      "content": "-   Zusammenarbeit mit den zuständigen Behörden\n    \n    Auf begründete Anfrage einer zuständigen Behörde haben Anbieter von Hochrisiko-KI-Systemen sämtliche Informationen und Dokumentationen zu übermitteln, einschließlich der automatisch erzeugten Protokolle, sofern sie Zugriff darauf haben (siehe Art. 21 AIA)",
      "keywords": [],
      "availableKeywords": [],
      "negativeKeywords": [],
      "relevantChunksIds": [],
      "parameters": []
    },
    {
      "id": "be9d0595-f380-4ba4-9b06-207fb395a8e4",
      "title": "KI-Servicestelle: Anbieterverpflichtungen",
      "content": "-   Konformitätsbewertung, -erklärung, -kennzeichnung\n    \n    Der Anbieter von Hochrisiko-KI-Systemen hat sicherzustellen, dass ein Konformitätsbewertungsverfahren durchgeführt wird (Art. 43 AIA). Je nachdem um welches Hochrisiko-KI-System es sich handelt, kann dies auf Grundlage einer internen Kontrolle oder unter Beteiligung einer notifizierten Stelle erfolgen. Weiters ist eine Konformitätsbewertungserklärung auszustellen (Art. 47 AIA) und eine CE-Kennzeichnung am KI-System selbst oder, wenn dies nicht möglich ist, auf seiner Verpackung oder in der beigefügten Dokumentation anzubringen (Art. 48 AIA).",
      "keywords": [],
      "availableKeywords": [],
      "negativeKeywords": [],
      "relevantChunksIds": [],
      "parameters": []
    },
    {
      "id": "d44da4c3-33ab-48fa-85e2-f47de3562bb7",
      "title": "KI-Servicestelle: Anbieterverpflichtungen",
      "content": "-   Meldepflicht gegenüber zuständigen Behörden bei schwerwiegenden Vorfällen\n    \n    Bei schwerwiegenden Vorfällen von in Verkehr gebrachte Hochrisiko-KI-Systeme hat der Anbieter dies jener nationalen Marktüberwachungsbehörde zu melden, wo der Vorfall stattgefunden hat. Eine Meldung hat unmittelbar nach Feststellen des kausalen Zusammenhangs oder der naheliegenden Wahrscheinlichkeit, aber in jedem Fall spätestens 15 Tage nach Kenntnis des schwerwiegenden Vorfalls, zu erfolgen (siehe Art. 73 AIA). Von dieser Grundregel gibt es für bestimmte Vorfälle zeitlich engere Anforderungen.\n    \n    Von einem schwerwiegenden Vorfall sind gemäß Art. 3 Ziffer 49 AIA Vorfälle oder Fehlfunktionen gemeint, die zum Tod oder zu schweren Gesundheitsschäden führen, schwerwiegende und irreversible Störungen der Verwaltung und des Betriebs kritischer Infrastrukturen, Verstöße gegen Verpflichtungen aus dem Unionsrecht, mit denen die Grundrechte geschützt werden sollen, oder schwere Sach- oder Umweltschäden.",
      "keywords": [],
      "availableKeywords": [],
      "negativeKeywords": [],
      "relevantChunksIds": [],
      "parameters": []
    },
    {
      "id": "2d2d6ae0-e189-43c2-b5a4-ce6e409335b9",
      "content": "-"
    },
    {
      "id": "a9c29f95-f8f9-494c-bf52-f6bdc0b0b126",
      "title": "KI-Servicestelle: Anbieterverpflichtungen",
      "content": "- Sicherstellung der Barrierefreiheitsanforderungen\n    \n    Konkret sind die Barrierefreiheitsanforderungen der Richtlinien (EU) 2016/2102 und (EU) 2019/882 zu erfüllen (siehe Art. 16 Buchstabe l AIA). Gemäß Anhang I Abschnitt I der Richtlinie (EU) 2019/882 betrifft dies etwa konkrete Anforderungen an die Bereitstellung von Informationen, die Gestaltung von Benutzerschnittstellen und Funktionalität und auch Unterstützungsdienste wie z. B. Help-Desk, Call-Center etc.).",
      "keywords": [],
      "availableKeywords": [],
      "negativeKeywords": [],
      "relevantChunksIds": [],
      "parameters": []
    },
    {
      "id": "649ea5ee-b256-46c3-9332-53e42dcce5d1",
      "title": "KI-Servicestelle: Anbieterverpflichtungen",
      "content": "-   Sofern erforderlich, Benennung eines Bevollmächtigten\n    \n    In Drittstaaten niedergelassene Anbieter müssen vor der Bereitstellung des Hochrisiko-KI-Systems gemäß Art. 22 AIA einen in der Union niedergelassenen [Bevollmächtigten](https://www.rtr.at/rtr/service/ki-servicestelle/ai-act/akteure.de.html \"Link zu den Akteuren im AI Act\") benennen. Anbieter sind verpflichtet, dem Bevollmächtigten zu ermöglichen, ihre Aufgaben wahrzunehmen.",
      "keywords": [],
      "availableKeywords": [],
      "negativeKeywords": [],
      "relevantChunksIds": [],
      "parameters": []
    },
    {
      "id": "97de0d49-8dfd-445b-becb-01576d557e09",
      "title": "KI-Servicestelle: Anbieterverpflichtungen",
      "content": "-   Sofern erforderlich, Korrekturmaßnahmen (Art. 20)\n    \n    Ist ein Anbieter von Hochrisiko-KI-Systemen der Auffassung oder gibt es Grund zur Annahme, dass ein in bereits in Verkehr gebrachtes oder in Betrieb genommenes Hochrisiko-KI-System nicht dem AI Act entspricht, sind unverzüglich Korrekturmaßnahmen zu ergreifen. Dies bedeutet primär die Herstellung der Konformität, es kann aber auch das Zurücknehmen, Deaktivieren oder Zurückrufen des KI-Systems bedeuten. Gleichzeitig sind auch nachgelagerte Akteure (Betreiber, Bevollmächtigte, Einführer) davon zu informieren.\n    \n    Birgt das Hochrisiko-KI-System ein Risiko im Sinne des Art. 79 Abs 1 AIA und wird sich der Anbieter dessen bewusst, so nimmt dieser – gegebenenfalls gemeinsam mit dem Betreiber – die Meldung an die Marktüberwachungsbehörden, gegebenenfalls auch an die notifizierte Stelle vor.",
      "keywords": [],
      "availableKeywords": [],
      "negativeKeywords": [],
      "relevantChunksIds": [],
      "parameters": []
    },
    {
      "id": "020bdcf5-11bc-470e-afb9-6045f8cd50dd",
      "title": "KI-Servicestelle: Anbieterverpflichtungen",
      "content": "#### KI-Systeme mit „begrenztem“ Risiko\n\nDer AI Act listet in Art. 50 AIA bestimmte [KI-Systeme auf, welche ein begrenztes Risiko](https://www.rtr.at/rtr/service/ki-servicestelle/ai-act/risikostufen_ki-systeme.de.html \"Link zu den Risikostufen von KI-Systemen\") bergen. Das Risiko kann mittels bestimmter Transparenzpflicht minimiert werden. Zusammengefasst können sie unter die Kategorie „Transparenz gegenüber nachgelagerten Akteuren“ zusammengefasst werden.",
      "keywords": [],
      "availableKeywords": [],
      "negativeKeywords": [],
      "relevantChunksIds": [],
      "parameters": []
    },
    {
      "id": "72ebcceb-c344-4867-a793-8beee798e43b",
      "content": "Den Anbieter treffen bezüglich folgender KI-Systeme folgende Transparenzpflichten:"
    },
    {
      "id": "cba8a6f7-4035-4e48-9cde-de0d62edfa78",
      "title": "KI-Servicestelle: Anbieterverpflichtungen",
      "content": "##### KI-Systeme, welche mit natürlichen Personen direkt interagieren (z. B. Chatbots)\n\nSolche KI-Systeme sind dahingehend zu konzipieren und zu entwickeln, dass betroffene natürliche Personen darüber informiert werden, dass sie mit einem KI-System interagieren. Ausgenommen davon sind Fälle, wo dies aus den Umständen und des Kontextes der Nutzung offensichtlich ist.",
      "keywords": [],
      "availableKeywords": [],
      "negativeKeywords": [],
      "relevantChunksIds": [],
      "parameters": []
    },
    {
      "id": "4e59e48e-bfc6-4ccc-9979-12ba3220dcec",
      "title": "KI-Servicestelle: Anbieterverpflichtungen",
      "content": "##### KI-Systeme, die Bild-, Audio- oder Videoinhalte erzeugen oder manipulieren (z. B. Deepfakes)\n\nKI-Systeme (einschließlich GPAI-Systeme), welche Bild-, Audio- oder Videoinhalte erzeugen oder manipulieren, sind so zu konzipieren und zu entwickeln, dass die Ausgaben in einem maschinenlesbaren Format ausgegeben und als künstlich erzeugt oder manipuliert erkannt werden können.",
      "keywords": [],
      "availableKeywords": [],
      "negativeKeywords": [],
      "relevantChunksIds": [],
      "parameters": []
    },
    {
      "id": "5841b6df-de62-452c-8a19-f2b6391feb5d",
      "title": "KI-Servicestelle: Anbieterverpflichtungen",
      "content": "##### KI-Systeme mit „minimalem“ Risiko\n\nBei [KI-Systemen mit minimalem Risiko](https://www.rtr.at/rtr/service/ki-servicestelle/ai-act/risikostufen_ki-systeme.de.html \"Link zu den Risikostufen von KI-Systemen\") werden keine verpflichtend einzuhaltenden Anforderungen normiert. Lediglich die Verpflichtung zur „KI-Kompetenz“ gemäß Art. 4 AIA trifft auch auf solche KI-Systeme zu. Im Übrigen wird die Einhaltung von Code of Practices gefördert, diese ist aber freiwillig.",
      "keywords": [],
      "availableKeywords": [],
      "negativeKeywords": [],
      "relevantChunksIds": [],
      "parameters": []
    },
    {
      "id": "e1e7c9bf-8ea9-4f53-b992-2b285f12dfdf",
      "content": "#### GPAI-Modelle\n\nHandelt es sich um GPAI-Modelle haben Anbieter gemäß Art. 53, 54 AIA folgende Pflichten zu erfüllen:"
    },
    {
      "id": "74f0a1e0-89f6-47f5-b65e-8fc4327d62d7",
      "title": "KI-Servicestelle: Anbieterverpflichtungen",
      "content": "-   Technische Dokumentation\n    \n    Anbieter von GPAI-Modellen erstellen und aktualisieren die technische Dokumentation des Modells, einschließlich seines Trainings- und Testverfahrens und der Ergebnisse seiner Bewertung, die mindestens die in Anhang XI aufgeführten Informationen enthält (Art. 53 Abs. 1 Buchstabe a Satz 1 AIA).\n    \n    Diese Verpflichtung gilt nicht für Anbieter von ausgenommenen Open-Source-Modellen im Sinne des Art. 2 Abs. 12 AIA, ausgenommen es handelt sich um ein GPAI-Modell mit systemischem Risiko.",
      "keywords": [],
      "availableKeywords": [],
      "negativeKeywords": [],
      "relevantChunksIds": [],
      "parameters": []
    },
    {
      "id": "3960ac09-8d97-4baf-a897-eac5f554a03e",
      "title": "KI-Servicestelle: Anbieterverpflichtungen",
      "content": "-   Zusammenarbeit mit den zuständigen Behörden\n    \n    Auf Anfrage einer zuständigen Behörde bzw. des AI Office haben Anbieter von GPAI-Modellen die oben bezeichnete technische Dokumentation zur Verfügung zu stellen (Art. 53 Abs. 1 Buchstabe a Satz 2 AIA).\n    \n    Ganz allgemein gilt, dass Anbieter von GPAI-Modellen „bei der Ausübung ihrer Zuständigkeiten und Befugnisse gemäß dieser Verordnung“ mit den zuständigen nationalen Behörden, erforderlichenfalls auch mit der Kommission, zusammenzuarbeiten haben (siehe Art. 53 Abs. 3 AIA).",
      "keywords": [],
      "availableKeywords": [],
      "negativeKeywords": [],
      "relevantChunksIds": [],
      "parameters": []
    },
    {
      "id": "00c8f4c7-c9c8-4a8d-8c17-5bb005aeb14b",
      "title": "KI-Servicestelle: Anbieterverpflichtungen",
      "content": "-   Transparenz und Bereitstellung von Information für Anbieter von KI-Systemen\n    \n    Anbieter von GPAI-Modellen haben für nachgelagerte Anbieter von KI-Systemen, die beabsichtigen dieses Modell in ihre KI-Systeme zu integrieren, bestimmte Informationen und Dokumentationen zu erstellen und aktualisieren sowie den Anbietern von KI-Systemen zur Verfügung stellen. Die technische Dokumentation hat die in Anhang XII genannten Mindestangaben zu erfüllen.\n    \n    Diese Informationen und Dokumentation muss Anbieter von KI-Systemen in die Lage versetzen, die Fähigkeiten und die Grenzen des GPAI-Modells „gut zu verstehen“ und sie auch befähigen, dass sie ihren Pflichten des AI Act nachkommen können (Art. 53 Abs. 1 Buchstabe b AIA)\n    \n    Diese Verpflichtung gilt nicht für Anbieter von ausgenommenen Open-Source-Modellen im Sinne des Art. 2 Abs. 12 AIA, ausgenommen es handelt sich um ein GPAI-Modell mit systemischem Risiko.",
      "keywords": [],
      "availableKeywords": [],
      "negativeKeywords": [],
      "relevantChunksIds": [],
      "parameters": []
    },
    {
      "id": "92de995d-6ec6-4518-aefe-5e81d76b7db3",
      "title": "KI-Servicestelle: Anbieterverpflichtungen",
      "content": "-   Strategie zur Einhaltung des EU-Urheberrechts\n    \n    Anbieter von GPAI-Modellen haben eine Strategie zur Einhaltung des EU-Urheberrechts samt damit zusammenhängender Rechte auch durch modernste Technologien vorzubringen. Das schließt im Besonderen die Ermittlung und Einhaltung eines gemäß Art. 4 Abs. 3 Urheberrechterichtlinie geltend gemachten Rechtsvorbehalts ein (siehe Art. 53 Abs. 1 Buchstabe c AIA).\n    \n    Anmerkung: Mit Art. 3 Urheberrechterichtlinie ([Richtlinie (EU) 2019/790](https://eur-lex.europa.eu/legal-content/DE/TXT/PDF/?uri=CELEX:32019L0790 \"Link zur Urheberrechterichtlinie\")) wird normiert, dass Text- und Data Mining („TDM“) grundsätzlich betrieben werden darf. Dieses Recht kann durch einen Vorbehalt der Rechteinhaber gemäß Art. 4 Abs. 3 Urheberrechterichtlinie aber derart eingeschränkt werden, sodass nur mehr Forschungseinrichtungen und Einrichtungen des Kulturerbes TDM zulässig betreiben können.\n    \n    Bei TDM handelt es sich um einen Sammelbegriff für verschiedene Verfahren, die es ermöglichen, große Mengen von Texten oder Daten unter verschiedenen Aspekten zu durchsuchen und auszuwerten. In Österreich ist dies in [§ 42h UrhG](https://www.ris.bka.gv.at/GeltendeFassung.wxe?Abfrage=Bundesnormen&Gesetzesnummer=10001848 \"Link zum österreichischen Urheberrechtsgesetz\") umgesetzt. Ferner sind die für das Training des GPAI-Modells verwendeten Inhalte nach einer vom AI Office bereitgestellten Vorlage zur veröffentlichen (siehe Art. 53 Abs. 1 Buchstabe d AIA).",
      "keywords": [],
      "availableKeywords": [],
      "negativeKeywords": [],
      "relevantChunksIds": [],
      "parameters": []
    },
    {
      "id": "8380352c-9c45-4369-b85f-2458cb560103",
      "title": "KI-Servicestelle: Anbieterverpflichtungen",
      "content": "-   Benennung eines Bevollmächtigten\n    \n    Ist der Anbieter eines GPAI-Modells in einem Drittstaat niedergelassen, ist der Anbieter verpflichtet, vor Inverkehrbringen des Modells einen Bevollmächtigten innerhalb der Union zu benennen (siehe Art. 54 AIA).",
      "keywords": [],
      "availableKeywords": [],
      "negativeKeywords": [],
      "relevantChunksIds": [],
      "parameters": []
    },
    {
      "id": "7d2ce9a7-cb03-4c28-aaa2-28e0f63262bf",
      "title": "KI-Servicestelle: Anbieterverpflichtungen",
      "content": "#### GPAI-Modelle mit systemischem Risiko\n\nHandelt es sich beim GPAI-Modell um ein solches mit systemischem Risiko haben Anbieter zusätzlich zu den in Art. 53 und 54 AIA genannten Pflichten auch jene des Art. 55 AIA zu erfüllen:\n\n-   Risikomanagement\n    \n    Unter dem Titel „Risikomanagement“ können die Pflichten gemäß Art. 55 Abs. 1 Buchstabe a und b zusammengefasst werden. Demnach haben Anbieter von GPAI-Modellen eine Modellevaluierung nach standardisierten Protokollen und Instrumenten vorzunehmen. Dies umfasst auch die Durchführung und Dokumentation von Angriffstest, um systemische Risiken zu ermitteln und zu mindern. Darüber hinaus sind ganz generell mögliche systemische Risiken auf Unionsebene – einschließlich ihrer Ursachen –, die sich aus der Entwicklung, dem Inverkehrbringen oder der Verwendung von GPAI-Modellen mit systemischem Risiko ergeben können, zu bewerten und zu mindern.\n    \n-   Meldepflicht gegenüber zuständigen Behörden bei schwerwiegenden Vorfällen\n    \n    Schwerwiegende Vorfälle sind zu dokumentieren und unverzüglich ans AI Office und gegebenenfalls an die zuständigen nationalen Behörden zu melden.\n    \n-   Cybersicherheit\n    \n    Anbieter von GPAI-Modellen haben ein „angemessenes Maß“ an Cybersicherheit und die physische Infrastruktur des Modells zu gewährleisten (siehe Art. 55 Abs. 1 Buchstabe d AIA). Beim Schutz der Cybersicherheit im Zusammenhang mit systemischen Risiken, die mit böswilliger Nutzung oder böswilligen Angriffen verbunden sind, sollte der unbeabsichtigte Modelldatenverlust, die unerlaubte Bereitstellung, die Umgehung von Sicherheitsmaßnahmen und der Schutz vor Cyberangriffen, unbefugtem Zugriff oder Modelldiebstahl gebührend beachtet werden.\n    \n    Dieser Schutz könnte durch die Sicherung von Modellgewichten, Algorithmen, Servern und Datensätzen erleichtert werden, z. B. durch Betriebssicherheitsmaßnahmen für die Informationssicherheit, spezifische Cybersicherheitsstrategien, geeignete technische und etablierte Lösungen sowie Kontrollen des physischen Zugangs und des Cyberzugangs, die den jeweiligen Umständen und den damit verbundenen Risiken angemessen sind (siehe Erwägungsgründe 115).",
      "keywords": [],
      "availableKeywords": [],
      "negativeKeywords": [],
      "relevantChunksIds": [],
      "parameters": []
    },
    {
      "id": "856e2b50-28e3-4e59-afb8-e0b942ae265d",
      "title": "KI-Servicestelle: Anbieterverpflichtungen",
      "content": "### Welche Pflichten treffen Produkthersteller?\n\nBei Hochrisiko-KI-Systemen, bei denen es sich um Sicherheitsbauteil von Produkten handelt, die unter die in Anhang I Abschnitt A aufgeführten Harmonisierungsrechtsvorschriften der Union fallen, gilt gemäß Art. 25 Abs. 3 AIA der Produkthersteller als Anbieter des Hochrisiko-KI-Systems und unterliegt in den beiden nachfolgenden Fällen den Pflichten eines Anbieter gemäß Art. 16 AIA:\n\n-   Das Hochrisiko-KI-System wird zusammen mit dem Produkt unter dem Namen oder der Handelsmarke des Produktherstellers in Verkehr gebracht;\n-   das Hochrisiko-KI-System wird unter dem Namen oder der Handelsmarke des Produktherstellers in Betrieb genommen, nachdem das Produkt in Verkehr gebracht wurde\n",
      "keywords": [],
      "availableKeywords": [],
      "negativeKeywords": [],
      "relevantChunksIds": [],
      "parameters": []
    },
    {
      "id": "268f2a84-8cd3-49f7-9690-f547936af47a",
      "title": "KI-Servicestelle: Betreiberverpflichtungen",
      "content": "### Welche Verpflichtungen treffen Betreiber?\n\nGenauso wie Anbieter, sind auch die Betreiber von KI-Systemen \nverpflichtet, bei der Verwendung jeder Art von KI-Systemen \nsicherzustellen, dass eingesetztes Personal und andere Personen, welche \nmit den KI-Systemen betraut sind ein ausreichendes Maß an KI-Kompetenz \naufweisen (Art. 4 iVm. Art. 3 Ziffer 56 AIA).",
      "keywords": [],
      "availableKeywords": [],
      "negativeKeywords": [],
      "relevantChunksIds": [],
      "parameters": []
    },
    {
      "id": "2b4e2670-f415-4bb2-ae30-8e1951e9f535",
      "title": "KI-Servicestelle: Betreiberverpflichtungen",
      "content": "#### Hochrisiko-KI-Systeme\n\nDie Pflichten der Betreiber von Hochrisiko-KI-Systemen werden in Art. 26 AIA geregelt. Folgende Verpflichtungen sind dabei einzuhalten:",
      "keywords": [],
      "availableKeywords": [],
      "negativeKeywords": [],
      "relevantChunksIds": [],
      "parameters": []
    },
    {
      "id": "725eccf5-6895-43c3-bd02-fd28a674168f",
      "title": "KI-Servicestelle: Betreiberverpflichtungen",
      "content": "-   Verwendung des Hochrisiko-KI-Systems laut Betriebsanleitung\n    \n    Anbieter haben gemäß Art. 13 Abs. 2 AIA eine Betriebsanleitung bereitzustellen und den Betreibern zur Verfügung zu stellen. Betreiber von Hochrisiko-KI-Systemen haben die erforderlichen technischen und organisatorischen Maßnahmen zu treffen, um sicherzustellen, dass Hochrisiko-KI-Systemen entsprechend der beigefügten Betriebsanleitung verwendet wird (siehe Art. 26 Abs. 1 AIA).\n    \n    Sofern die Betreiber die Kontrolle über Eingabedaten haben, müssen diese der Zweckbestimmung des Hochrisiko-KI-Systems entsprechen und müssen ausreichend repräsentativ sein (siehe Art. 26 Abs. 4 AIA).\n    \n    Davon bleiben sonstige Pflichten des Betreibers nach dem Unionsrecht oder nationalem Recht unberührt (siehe Art. 26 Abs. 3 AIA).",
      "keywords": [],
      "availableKeywords": [],
      "negativeKeywords": [],
      "relevantChunksIds": [],
      "parameters": []
    },
    {
      "id": "2629f5ca-f950-440a-96be-44e71d8d2a85",
      "title": "KI-Servicestelle: Betreiberverpflichtungen",
      "content": "-   Menschliche Aufsicht\n    \n    Für die grundsätzliche Implementierung menschlicher Überwachungstools sind die Anbieter zuständig (siehe Art. 16 Buchstabe a iVm Art. 14 AIA), die Betreiber sind in der Folge verpflichtet, natürlichen Personen, die über die erforderliche Kompetenz, Ausbildung und Befugnis verfügen, die menschliche Aufsicht zu übertragen (siehe Art. 26 Abs. 2 AIA). Betreiber sind auch verpflichtet, diesen natürlichen Personen die erforderliche Unterstützung zukommen zu lassen.\n    \n    Davon bleiben sonstige Pflichten des Betreibers nach dem Unionsrecht oder nationalem Recht unberührt (siehe Art. 26 Abs. 3).",
      "keywords": [],
      "availableKeywords": [],
      "negativeKeywords": [],
      "relevantChunksIds": [],
      "parameters": []
    },
    {
      "id": "7dd66929-d63c-4bac-bec0-a41ec1644573",
      "title": "KI-Servicestelle: Betreiberverpflichtungen",
      "content": "-   Überwachung des KI-Systems\n    \n    Gemäß Art. 26 Abs. 5 UAbs. 1 AIA haben die Betreiber den Betrieb des eingesetzten Hochrisiko-KI-Systems anhand der beigefügten Betriebsanleitung zu überwachen und informieren ggf. Anbieter gemäß Art. 72 AIA („Beobachtung nach dem Inverkehrbringen“).\n    \n    Für Betreiber, die Finanzinstitute sind und den einschlägigen Rechtsvorschriften über Finanzdienstleistungen unterliegen, gelten die Anforderungen über Regelungen, Verfahren oder Mechanismen der internen Unternehmensführung (siehe Art. 26 Abs. 5 Uabs. 2 AIA).",
      "keywords": [],
      "availableKeywords": [],
      "negativeKeywords": [],
      "relevantChunksIds": [],
      "parameters": []
    },
    {
      "id": "c7c652b8-5799-4a4c-b21d-63f64e0323c2",
      "content": "-"
    },
    {
      "id": "2b42aac4-945f-40fb-9f90-7cee39dbbc74",
      "title": "KI-Servicestelle: Betreiberverpflichtungen",
      "content": "Meldung von schwerwiegenden Vorfällen\n    \n    Gibt es Grund zur Annahme, dass das Hochrisiko-KI-System ein Risiko im Sinne des Art. 79 AIA birgt, oder wurde ein schwerwiegender Vorfall festgestellt, treffen den Betreiber Berichtspflichten gegenüber dem Anbieter, Einführer/Händler sowie die zuständigen Marktüberwachungsbehörden (siehe Art. 26 Abs. 5 UAbs. 1 AIA).\n    \n    Wenn Grund zur Annahme besteht, dass ein Hochrisiko-KI-System ein Risiko im Sinne des Art. 79 Abs. 1 birgt, ist von der Verwendung abzusehen.",
      "keywords": [],
      "availableKeywords": [],
      "negativeKeywords": [],
      "relevantChunksIds": [],
      "parameters": []
    },
    {
      "id": "e3e8d669-8420-4865-9fd8-0ad760b09242",
      "title": "KI-Servicestelle: Betreiberverpflichtungen",
      "content": "-   Aufbewahrung von erzeugten Protokollen\n    \n    Betreiber haben die automatisch erzeugten Protokolle von Hochrisiko-KI-Systeme für mindestens 6 Monate (ausgenommen das geltende Unionsrecht wie z.B. die DSGVO bestimmen etwas anderes) aufzubewahren, sofern diese unter ihrer Kontrolle liegen (siehe Art. 26 Abs. 6 UAbs. 1 AIA).\n    \n    Betreiber, die Finanzinstitute sind und den einschlägigen Rechtsvorschriften über Finanzdienstleistungen unterliegen, haben die Protokolle als Teil dieser Anforderungen aufzubewahren (siehe Art. 26 Abs. 6 UAbs. 2 AIA).",
      "keywords": [],
      "availableKeywords": [],
      "negativeKeywords": [],
      "relevantChunksIds": [],
      "parameters": []
    },
    {
      "id": "fb82ef44-9f09-40c7-bad5-4656bebeb483",
      "title": "KI-Servicestelle: Betreiberverpflichtungen",
      "content": "-   Sofern relevant, Datenschutz-Folgenabschätzung gemäß Art. 35 DSGVO\n    \n    Betreiber von Hochrisiko-KI-Systemen verwenden ggf. die gemäß Art. 13 AIA von den Anbietern bereitgestellten Informationen („Betriebsanleitungen“), um ihrer Pflicht zur Durchführung einer Datenschutz-Folgenabschätzung gemäß Art. 35 der DSGVO oder Artikel 27 der Richtlinie (EU) 2016/680 nachzukommen (siehe Art. 26 Abs. 9).",
      "keywords": [],
      "availableKeywords": [],
      "negativeKeywords": [],
      "relevantChunksIds": [],
      "parameters": []
    },
    {
      "id": "44e0a04a-089c-40ec-a3bc-86f4015339f3",
      "title": "KI-Servicestelle: Betreiberverpflichtungen",
      "content": "-   Zusammenarbeit mit zuständigen nationalen Behörden\n    \n    Gemäß Art. 26 Abs. 12 AIA arbeiten die Betreiber mit den zuständigen Behörden bei allen Maßnahmen zusammen, die diese im Zusammenhang mit dem Hochrisiko-KI-System zur Umsetzung des AIA ergreifen.",
      "keywords": [],
      "availableKeywords": [],
      "negativeKeywords": [],
      "relevantChunksIds": [],
      "parameters": []
    },
    {
      "id": "0a86d1c5-9a31-4783-842f-6086786f0867",
      "title": "KI-Servicestelle: Betreiberverpflichtungen",
      "content": "-   Transparenz gegenüber nachgelagerten Akteuren\n    \n    Beim Einsatz von Hochrisiko-KI-Systemen gemäß Anhang III sind natürliche Personen gemäß Art. 26 Abs. 11 AIA, die von einer Entscheidung betroffen sind oder bei solchen Entscheidungen, wo das besagte KI-System Unterstützung leistet, über die Verwendung des Hochrisiko-KI-Systems zu informieren. Im Rahmen der Strafverfolgung gilt Art. 13 Richtlinie 2016/680. Das betrifft etwa KI-Systeme, die bei der Zulassung zu Bildungseinrichtungen oder der Filterung von Bewerber:innen bei Stellenanzeigen eingesetzt werden.\n    \n    Diese Pflichten gelten unbeschadet der Transparenzpflichten gemäß Art. 50 AIA.",
      "keywords": [],
      "availableKeywords": [],
      "negativeKeywords": [],
      "relevantChunksIds": [],
      "parameters": []
    },
    {
      "id": "7b61393c-3edc-4b21-a63a-67ef711aa4bb",
      "title": "KI-Servicestelle: Betreiberverpflichtungen",
      "content": "-   Recht auf Erläuterung der Entscheidungsfindung im Einzelfall\n    \n    Gemäß Art. 86 AIA haben Personen, die von einer Entscheidung betroffen sind, die der Betreiber auf der Grundlage der Ausgaben eines in Anhang III aufgeführten Hochrisiko-KI-Systems (ausgenommen Nummer 2: Kritische Infrastruktur) getroffen hat und die rechtliche Auswirkungen hat oder sie in ähnlicher Art erheblich auf eine Weise beeinträchtigt, die ihrer Ansicht nach ihre Gesundheit, ihre Sicherheit oder ihre Grundrechte beeinträchtigt, haben das Recht, vom Betreiber eine klare und aussagekräftige Erläuterung zur Rolle des KI-Systems im Entscheidungsprozess und zu den wichtigsten Elementen der getroffenen Entscheidung zu erhalten.",
      "keywords": [],
      "availableKeywords": [],
      "negativeKeywords": [],
      "relevantChunksIds": [],
      "parameters": []
    },
    {
      "id": "f7521e56-add5-4d83-a21e-e9c641ccf8d8",
      "title": "KI-Servicestelle: Betreiberverpflichtungen",
      "content": "Folgende Pflichten treffen nur bestimmte Betreiber beim Einsatz spezifischer Hochrisiko-KI-Systeme:\n\n-   Sofern Arbeitgeber, der Hochrisiko-KI-Systeme am Arbeitsplatz einsetzt: Informationspflichten gegenüber der Arbeiternehmervertretung\n    \n    Arbeitgeber informieren neben den betroffenen Arbeitnehmer:innen auch die Arbeitnehmervertretung vor Inbetriebnahme oder Verwendung eines Hochrisiko-KI-Systems am Arbeitsplatz über den geplanten Einsatz eines solchen KI-Systems (siehe Art. 26 Abs. 7). Gemäß Anhang III Ziffer 4 Buchstabe a und b AIA zählen hierunter KI-Systeme die bestimmungsgemäß für die Einstellung oder Auswahl natürlicher Personen verwendet werden sollen, insbesondere um gezielte Stellenanzeigen zu schalten, Bewerbungen zu sichten oder zu filtern und Bewerber zu bewerten sowie KI-Systeme, die bestimmungsgemäß für Entscheidungen, die die Bedingungen von Arbeitsverhältnissen, Beförderungen und Kündigungen von Arbeitsvertragsverhältnissen beeinflussen, für die Zuweisung von Aufgaben aufgrund des individuellen Verhaltens oder persönlicher Merkmale oder Eigenschaften oder für die Beobachtung und Bewertung der Leistung und des Verhaltens von Personen in solchen Beschäftigungsverhältnissen verwendet werden soll.",
      "keywords": [],
      "availableKeywords": [],
      "negativeKeywords": [],
      "relevantChunksIds": [],
      "parameters": []
    },
    {
      "id": "e3612b37-75ae-4a48-a2d5-0c86a8d41255",
      "title": "KI-Servicestelle: Betreiberverpflichtungen",
      "content": "-   Sofern EU-Organe, EU-Einrichtungen und sonstige EU-Stellen Betreiber sind: Registrierungspflicht\n    \n    EU-Organe, -Einrichtungen und sonstige Stellen der Union, welche Betreiber von Hochrisiko-KI-Systemen sind, müssen das verwendete KI-System gemäß Art. 49 AIA registrieren (siehe Art. 26 Abs. 8 AIA). Sofern das zur Verwendung geplante Hochrisiko-KI-System nicht in der in Art. 71 genannten EU-Datenbank registriert ist, sehen sie von der Verwendung ab und informieren auch den Anbieter oder Händler hierüber.",
      "keywords": [],
      "availableKeywords": [],
      "negativeKeywords": [],
      "relevantChunksIds": [],
      "parameters": []
    },
    {
      "id": "455a7f0e-e6cf-4241-892f-098bec6464d2",
      "title": "KI-Servicestelle: Betreiberverpflichtungen",
      "content": "-   Sofern Einsatz zur nachträglichen biometrischen Fernidentifizierung: Genehmigungspflicht einer Justiz- oder Verwaltungsbehörde\n    \n    Setzen Betreiber (also Strafverfolgungsbehörden) Hochrisiko-KI-Systeme zur nachträglichen biometrischen Fernidentifizierung im Rahmen von Ermittlungen zur gezielten Suche einer Person, die der Begehung einer Straftat verdächtigt wird oder aufgrund einer solchen verurteilt wurde, haben diese gemäß Art. 26 Abs. 10 AIA eine Genehmigung vorab oder unverzüglich, spätestens binnen 48 Stunden bei einer Justiz- oder Verwaltungsbehörde einzuholen, die einer justiziellen Überprüfung unterliegt. Wird die beantragte Genehmigung abgelehnt, ist die Verwendung des besagten Hochrisiko-KI-Systems mit sofortiger Wirkung einzustellen und etwaige personenbezogene Daten, die im Zusammenhang mit der Verwendung dieses Systems stehen, sind zu löschen. Jede Verwendung solcher Hochrisiko-KI-Systeme ist in der einschlägigen Polizeiakte zu dokumentieren und der zuständigen Marktüberwachungsbehörde und der nationalen Datenschutzbehörde (ausgenommen sensible operative Daten) auf Anfrage zur Verfügung zu stellen. Den genannten Behörden sind auch Jahresberichte vorzulegen.\n    \n    Der Einsatz von solchen KI-Systemen in nicht zielgerichteter Weise und ohne jeglichen Zusammenhang mit einer Straftat oder der Suche nach einer bestimmten vermissten Person sind untersagt.\n    \n    Ausgenommen davon ist die erstmalige Identifizierung eines potenziellen Verdächtigen auf der Grundlage objektiver und nachprüfbarer Tatsachen, die in unmittelbarem Zusammenhang mit der Straftat stehen.\n    \n    Den Mitgliedstaaten bleibt es unbenommen, strengere Rechtsvorschriften für die Verwendung von KI-Systemen zur nachträglichen biometrischen Fernidentifizierung zu erlassen.\n    \n    Unberührt bleibt von diesem Artikel die Anwendung der Richtlinie (EU) 2016/680.",
      "keywords": [],
      "availableKeywords": [],
      "negativeKeywords": [],
      "relevantChunksIds": [],
      "parameters": []
    },
    {
      "id": "9cf8614f-614f-4a97-a52f-93a37e60c327",
      "title": "KI-Servicestelle: Betreiberverpflichtungen",
      "content": "-   Sofern öffentliche und private Einrichtungen, welche öffentliche Dienste erbringen/teilweise private Institutionen: Erstellung einer Grundrechte-Folgenabschätzung\n    \n    Gemäß Art. 27 AIA haben Einrichtungen des öffentlichen Rechts und private Einrichtungen, welche öffentliche Dienste erbringen, beim Einsatz (gilt für die erste Verwendung) eines Hochrisiko-KI-Systems gemäß Art. 6 Abs. 2 iVm. Annex III (ausgenommen Ziffer 2: Kritische Infrastruktur) und Betreiber von Hochrisiko-KI-Systemen beim Einsatz von Hochrisiko-KI-Systemen gemäß Anhang III Nummer 5 Buchstaben b (Kreditwürdigkeitsprüfung und Bonitätsbewertung natürlicher Personen) und c (Risikobewertung und Preisbildung in Bezug auf natürliche Personen im Fall von Lebens- und Krankenversicherungen) eine Grundrechte-Folgenabschätzung vorzunehmen.\n    \n    Folgende Aspekte sind dabei zu berücksichtigen:\n    \n    -   eine Beschreibung der Verfahren des Betreibers, bei denen das Hochrisiko-KI-System im Einklang mit seiner Zweckbestimmung verwendet wird;\n    -   eine Beschreibung des Zeitraums und der Häufigkeit, innerhalb dessen bzw. mit der jedes Hochrisiko-KI-System verwendet werden soll;\n    -   die Kategorien der natürlichen Personen und Personengruppen, die von seiner Verwendung im spezifischen Kontext betroffen sein könnten;\n    -   die spezifischen Schadensrisiken, die sich auf die gemäß Buchstabe c dieses Absatzes ermittelten Kategorien natürlicher Personen oder Personengruppen auswirken könnten, unter Berücksichtigung der vom Anbieter gemäß Artikel 13 bereitgestellten Informationen;\n    -   eine Beschreibung der Umsetzung von Maßnahmen der menschlichen Aufsicht entsprechend den Betriebsanleitungen;\n    -   die Maßnahmen, die im Falle des Eintretens dieser Risiken zu ergreifen sind, einschließlich der Regelungen für die interne Unternehmensführung und Beschwerdemechanismen.\n    \n    Sofern diese Pflichten bereits mit der Datenschutz-Folgenabschätzung gemäß Art. 35 DSGVO oder Art. 27 der Richtlinie (EU) 2016/680 abgedeckt sind, so ergänzt die Grundrechte- die Datenschutz-Folgenabschätzung im Sinne des AIA.",
      "keywords": [],
      "availableKeywords": [],
      "negativeKeywords": [],
      "relevantChunksIds": [],
      "parameters": []
    },
    {
      "id": "b48bb3d6-986f-4161-a486-48216c35347a",
      "title": "KI-Servicestelle: Betreiberverpflichtungen",
      "content": "#### KI-Systeme mit „begrenztem“ Risiko\n\nIn Art 50 AIA werden bestimmte KI-Systeme aufgelistet, welche ein begrenztes Risiko bergen, da das Risiko mittels bestimmter Transparenzpflichten minimiert werden kann. Die Betreiber treffen bei folgenden KI-Systemen folgende Transparenzpflichten:\n\n-   Emotionserkennungssysteme oder KI-Systeme zur biometrischen Kategorisierung\n    \n    Unberührt von anderen Transparenzpflichten, welche aus dem Unionsrecht oder dem nationalen Recht resultieren, sind betroffene Personen über den Betrieb eines Emotionserkennungssystems oder eines KI-Systems zur biometrischen Kategorisierung zu informieren (siehe Art. 50 Abs. 3 AIA). Personenbezogene Daten dürfen nur im Einklang mit den Datenschutzbestimmungen verarbeitet werden. Ausgenommen sind zugelassene KI-Systeme, zur Aufdeckung, Verhütung und Ermittlung von Straftaten, sofern geeignete Schutzvorkehrungen für die Rechte und Freiheiten Dritter bestehen.\n    \n    Die Information ist spätestens zum Zeitpunkt der ersten Interaktion oder Aussetzung in klarer und eindeutiger Weise bereitzustellen und müssen den geltenden Barrierefreiheitsanforderungen entsprechen (siehe Art. 50 Abs. 5 AIA).",
      "keywords": [],
      "availableKeywords": [],
      "negativeKeywords": [],
      "relevantChunksIds": [],
      "parameters": []
    },
    {
      "id": "16b18429-94ae-4d83-80ed-907e2e552fe5",
      "title": "KI-Servicestelle: Betreiberverpflichtungen",
      "content": "-   KI-Systeme, die Text-, Bild-, Ton- oder Videoinhalte erzeugen oder manipulieren\n    \n    Unberührt von anderen unionsrechtlichen oder nationalen Transparenzpflichten, müssen Betreiber eines KI-Systems, das Textinhalte erzeugt oder manipuliert oder/und Bild-, Ton- oder Videoinhalte erzeugt oder manipuliert, die ein Deep-Fake sind, gemäß Art. 50 Abs. 4 AIA offenlegen, dass die Inhalte künstlich erzeugt oder manipuliert wurden. Ausgenommen ist die Verwendung zur Aufdeckung, Verhütung, Ermittlung und Verfolgung von Straftaten.\n    \n    Ein „Deep Fake“ im Sinne des AI Acts ist ein durch ein KI erzeugter oder manipulierter Bild-, Ton- oder Videoinhalt, der wirklichen Personen, Gegenständen, Orten, Einrichtungen oder Ereignissen ähnelt und einer Person fälschlicherweise als echt oder wahrheitsgemäß erscheinen würde (siehe Art. 3 Ziffer 60 AIA).\n    \n    Ist offensichtlich, dass der künstlich erzeugte oder manipulierte Bild-, Ton- oder Videoinhalt Teil eines künstlerischen, kreativen, satirischen, fiktionalen oder analogen Werks oder Programms ist, beschränkt sich die Transparenzpflicht darauf, das Vorhandensein von künstlich erzeugten und manipulierten Inhalten derart offenzulegen, dass die Darstellung oder der Genuss des Werkes nicht beeinträchtigt wird.\n    \n    Bei erzeugten und manipulierten Texten gelten die Transparenzpflichten nicht, wenn dieser Text von einem Menschen überprüft wurde und es einen redaktionellen Verantwortlichen gibt.\n    \n    Die Information ist spätestens zum Zeitpunkt der ersten Interaktion oder Aussetzung in klarer und eindeutiger Weise bereitzustellen und müssen den geltenden Barrierefreiheitsanforderungen entsprechen (siehe Art. 50 Abs. 5 AIA).\n    \n    Lesen Sie mehr zu den [Transparenzpflichten](https://www.rtr.at/rtr/service/ki-servicestelle/ai-act/Transparenzpflichten.de.html)!",
      "keywords": [],
      "availableKeywords": [],
      "negativeKeywords": [],
      "relevantChunksIds": [],
      "parameters": []
    },
    {
      "id": "16c7a4da-0919-4e73-a3ee-bfa65bc49748",
      "title": "KI-Servicestelle: Betreiberverpflichtungen",
      "content": "#### KI-Systeme mit „minimalem Risiko“\n\nBei KI-Systemen mit „minimalem“ Risiko werden keine verpflichtend einzuhaltenden Anforderungen gestellt. Lediglich die Verpflichtung zur „KI-Kompetenz“ gemäß Art. 4 AIA trifft auch auf solche KI-Systeme zu. Die Einhaltung von Code of Practices wird gefördert, aber ist freiwillig.",
      "keywords": [],
      "availableKeywords": [],
      "negativeKeywords": [],
      "relevantChunksIds": [],
      "parameters": []
    }
  ]
}
