interface answer {
  sources: Array<string>,
  prompt: string,
  answer: string
}

export const answer1 : answer = {
  sources : [
    "Art 3 AIA (95 %)",
    "Art 25 AIA (92 %)",
    "ErwGr 97 AIA (92 %)",
    "KI-Servicestelle: Risikostufen KI-Systeme (97 %)",
    "KI-Servicestelle: Akteure (81 %)",
    "KI-Servicestelle: Anbieterverpflichtungen (80 %)"
  ],
  prompt: "Sie sind Senior-Partner in einer östereichischen Großkanzlei. Sie beantworten Mandantenanfragen höflich, präzise und genau. Sie verwenden ausschließlich die Ihnen übergebenen Quellen um Ihre Subsumptionen durchzuführen.<br/>Folgende Kundenanfrage " +
      `ist bei Ihnen gestern eingegangen: <br/><br/>"""<br/>%%%USERPROMPT%%%<br/>"""<br/><br/>Sie verwenden dazu folgende Quellen:<br/>`+
    `<br/>Quellen:<br/><br/>` +
    `Artikel 3 AI Act: Begriffsbestimmungen<br/
Für die Zwecke dieser Verordnung bezeichnet der Ausdruck<br/>
1.\t„KI-System“ ein maschinengestütztes System, das für einen in unterschiedlichem Grade autonomen Betrieb ausgelegt ist und das nach seiner Betriebsaufnahme anpassungsfähig sein kann und das aus den erhaltenen Eingaben für explizite oder implizite Ziele ableitet, wie Ausgaben wie etwa Vorhersagen, Inhalte,Empfehlungen oder Entscheidungen erstellt werden, die physische oder virtuelle Umgebungen beeinflussen können;<br/>
2.\t„Risiko“ die Kombination aus der Wahrscheinlichkeit des Auftretens eines Schadens und der Schwere dieses Schadens;<br/>
3.\t„Anbieter“ eine natürliche oder juristische Person, Behörde, Einrichtung oder sonstige Stelle, die ein KI-System oder ein KI-Modell mit allgemeinem Verwendungszweck entwickelt oder entwickeln lässt und es unter ihrem eigenen Namen oder ihrer Handelsmarke in Verkehr bringt oder das KI-System unter ihrem eigenen Namen oder ihrer Handelsmarke in Betrieb nimmt, sei es entgeltlich oder unentgeltlich;<br/>
4.\t„Betreiber“ eine natürliche oder juristische Person, Behörde, Einrichtung oder sonstige Stelle, die ein KI-System in eigener Verantwortung verwendet, es sei denn, das KI-System wird im Rahmen einer persönlichen und nicht beruflichen Tätigkeit verwendet;<br/>
5.\t„Bevollmächtigter“ eine in der Union ansässige oder niedergelassene natürliche oder juristische Person, die vom Anbieter eines KI-Systems oder eines KI-Modells mit allgemeinem Verwendungszweck schriftlich dazu bevollmächtigt wurde und sich damit einverstanden erklärt hat, in seinem Namen die in dieser Verordnung festgelegten Pflichten zu erfüllen bzw. Verfahren durchzuführen;<br/>
6.\t„Einführer“ eine in der Union ansässige oder niedergelassene natürliche oder juristische Person, die ein KI-System, das den Namen oder die Handelsmarke einer in einem Drittland niedergelassenen natürlichen oder juristischen Person trägt, in Verkehr bringt;<br/>
7.\t„Händler“ eine natürliche oder juristische Person in der Lieferkette, die ein KI-System auf dem Unionsmarkt bereitstellt, mit Ausnahme des Anbieters oder des Einführers;<br/>
8.\t„Akteur“ einen Anbieter, Produkthersteller, Betreiber, Bevollmächtigten, Einführer oder Händler;<br/>
9.\t„Inverkehrbringen“ die erstmalige Bereitstellung eines KI-Systems oder eines KI-Modells mit allgemeinem Verwendungszweck auf dem Unionsmarkt;<br/>
10.\t„Bereitstellung auf dem Markt“ die entgeltliche oder unentgeltliche Abgabe eines KI-Systems oder eines KI-Modells mit allgemeinem Verwendungszweck zum Vertrieb oder zur Verwendung auf dem Unionsmarkt im Rahmen einer Geschäftstätigkeit;<br/>
11.\t„Inbetriebnahme“ die Bereitstellung eines KI-Systems in der Union zum Erstgebrauch direkt an den Betreiber oder zum Eigengebrauch entsprechend seiner Zweckbestimmung;<br/>
12.\t„Zweckbestimmung“ die Verwendung, für die ein KI-System laut Anbieter bestimmt ist, einschließlich der besonderen Umstände und Bedingungen für die Verwendung, entsprechend den vom Anbieter bereitgestellten Informationen in den Betriebsanleitungen, im Werbe- oder Verkaufsmaterial und in diesbezüglichen Erklärungen sowie in der technischen Dokumentation;<br/>
13.\t„vernünftigerweise vorhersehbare Fehlanwendung“ die Verwendung eines KI-Systems in einer Weise, die nicht seiner Zweckbestimmung entspricht, die sich aber aus einem vernünftigerweise vorhersehbaren menschlichen Verhalten oder einer vernünftigerweise vorhersehbaren Interaktion mit anderen Systemen, auch anderen KI-Systemen, ergeben kann;<br/>
14.\t„Sicherheitsbauteil“ einen Bestandteil eines Produkts oder KI-Systems, der eine Sicherheitsfunktion für dieses Produkt oder KI-System erfüllt oder dessen Ausfall oder Störung die Gesundheit und Sicherheit von Personen oder Eigentum gefährdet;<br/>
15.\t„Betriebsanleitungen“ die Informationen, die der Anbieter bereitstellt, um den Betreiber insbesondere über die Zweckbestimmung und die ordnungsgemäße Verwendung eines KI-Systems zu informieren;<br/>
16.\t„Rückruf eines KI-Systems“ jede Maßnahme, die auf die Rückgabe an den Anbieter oder auf die Außerbetriebsetzung oder Abschaltung eines den Betreibern bereits zur Verfügung gestellten KI-Systems abzielt;<br/>
17.\t„Rücknahme eines KI-Systems“ jede Maßnahme, mit der die Bereitstellung eines in der Lieferkette befindlichen KI-Systems auf dem Markt verhindert werden soll;<br/>
18.\t„Leistung eines KI-Systems“ die Fähigkeit eines KI-Systems, seine Zweckbestimmung zu erfüllen;<br/>
19.\t„notifizierende Behörde“ die nationale Behörde, die für die Einrichtung und Durchführung der erforderlichen Verfahren für die Bewertung, Benennung und Notifizierung von Konformitätsbewertungsstellen und für deren Überwachung zuständig ist;<br/>
20.\t„Konformitätsbewertung“ ein Verfahren mit dem bewertet wird, ob die in Titel II Abschnitt 2 festgelegten Anforderungen an ein Hochrisiko-KI-System erfüllt wurden;<br/>
21.\t„Konformitätsbewertungsstelle“ eine Stelle, die Konformitätsbewertungstätigkeiten einschließlich Prüfungen, Zertifizierungen und Inspektionen durchführt und dabei als Dritte auftritt;<br/>
22.\t„notifizierte Stelle“ eine Konformitätsbewertungsstelle, die gemäß dieser Verordnung und den anderen einschlägigen Harmonisierungsrechtsvorschriften der Union notifiziert wurde;<br/>
23.\t„wesentliche Veränderung“ eine Veränderung eines KI-Systems nach dessen Inverkehrbringen oder Inbetriebnahme, die in der vom Anbieter durchgeführten ursprünglichen Konformitätsbewertung nicht vorgesehen oder geplant war und durch die die Konformität des KI-Systems mit den Anforderungen in Kapitel III Abschnitt 2 beeinträchtigt wird oder die zu einer Änderung der Zweckbestimmung führt, für die das KI-System bewertet wurde;<br/>
24.\t„CE-Kennzeichnung“ eine Kennzeichnung, durch die ein Anbieter erklärt, dass ein KI-System die Anforderungen erfüllt, die in Kapitel III Abschnitt 2 und in anderen anwendbaren Harmonisierungsrechtsvorschriften, die die Anbringung dieser Kennzeichnung vorsehen, festgelegt sind;<br/>
25.\t„System zur Beobachtung nach dem Inverkehrbringen“ alle Tätigkeiten, die Anbieter von KI-Systemen zurSammlung und Überprüfung von Erfahrungen mit der Verwendung der von ihnen in Verkehr gebrachten oder in Betrieb genommenen KI-Systeme durchführen, um festzustellen, ob unverzüglich nötige Korrektur- oder Präventivmaßnahmen zu ergreifen sind;<br/>
26.\t„Marktüberwachungsbehörde“ die nationale Behörde, die die Tätigkeiten durchführt und die Maßnahmen ergreift, die in der Verordnung (EU) 2019/1020 vorgesehen sind;<br/>
27.\t„harmonisierte Norm“ bezeichnet eine harmonisierte Norm im Sinne des Artikels 2 Absatz 1 Buchstabe c der Verordnung (EU) Nr. 1025/2012;<br/>
28.\t„gemeinsame Spezifikation“ eine Reihe technischer Spezifikationen im Sinne des Artikels 2 Nummer 4 der Verordnung (EU) Nr. 1025/2012, deren Befolgung es ermöglicht, bestimmte Anforderungender vorliegenden Verordnung zu erfüllen;<br/>
29.\t„Trainingsdaten“ Daten, die zum Trainieren eines KI-Systems verwendet werden, wobei dessen lernbare Parameterangepasst werden;<br/>
30.\t„Validierungsdaten“ Daten, die zur Evaluation des trainierten KI-Systems und zur Einstellung seiner nicht erlernbaren Parameter und seines Lernprozesses verwendet werden, um unter anderem eine Unter- oder Überanpassung zu vermeiden;<br/>
31.\t„Validierungsdatensatz“ einen separaten Datensatz oder einen Teil des Trainingsdatensatzes mit fester oder variabler Aufteilung;<br/>
32.\t„Testdaten“ Daten, die für eine unabhängige Bewertung desKI-Systems verwendet werden, um die erwartete Leistung dieses Systems vor dessen Inverkehrbringen oder Inbetriebnahme zu bestätigen;<br/>
33.\t„Eingabedaten“ die in ein KI-System eingespeisten oder von diesem direkt erfassten Daten, auf deren Grundlage das System eine Ausgabe hervorbringt;<br/>
34.\t„biometrische Daten“ mit speziellen technischen Verfahren gewonnene personenbezogene Daten zu den physischen, physiologischen oder verhaltenstypischen Merkmalen einer natürlichen Person, wie etwa Gesichtsbilder oder daktyloskopische Daten;<br/>
35.\t„biometrische Identifizierung“ die automatisierte Erkennung physischer, physiologischer, verhaltensbezogener oder psychologischer menschlicher Merkmale zum Zwecke der Feststellung der Identität einer natürlichen Person durch den Vergleich biometrischer Daten dieser Person mit biometrischen Daten von Personen, die in einer Datenbank gespeichert sind;<br/>
36.\t„biometrische Verifizierung“ die automatisierte Eins-zu-eins-Verifizierung, einschließlich Authentifizierung, der Identität natürlicher Personen durch den Vergleich ihrer biometrischen Daten mit zuvor bereitgestellten biometrischen Daten;<br/>
37.\t„besondere Kategorien personenbezogener Daten“ die in Artikel 9 Absatz 1der Verordnung (EU) 2016/679, Artikel 10 der Richtlinie (EU) 2016/680 und Artikel 10 Absatz 1 der Verordnung (EU) 2018/1725 aufgeführten Kategorien personenbezogener Daten;<br/>
38.\t„sensible operative Daten“ operative Daten im Zusammenhang mit Tätigkeiten zur Verhütung, Aufdeckung, Untersuchung oder Verfolgung von Straftaten, deren Offenlegung die Integrität von Strafverfahren gefährden könnte;<br/>
39.\t„Emotionserkennungssystem“ ein KI-System, das dem Zweck dient, Emotionen oder Absichten natürlicher Personen auf der Grundlage ihrer biometrischen Daten festzustellen oder daraus abzuleiten;<br/>
40.\t„System zur biometrischen Kategorisierung“ ein KI-System, das dem Zweck dient, natürliche Personen auf der Grundlage ihrer biometrischen Daten bestimmten Kategorienzuzuordnen, sofern es sich um eine Nebenfunktion eines anderen kommerziellen Dienstes handelt und aus objektiven technischen Gründen unbedingt erforderlich ist;<br/>
41.\t„biometrisches Fernidentifizierungssystem“ ein KI-System, das dem Zweck dient, natürliche Personen ohne ihre aktive Einbeziehung und in der Regel aus der Fernedurch Abgleich der biometrischen Daten einer Person mit den in einer Referenzdatenbank gespeicherten biometrischen Daten zu identifizieren;<br/>
42.\t„biometrisches Echtzeit-Fernidentifizierungssystem“ ein biometrisches Fernidentifizierungssystem, bei dem die Erfassung biometrischer Daten, der Abgleich und die Identifizierung ohne erhebliche Verzögerung erfolgen, und das zur Vermeidung einer Umgehung der Vorschriften nicht nur die sofortige Identifizierung, sondern auch eine Identifizierung mit begrenzten kurzen Verzögerungen umfasst;<br/>
43.\t„System zur nachträglichen biometrischen Fernidentifizierung“ ein biometrisches Fernidentifizierungssystem, das kein biometrisches Echtzeit-Fernidentifizierungssystem ist;<br/>
44.\t„öffentlich zugänglicher Raum“ einen einer unbestimmten Anzahl natürlicher Personen zugänglichen physischen Ort in privatem oder öffentlichem Eigentum, unabhängig davon, ob bestimmte Bedingungen für den Zugang gelten, und unabhängig von möglichen Kapazitätsbeschränkungen;<br/>
45.\t„Strafverfolgungsbehörde“<br/>
a)\teine Behörde, die für die Verhütung, Ermittlung, Aufdeckung oder Verfolgung von Straftaten oder die Strafvollstreckung, einschließlich des Schutzes vor und der Abwehr von Gefahren für die öffentliche Sicherheit, zuständig ist, oder<br/>
b)\teine andere Stelle oder Einrichtung, der durch nationales Recht die Ausübung öffentlicher Gewalt und hoheitlicher Befugnisse zur Verhütung, Ermittlung, Aufdeckung oder Verfolgung von Straftaten oder zur Strafvollstreckung, einschließlich des Schutzes vor und der Abwehr von Gefahren für die öffentliche Sicherheit, übertragen wurde;<br/>
46.\t„Strafverfolgung“ Tätigkeiten der Strafverfolgungsbehörden oder in deren Auftrag zur Verhütung, Ermittlung, Aufdeckung oder Verfolgung von Straftaten oder zur Strafvollstreckung, einschließlich des Schutzes vor und der Abwehr von Gefahren für die öffentliche Sicherheit;<br/>
47.\t„Büro für Künstliche Intelligenz“ die Aufgabe der Kommission, zur Umsetzung, Beobachtung und Überwachung von KI-Systemen und KI-Modellen mit allgemeinem Verwendungszweck und zu der im Beschluss der Kommission vom 24. Januar 2024 vorgesehenen KI-Governance beizutragen; Bezugnahmen in dieser Verordnung auf das Büro für Künstliche Intelligenz gelten als Bezugnahmen auf die Kommission;<br/>
48.\t„zuständige nationale Behörde“ eine notifizierende Behörde oder eine Marktüberwachungsbehörde; in Bezug auf KI-Systeme, die von Organen, Einrichtungen und sonstigen Stellen der Union in Betrieb genommen oder verwendet werden, sind Bezugnahmen auf die zuständigen nationalen Behörden oder Marktüberwachungsbehörden in dieser Verordnung als Bezugnahmen auf den Europäischen Datenschutzbeauftragten auszulegen;<br/>
49.\t„schwerwiegender Vorfall“ einen Vorfall oder eine Fehlfunktion bezüglich eines KI-Systems, das bzw. die direkt oder indirekt eine der nachstehenden Folgen hat:<br/>
a)\tden Tod oder die schwere gesundheitliche Schädigung einer Person;<br/>
b)\teine schwere und unumkehrbare Störung der Verwaltung oder des Betriebs kritischer Infrastrukturen;<br/>
c)\tdie Verletzung von Pflichten aus den Unionsrechtsvorschriften zum Schutz der Grundrechte;<br/>
d)\tschwere Sach- oder Umweltschäden;<br/>
50.\t„personenbezogene Daten“ personenbezogene Daten im Sinne von Artikel 4 Nummer 1 der Verordnung (EU) 2016/679;<br/>
51.\t„nicht personenbezogene Daten“ Daten, die keine personenbezogenen Daten im Sinne von Artikel 4 Nummer 1 der Verordnung (EU) 2016/679 sind;<br/>
52.\t„Profiling“ das Profiling im Sinne von Artikel 4 Nummer 4 der Verordnung (EU) 2016/679;<br/>
53.\t„Plan für einen Test unter Realbedingungen“ ein Dokument, in dem die Ziele, die Methodik, der geografische, bevölkerungsbezogene und zeitliche Umfang, die Überwachung, die Organisation und die Durchführung eines Tests unter Realbedingungen beschrieben werden;<br/>
54.\t„Plan für das Reallabor“ ein zwischen dem teilnehmenden Anbieter und der zuständigen Behörde vereinbartes Dokument, in dem die Ziele, die Bedingungen, der Zeitrahmen, die Methodik und die Anforderungen für die im Reallabor durchgeführten Tätigkeiten beschrieben werden;<br/>
55.\t„KI-Reallabor“ einen kontrollierten Rahmen, der von einer zuständigen Behörde geschaffen wird und den Anbieter oder zukünftige Anbieter von KI-Systemen nach einem Plan für das Reallabor einen begrenzten Zeitraum und unter regulatorischer Aufsicht nutzen können, um ein innovatives KI-System zu entwickeln, zu trainieren, zu validieren und – gegebenenfalls unter Realbedingungen – zu testen.<br/>
56.\t„KI-Kompetenz“ die Fähigkeiten, die Kenntnisse und das Verständnis, die es Anbietern, Betreibern und Betroffenen unter Berücksichtigung ihrer jeweiligen Rechte und Pflichten im Rahmen dieser Verordnung ermöglichen, KI-Systeme sachkundig einzusetzen sowie sich der Chancen und Risiken von KI und möglicher Schäden, die sie verursachen kann, bewusst zu werden.<br/>
57.\t„Test unter Realbedingungen“ den befristeten Test eines KI-Systems auf seine Zweckbestimmung, der unter Realbedingungen außerhalb eines Labors oder einer anderweitig simulierten Umgebung erfolgt, um zuverlässige und belastbare Daten zu erheben und die Konformität des KI-Systems mit den Anforderungen der vorliegenden Verordnung zu bewerten und zu überprüfen, wobei dieser Test nicht als Inverkehrbringen oder Inbetriebnahme des KI-Systems im Sinne dieser Verordnung gilt, sofern alle Bedingungen nach Artikel 57 oder Artikel 60 erfüllt sind;<br/>
58.\t„Testteilnehmer“ für die Zwecke eines Tests unter Realbedingungen eine natürliche Person, die an dem Test unter Realbedingungen teilnimmt;<br/>
59.\t„informierte Einwilligung“ eine aus freien Stücken erfolgende, spezifische, eindeutige und freiwillige Erklärung der Bereitschaft, an einem bestimmten Test unter Realbedingungen teilzunehmen, durch einen Testteilnehmer, nachdem dieser über alle Aspekte des Tests, die für die Entscheidungsfindung des Testteilnehmers bezüglich der Teilnahme relevant sind, aufgeklärt wurde;<br/>
60.\t„Deepfake“ einen durch KI erzeugten oder manipulierten Bild-, Ton- oder Videoinhalt, der wirklichen Personen, Gegenständen, Orten, Einrichtungen oder Ereignissen ähnelt und einer Person fälschlicherweise als echt oder wahrheitsgemäß erscheinen würde;<br/>
61.\t„weitverbreiteter Verstoß“ jede Handlung oder Unterlassung, die gegen das Unionsrecht verstößt, das die Interessen von Einzelpersonen schützt, und die<br/>
a)\tdie kollektiven Interessen von Einzelpersonen in mindestens zwei anderen Mitgliedstaaten als dem Mitgliedstaat schädigt oder zu schädigen droht, in dem<br/>
i)\tdie Handlung oder die Unterlassung ihren Ursprung hatte oder stattfand,<br/>
ii)\tder betreffende Anbieter oder gegebenenfalls sein Bevollmächtigter sich befindet oder niedergelassen ist oder<br/>
iii)\tder Betreiber niedergelassen ist, sofern der Verstoß vom Betreiber begangen wird,<br/>
b)\tdie kollektiven Interessen von Einzelpersonen geschädigt hat, schädigt oder schädigen könnte und allgemeine Merkmale aufweist, einschließlich derselben rechtswidrigen Praxis oder desselben verletzten Interesses, und gleichzeitig auftritt und von demselben Akteur in mindestens drei Mitgliedstaaten begangen wird;<br/>
62.\t„kritische Infrastrukturen“ kritische Infrastrukturen im Sinne von Artikel 2 Nummer 4 der Richtlinie (EU) 2022/2557;<br/>
63.\t„KI-Modell mit allgemeinem Verwendungszweck“ ein KI-Modell – einschließlich der Fälle, in denen ein solches KI-Modell mit einer großen Datenmenge unter umfassender Selbstüberwachung trainiert wird –, das eine erhebliche allgemeine Verwendbarkeit aufweist und in der Lage ist, unabhängig von der Art und Weise seines Inverkehrbringens ein breites Spektrum unterschiedlicher Aufgaben kompetent zu erfüllen, und das in eine Vielzahl nachgelagerter Systeme oder Anwendungen integriert werden kann, ausgenommen KI-Modelle, die vor ihrem Inverkehrbringen für Forschungs- und Entwicklungstätigkeiten oder die Konzipierung von Prototypen eingesetzt werden;<br/>
64.\t„Fähigkeiten mit hoher Wirkkraft“ bezeichnet Fähigkeiten, die den bei den fortschrittlichsten KI-Modellen mit allgemeinem Verwendungszweck festgestellten Fähigkeiten entsprechen oder diese übersteigen;<br/>
65.\t„systemisches Risiko“ ein Risiko, das für die Fähigkeiten mit hoher Wirkkraft von KI-Modellen mit allgemeinem Verwendungszweck spezifisch ist und aufgrund deren Reichweite oder aufgrund tatsächlicher oder vernünftigerweise vorhersehbarer negativer Folgen für die öffentliche Gesundheit, die Sicherheit, die öffentliche Sicherheit, die Grundrechte oder die Gesellschaft insgesamt erhebliche Auswirkungen auf den Unionsmarkt hat, die sich in großem Umfang über die gesamte Wertschöpfungskette hinweg verbreiten können;<br/>
66.\t„KI-System mit allgemeinem Verwendungszweck“ ein KI-System, das auf einem KI-Modell mit allgemeinem Verwendungszweck beruht und in der Lage ist, einer Vielzahl von Zwecken sowohl für die direkte Verwendung als auch für die Integration in andere KI-Systeme zu dienen;<br/>
67.\t„Gleitkommaoperation“ jede Rechenoperation oder jede Zuweisung mit Gleitkommazahlen, bei denen es sich um eine Teilmenge der reellen Zahlen handelt, die auf Computern typischerweise durch das Produkt aus einer ganzen Zahl mit fester Genauigkeit und einer festen Basis mit ganzzahligem Exponenten dargestellt wird;<br/>
68.\t„nachgelagerter Anbieter“ einen Anbieter eines KI-Systems, einschließlich eines KI-Systems mit allgemeinem Verwendungszweck, das ein KI-Modell integriert, unabhängig davon, ob das KI-Modell von ihm selbst bereitgestellt und vertikal integriert wird oder von einer anderen Einrichtung auf der Grundlage vertraglicher Beziehungen bereitgestellt wird.<br/>
<br/><br/>
Artikel 25: Verantwortlichkeiten entlang der KI-Wertschöpfungskette<br/>
(1)\tIn den folgenden Fällen gelten Händler, Einführer, Betreiber oder sonstige Dritte als Anbieter eines Hochrisiko-KI-Systems für die Zwecke dieser Verordnung und unterliegen den Anbieterpflichten gemäß Artikel 16:<br/>
a)\twenn sie ein bereits in Verkehr gebrachtes oder in Betrieb genommenes Hochrisiko-KI-System mit ihrem Namen oder ihrer Handelsmarke versehen, unbeschadet vertraglicher Vereinbarungen, die eine andere Aufteilung der Pflichten vorsehen;<br/>
b)\twenn sie eine wesentliche Veränderung eines Hochrisiko-KI-Systems, das bereits in Verkehr gebracht oder in Betrieb genommen wurde, so vornehmen, dass es weiterhin ein Hochrisiko-KI-System gemäß Artikel 6 bleibt;<br/>
c)\twenn sie die Zweckbestimmung eines KI-Systems, einschließlich eines KI-Systems mit allgemeinem Verwendungszweck, das nicht als hochriskant eingestuft wurde und bereits in Verkehr gebracht oder in Betrieb genommen wurde, so verändern, dass das betreffende KI-System zu einem Hochrisiko-KI-System im Sinne von Artikel 6 wird.<br/>
(2)\tUnter den in Absatz 1 genannten Umständen gilt der Anbieter, der das KI-System ursprünglich in Verkehr gebracht oder in Betrieb genommen hatte, nicht mehr als Anbieter dieses spezifischen KI-Systems für die Zwecke dieser Verordnung. Dieser Erstanbieter arbeitet eng mit neuen Anbietern zusammen, stellt die erforderlichen Informationen zur Verfügung und sorgt für den vernünftigerweise zu erwartenden technischen Zugang und sonstige Unterstützung, die für die Erfüllung der in dieser Verordnung festgelegten Pflichten, insbesondere in Bezug auf die Konformitätsbewertung von Hochrisiko-KI-Systemen, erforderlich sind. Dieser Absatz gilt nicht in Fällen, in denen der Erstanbieter eindeutig festgelegt hat, dass sein KI-System nicht in ein Hochrisiko-KI-System umgewandelt werden darf und daher nicht der Pflicht zur Übergabe der Dokumentation unterliegt.<br/>
(3)\tIm Falle von Hochrisiko-KI-Systemen, bei denen es sich um Sicherheitsbauteile von Produkten handelt, die unter die in Anhang I Abschnitt A aufgeführten Harmonisierungsrechtsvorschriften der Union fallen, gilt der Produkthersteller als Anbieter des Hochrisiko-KI-Systems und unterliegt in den beiden nachfolgenden Fällen den Pflichten nach Artikel 16:<br/>
a)\tDas Hochrisiko-KI-System wird zusammen mit dem Produkt unter dem Namen oder der Handelsmarke des Produktherstellers in Verkehr gebracht;<br/>
b)\tdas Hochrisiko-KI-System wird unter dem Namen oder der Handelsmarke des Produktherstellers in Betrieb genommen, nachdem das Produkt in Verkehr gebracht wurde.<br/>
(4)\tDer Anbieter eines Hochrisiko-KI-Systems und der Dritte, der ein KI-System, Instrumente, Dienste, Komponenten oder Verfahren bereitstellt, die in einem Hochrisiko-KI-System verwendet oder integriert werden, legen in einer schriftlichen Vereinbarung die Informationen, die Fähigkeiten, den technischen Zugang und die sonstige Unterstützung nach dem allgemein anerkannten Stand der Technik fest, die erforderlich sind, damit der Anbieter des Hochrisiko-KI-Systems die in dieser Verordnung festgelegten Pflichten vollständig erfüllen kann. Dieser Absatz gilt nicht für Dritte, die Instrumente, Dienste, Verfahren oder Komponenten, bei denen es sich nicht um KI-Modelle mit allgemeinem Verwendungszweck handelt, im Rahmen einer freien und quelloffenen Lizenz öffentlich zugänglich machen.<br/>
Das Büro für Künstliche Intelligenz kann freiwillige Musterbedingungen für Verträge zwischen Anbietern von Hochrisiko-KI-Systemen und Dritten, die Instrumente, Dienste, Komponenten oder Verfahren bereitstellen, die für Hochrisiko-KI-Systeme verwendet oder in diese integriert werden, ausarbeiten und empfehlen. Bei der Ausarbeitung dieser freiwilligen Musterbedingungen berücksichtigt das Büro für Künstliche Intelligenz mögliche vertragliche Anforderungen, die in bestimmten Sektoren oder Geschäftsfällen gelten. Die freiwilligen Musterbedingungen werden veröffentlicht und sind kostenlos in einem leicht nutzbaren elektronischen Format verfügbar.<br/>
(5)\tDie Absätze 2 und 3 berühren nicht die Notwendigkeit, Rechte des geistigen Eigentums, vertrauliche Geschäftsinformationen und Geschäftsgeheimnisse im Einklang mit dem Unionsrecht und dem nationalen Recht zu achten und zu schützen.<br/>
<br/><br/>` +
    `<br/>Quelle: Übersicht: Die Akteure im AI Act
<br/>Der AI Act sieht viele Rollen in der KI-Wertschöpfungskette vor. Die verschiedenen Akteure sind dabei keineswegs unbekannt, der Unionsgesetzgeber orientierte sich dabei in vielerlei Hinsicht an den EU-Produktrechtsnormen (siehe etwa die Produktsicherheitsverordnung, Medizinprodukteverordnung).
<br/>Zu den Akteuren im AI Act zählen gemäß Art. 3 Ziffer 8:
<br/>Anbieter („Provider“);
<br/>Produkthersteller („Product Manufacturer“);
<br/>Bevollmächtigter („Authorised Representative“);
<br/>Einführer („Importer“);
<br/>Händler („Distributor“);
<br/>Betreiber („Deployer“).
<br/>Ferner kommen auch noch Nutzer und „betroffene Personen“ vor. Diese werden aber nicht als Akteure im Sinne des AI Act bezeichnet.
<br/>Inverkehrbringen, Bereitstellen, Inbetriebnahme
<br/>Die verschiedenen Akteure übernehmen verschiedene Tätigkeiten in der KI-Wertschöpfungskette. Unterschieden wird dabei in „Inverkehrbringen“, „Bereitstellen“ und der „Inbetriebnahme“, die im AI Act auch legaldefiniert werden. Diese Begriffe sind nicht neu, kommen sie doch bereits im EU-Produktrecht vor.
<br/>Mit „Inverkehrbringen“ ist gemäß Art. 3 Ziffer 9 AIA „die erstmalige Bereitstellung eines KI-Systems oder eines GPAI-Modell auf dem Unionsmarkt“ gemeint. Laut Definition erfasst das Inverkehrbringen zugleich die „Bereitstellung auf dem Markt“, was wiederum „die entgeltliche oder unentgeltliche Bereitstellung eines KI-Systems oder eines KI-Modells mit allgemeinem Verwendungszweck zum Vertrieb oder zur Verwendung auf dem Unionsmarkt im Rahmen einer Geschäftstätigkeit“ bezeichnet (Art. 3 Ziffer 10 AIA).
<br/>Der Unterschied zwischen „Inverkehrbringen“ und „Bereitstellen“ liegt darin, dass beim Inverkehrbringen die Bereitstellung auf dem Markt erstmalig erfolgt. Das Inverkehrbringen übernimmt innerhalb der EU in der Regel der Hersteller des Produkts bzw. im Falle des KI-Systems/GPAI-Modell der Anbieter; bei Produkten bzw. KI-Systemen außerhalb der EU der Importeur. Ist die erstmalige Bereitstellung erfolgt, wird die weitere Bereitstellung (umgangssprachlich als „Vertrieb“ bezeichnet) für gewöhnlich vom Händler übernommen, die typische Tätigkeiten wie den Verkauf, die Lagerung, den Transport (etwa bei in physischen Produkten integrierte Hochrisiko-KI-Systeme), die Kundenbetreuung oder die Wartung übernehmen.
<br/>Diese Form der Lieferkette stellt vor allem den traditionellen Weg einer Lieferkette dar, wo das Produkt vom Hersteller über den Importeur und (Zwischen-)Händler ihren Weg zum Endkunden findet. Mit dem Fernabsatz haben sich auch neue Vertriebsformen entwickelt. Anbieter und Händler aus Drittstaaten können ihre Produkte durch Online-Schnittstellen am Unionsmarkt anbieten, was vor allem Anbieter auch das Ausklammern bestimmter Akteure (z. B. Händler) ermöglicht. Gerade bei digitalen Produkten wie Software-Anwendungen, welche durch einen simplen Download erworben werden können, spielt diese Form des Absatzes eine bedeutsame Rolle.
<br/>Auf die Veränderungen der Absatzformen hat auch der Unionsgesetzgeber in der Marktüberwachungsverordnung (Erwägungsgründe 15) reagiert: Wird ein Produkt online oder über eine andere Form des Fernabsatzes angeboten, so sollte das Produkt als auf dem Markt bereitgestellt gelten, wenn sich das Verkaufsangebot an Endnutzer in der Union richtet. Ob ein solches Verkaufsangebot an Endnutzer vorliegt, ist eine Einzelfallentscheidung und hat unter Berücksichtigung von Kriterien wie etwa die geografischen Gebiete, in die geliefert werden kann, die für das Angebot oder für die Bestellung verfügbaren Sprachen und die Zahlungsarten zu erfolgen. Die bloße Zugänglichkeit der Website des Akteurs reicht für sich alleine nicht aus, eine Bereitstellung auf dem Unionsmarkt anzunehmen.
<br/>Mit „Inbetriebnahme“ wird gemäß Art. 3 Ziffer 11 AIA „die Bereitstellung eines KI-Systems durch den Anbieter in der Union zum Erstgebrauch direkt an den Betreiber oder zum Eigengebrauch entsprechend seiner Zweckbestimmung“ bezeichnet. Mit „Zweckbestimmung“ wird kurzgefasst die Verwendung, für die ein KI-System laut Anbieter bestimmt oder propagiert wird (vgl. Art. 3 Ziffer 12 AIA).
<br/>Die einzelnen Akteure
<br/>Je nachdem, um welchen Akteur und welches KI-System oder GPAI-Modell es sich handelt, sind unterschiedlich weitreichende Verpflichtungen einzuhalten. Es ist daher von fundamentaler Bedeutung, in den einzelnen Verpflichtungsadressaten zu unterscheiden. In bestimmten Situationen kann ein Akteur auch mehrere Rollen gleichzeitig übernehmen. Die folgenden Erläuterungen und die Grafik sollen einen Überblick geben.
<br/>Die Infografik fasst den Fließtext zusammen und beschreibt die Rollen entlang der KI-Wertschöpfungskette
<br/>© RTR (CC BY 4.0)
<br/>Wer ist Anbieter?
<br/>Laut Art. 3 Ziffer 3 AIA ist ein Anbieter
<br/>eine natürliche oder juristische Person, Behörde, Einrichtung oder sonstige Stelle, die ein KI-System oder ein KI-Modell mit allgemeinem Verwendungszweck entwickelt oder entwickeln lässt und es unter ihrem eigenen Namen oder ihrer Handelsmarke in Verkehr bringt oder das KI-System unter ihrem eigenen Namen oder ihrer Handelsmarke in Betrieb nimmt, sei es entgeltlich oder unentgeltlich.
<br/>Beim Anbieter handelt es sich um jenes Glied in der KI-Wertschöpfungskette, das das KI-System oder GPAI-Modell entwickelt. Typischerweise handelt es sich dabei um Personen und Einrichtungen, die in den einzelnen Entwicklungsphasen – Datenvorbereitung, Modelltraining, Evaluierung und Optimierung – von KI-Systemen oder GPAI-Modellen beteiligt sind.
<br/>Da die Entwicklung eines KI-Systems oder GPAI-Modells meist mehrere Berufsdisziplinen umfasst, arbeiten oft mehrere Fachleute wie Datenwissenschaftler, Ingenieure, Domänenexperten und Designer zusammen. Von einem Anbieter wird daher auch dann ausgegangen, wenn diese das KI-System oder ein GPAI-Modell entwickeln lässt (mit anderen Worten „in Auftrag gibt“), um es in der Folge selbst in den Verkehr zu bringen oder das System unter dem eigenen Namen oder ihrer eigenen Marke – entgeltlich oder unentgeltlich in Betrieb zu nehmen. Anbieter können auch bestimmte Instrumente, Dienstleistungen, Komponenten oder Prozesse, wie z.B. Trainieren, Neutrainieren, Testen und Bewerten von Modellen, die Integration in Software oder andere Aspekte der Modellentwicklung auslagern. Die Verpflichtungen im Zusammenhang mit dem AI Act treffen allerdings weitergehend die Anbieter.
<br/>Hinweis: Um die Anwendung des AI Act auch in diesen Situationen sicherzustellen, gilt es die Pflichten vertraglich zu regeln. Das AI Office wird diesbezüglich ermächtigt, Mustervertragsbestimmungen zu erstellen und zur Verfügung zu stellen (Art. 25 Abs. 4 AI Act).
<br/>Von einem Anbieter ist auch dann die Rede, wenn diese ein KI-Modell in ihr KI-System oder GPAI-System integriert. Irrelevant ist dabei, ob das Modell von ihm selbst bereitgestellt und vertikal integriert wird oder von jemand anderem stammt. In diesem Fall wird von einem „nachgelagerten Anbieter“ gesprochen (siehe Art. 3 Ziffer 68 AIA)
<br/>Durch die Regel in Art. 25 Abs. 1 AIA werden auch Einführer, Händler, Betreiber und sonstige Dritte als Anbieter behandelt, wenn sie:
<br/>ein bereits in Verkehr gebrachtes oder in Betrieb genommenes Hochrisiko-KI-System mit ihrem Namen oder ihrer Handelsmarke versehen, unbeschadet vertraglicher Vereinbarungen, die eine andere Aufteilung der Pflichten vorsieht. Der jeweilige Akteur tritt somit als Anbieter eines KI-Systems auf obwohl dieses nicht selbst entwickelt wurde („Quasi-Hersteller“);
<br/>eine wesentliche Änderung an einem Hochrisiko-KI-System, das bereits in Verkehr gebracht oder in Betrieb genommen wurde, so vornehmen, dass es weiterhin ein Hochrisiko-KI-System im Sinne von Art. 6 AIA bleibt;
<br/>die Zweckbestimmung eines KI-Systems, einschließlich eines GPAI-Systems, das nicht als hochriskant eingestuft wurde und bereits in Verkehr gebracht oder in Betrieb genommen wurde, so verändern, dass das betreffende KI-System zu einem Hochrisiko-KI-System im Sinne von Art. 6 AIA wird.
<br/>Wer ist Produkthersteller?
<br/>Produkthersteller werden zwar als Akteure aufgezählt, eine entsprechende Definition fehlt allerdings im AI Act. Da im Anhang I des AI Acts auf unionsrechtliche Normen des Produktrechts verwiesen wird, ist als Produkthersteller im AI Act der Hersteller des jeweiligen Produkts gemeint.
<br/>Beispielshaft wird als Hersteller im Sinne der Aufzüge-Richtlinie „jede natürliche oder juristische Person, die ein Sicherheitsbauteil für Aufzüge herstellt bzw. entwickeln oder herstellen lässt und es unter ihrem eigenen Namen oder ihrer eigenen Handelsmarke vermarktet“ (Art. 2 Ziffer 8 Aufzüge-Richtlinie).
<br/>Wird ein KI-System als Sicherheitskomponente in ein Produkt eingebaut, hat der Produkthersteller die im AI Act festgelegten Pflichten eines Anbieters eines KI-Systems zu erfüllen. Der Produkthersteller wird in diesen Fällen als Anbieter behandelt.
<br/>
<br/>Wer ist Bevollmächtigter?
<br/>Gemäß Art. 3 Z 5 AIA ist ein Bevollmächtigter
<br/>eine in der Union befindliche oder niedergelassene natürliche oder juristische Person, die vom Anbieter eines KI-Systems oder eines KI-Modells mit allgemeinem Verwendungszweck schriftlich dazu bevollmächtigt wurde und sich damit einverstanden erklärt hat, in seinem Namen die in dieser Verordnung festgelegten Pflichten zu erfüllen bzw. Verfahren durchzuführen.
<br/>Ein Bevollmächtigter wird notwendig, wenn die Anbieter des KI-Systems bzw. des GPAI-Modells nicht innerhalb der Union niedergelassen ist. Damit die Einhaltung der unionsrechtlichen Anforderungen an KI-Systeme bzw. GPAI-Modelle sichergestellt wird, ist die Bestellung eines Bevollmächtigten vorgesehen, der im Namen der Anbieter des KI-Systems bzw. des GPAI-Modells für die Einhaltung der im AI Act festgelegten Pflichten sorgt und auch Verfahren führt. Diese Verpflichtung gilt nicht für Anbieter von ausgenommenen Open-Source-Modellen und -Systemen im Sinne des Art. 2 Abs. 12 AIA.
<br/>Wer ist Einführer?
<br/>Art 3 Z 6 AIA definiert einen Einführer als
<br/>eine in der Union befindliche oder niedergelassene natürliche oder juristische Person, die ein KI-System, das den Namen oder die Handelsmarke einer in einem Drittland niedergelassenen natürlichen oder juristischen Person trägt, in der Union in Verkehr bringt.
<br/>Der Einführer, auch als Importeur bezeichnet, stellt jenes Glied in der KI-Wertschöpfungskette dar, das ein KI-System eines ausländischen Anbieters in der Union in Verkehr bringt. Der Importeur spielt also nur eine Rolle bei KI-Systemen aus Drittländern. In gewissen Situationen kann die Rolle des Einführers mit jener des Händlers zusammenfallen, und zwar dann, wenn der Einführer das KI-System vom Anbieter bezieht und gleichzeitig bereitstellt.
<br/>Unter Umständen kann der Einführer auch als Anbieter behandelt werden (siehe Art. 25 Abs. 1 AIA).
<br/>
<br/>Wer ist Händler?
<br/>Gemäß Art 3 Z 7 AIA wird ein Händler wie folgt legaldefiniert:
<br/>Eine natürliche oder juristische Person in der Lieferkette, die ein KI-System auf dem Unionsmarkt bereitstellt, mit Ausnahme des Anbieters oder des Einführers.
<br/>Beim Händler handelt es sich um jene Person in der KI-Wertschöpfungskette, die ein KI-System auf dem Unionsmarkt bereitstellt. Die reine Bereitstellung kommt in zeitlicher Hinsicht nach dem Inverkehrbringen.
<br/>Unter Umständen kann der Händler auch als Anbieter behandelt werden (siehe Art. 25 Abs. 1 AIA).
<br/>
<br/>Wer ist Betreiber?
<br/>Gemäß Art. 3 Ziffer 4 AIA ist ein Betreiber
<br/>eine natürliche oder juristische Person, Behörde, Einrichtung oder sonstige Stelle, die ein KI-System in eigener Verantwortung verwendet, es sei denn, das KI-System wird im Rahmen einer persönlichen und nicht beruflichen Tätigkeit verwendet.
<br/>Als Betreiber wird jenes Glied in der KI-Wertschöpfungskette bezeichnet, das ein KI-System in eigener Verantwortung verwendet. Beispielhaft werden die Organe, Einrichtungen und sonstigen Stellen der Union genannt (Erwägungsgründe 23). In der KI-Wertschöpfungskette sind sie den Anbietern nachgelagert, sie führen das KI-System in der Praxis aus. Betreiber ist jene Person, Behörde, etc. die entscheidet, ob und wie ein KI-System eingesetzt wird und trägt dafür auch die Verantwortung. Ausgenommen ist vom Betreiber-Begriff die rein private Nutzung von KI-Systemen.
<br/>Unter Umständen kann der Betreiber auch als Anbieter behandelt werden (siehe Art. 25 Abs. 1 AIA).
<br/>
<br/>Wer ist Nutzer?
<br/>Der Begriff „Nutzer“ kommt im AI Act zwar vor, wird aber nicht legaldefiniert. Der Begriff Nutzer wird an verschiedenen Stellten des AI Act genannt, z. B. im Anhang XIII zu finden als „Endnutzer“ und „gewerblicher Nutzer“ oder in verschiedenen Erwägungsgründen (siehe Erwägungsgründe 16: „um es den Nutzern zu ermöglichen“; Erwägungsgründe 102: „Software und Daten, einschließlich Modellen […] die Nutzer kostenlos abrufen, nutzen, verändern und weiter verteilen können“, „wenn sie es den Nutzern ermöglicht“). In der vom Parlament abgestimmten Fassung wurde dieser Begriff teilweise mit dem Betreiber gleichgestellt.
<br/>
<br/> „Betroffene“ Personen
<br/>Je nach Art des KI-Systems kann sich dessen Verwendung auf andere Personen als den Betreiber auswirken (Erwägungsgründe 13 AIA). Damit sind jene Personen gemeint, die Gegenstand des Einsatzes des KI-Systems sind oder in anderweitiger Weise von der Nutzung eines KI-Systems tangiert werden.
<br/>Beispiele hierfür sind auch im AI Act zu finden, wie z. B. die Nutzung eines Chatbot oder die Herstellung künstlicher Audio-, Bild-, Video- oder Textinhalte wie Deepfakes (siehe Art. 50 Abs. 1 und 2 AIA), die Nutzung eines Emotionserkennungssystems oder eines Systems zur biometrischen Kategorisierung (siehe Art. 50 Abs. 3 AIA), die Verwendung eines biometrischen Echtzeit-Fernidentifizierungssystems (Art. 5 Abs. 2 AIA) oder die Inbetriebnahme oder Verwendung eines Hochrisiko-KI-Systems am Arbeitsplatz (Art. 26 Abs. 7 AIA).
<br/>` +
    `Sie führen Quellen als Endnote an, Quellen werden mit Nummer referenziert, in der Form [1].`,
  answer: "Wenn Sie ein KI-System für Ihre Zwecke trainieren möchten, gibt es mehrere Aspekte des AI Act, die Sie beachten sollten. " +
    "Wird ein KI-System verändert oder verfeinert, ist weiterhin der AIA zu beachten [1][2]. \n"+
    "Dabei gilt die natürliche oder juristische Person, Behörde, Einrichtung oder sonstige Stelle, die ein KI-System entwickelt oder" +
    "entwickeln lässt und unter eigenen Namen oder ihrer Handelsmarke in Verkehr bringt oder das KI-System unter ihrem eigenen Namen oder "+
    "ihrer Handelsmarke in Betrieb nimmt, sei es entgeltlich oder unentgeltlich, als Anbieter eines KI-Systems [3][4]. \n"+
    "Welche Pflichten einzuhalten sind, hängt von der Risikostufe ab. KI-Systeme werden entsprechend ihrem Risikopotential nach inakzeptablem, hohem, geringem und minimalem Risiko kategorisiert. \n"+
    "* Inakzeptables Risiko: Diese Systeme sind vollständig verboten, z.B. Systeme, die Methoden zur sozialen Manipulation oder Bewertung enthalten \n"+
    "* Hohes Risiko: Diese Systeme unterliegen strengen Anforderungen und müssen vor der Inbetriebnahme eine Konformitätsbewertung durchlaufen. Beispiele sind KI im Bereich der Strafverfolgung, Gesundheitswesen, oder kritische Infrastrukturen. \n" +
    "* Begrenztes Risiko: Diese Systeme unterliegen Transparenzanforderungen \n" +
    "* Minimales Risiko: Diese Systeme unterliegen keinen obligatorischen Pflichten des AIA Act. Beispiele sind wie Spamfilter.[5] \n" +
    "[1] Art 25 AIA,\n[2] ErwGr 97 AIA,\n[3] Art 3 Z 3 AIA,\n[4] KI-Servicestelle: Akteure,\n[5] KI-Servicestelle: Anbieterverpflichtungen"
}

export const answer2 : answer = {
  sources: [
    "Art 3 Z 3 AI Act (75 %)",
    "Art 3 Z 4 AI Act (72 %)",
    "Art 50 AI Act (71 %)",
    "ErwGr 134 AI Act (65 %)",
    "KI-Servicestelle: Risikostufen KI-Systeme (82 %)",
    "KI-Servicestelle: Akteure (71 %)",
    "KI-Servicestelle: Betreiberverpflichtungen (68 %)"
  ],
    prompt:
      "Sie sind Senior-Partner in einer östereichischen Großkanzlei. Sie beantworten Mandantenanfragen höflich, präzise und genau. Sie verwenden ausschließlich die Ihnen übergebenen Quellen um Ihre Subsumptionen durchzuführen.<br/>Folgende Kundenanfrage " +
      `ist bei Ihnen gestern eingegangen: <br/><br/>"""<br/>%%%USERPROMPT%%%<br/>"""<br/><br/>Sie verwenden dazu folgende Quellen:<br/>`+
      `<br/>Quellen:<br/><br/>` +
      `Artikel 3 AI Act: Begriffsbestimmungen<br/
Für die Zwecke dieser Verordnung bezeichnet der Ausdruck<br/>
1.\t„KI-System“ ein maschinengestütztes System, das für einen in unterschiedlichem Grade autonomen Betrieb ausgelegt ist und das nach seiner Betriebsaufnahme anpassungsfähig sein kann und das aus den erhaltenen Eingaben für explizite oder implizite Ziele ableitet, wie Ausgaben wie etwa Vorhersagen, Inhalte,Empfehlungen oder Entscheidungen erstellt werden, die physische oder virtuelle Umgebungen beeinflussen können;<br/>
2.\t„Risiko“ die Kombination aus der Wahrscheinlichkeit des Auftretens eines Schadens und der Schwere dieses Schadens;<br/>
3.\t„Anbieter“ eine natürliche oder juristische Person, Behörde, Einrichtung oder sonstige Stelle, die ein KI-System oder ein KI-Modell mit allgemeinem Verwendungszweck entwickelt oder entwickeln lässt und es unter ihrem eigenen Namen oder ihrer Handelsmarke in Verkehr bringt oder das KI-System unter ihrem eigenen Namen oder ihrer Handelsmarke in Betrieb nimmt, sei es entgeltlich oder unentgeltlich;<br/>
4.\t„Betreiber“ eine natürliche oder juristische Person, Behörde, Einrichtung oder sonstige Stelle, die ein KI-System in eigener Verantwortung verwendet, es sei denn, das KI-System wird im Rahmen einer persönlichen und nicht beruflichen Tätigkeit verwendet;<br/>
5.\t„Bevollmächtigter“ eine in der Union ansässige oder niedergelassene natürliche oder juristische Person, die vom Anbieter eines KI-Systems oder eines KI-Modells mit allgemeinem Verwendungszweck schriftlich dazu bevollmächtigt wurde und sich damit einverstanden erklärt hat, in seinem Namen die in dieser Verordnung festgelegten Pflichten zu erfüllen bzw. Verfahren durchzuführen;<br/>
6.\t„Einführer“ eine in der Union ansässige oder niedergelassene natürliche oder juristische Person, die ein KI-System, das den Namen oder die Handelsmarke einer in einem Drittland niedergelassenen natürlichen oder juristischen Person trägt, in Verkehr bringt;<br/>
7.\t„Händler“ eine natürliche oder juristische Person in der Lieferkette, die ein KI-System auf dem Unionsmarkt bereitstellt, mit Ausnahme des Anbieters oder des Einführers;<br/>
8.\t„Akteur“ einen Anbieter, Produkthersteller, Betreiber, Bevollmächtigten, Einführer oder Händler;<br/>
9.\t„Inverkehrbringen“ die erstmalige Bereitstellung eines KI-Systems oder eines KI-Modells mit allgemeinem Verwendungszweck auf dem Unionsmarkt;<br/>
10.\t„Bereitstellung auf dem Markt“ die entgeltliche oder unentgeltliche Abgabe eines KI-Systems oder eines KI-Modells mit allgemeinem Verwendungszweck zum Vertrieb oder zur Verwendung auf dem Unionsmarkt im Rahmen einer Geschäftstätigkeit;<br/>
11.\t„Inbetriebnahme“ die Bereitstellung eines KI-Systems in der Union zum Erstgebrauch direkt an den Betreiber oder zum Eigengebrauch entsprechend seiner Zweckbestimmung;<br/>
12.\t„Zweckbestimmung“ die Verwendung, für die ein KI-System laut Anbieter bestimmt ist, einschließlich der besonderen Umstände und Bedingungen für die Verwendung, entsprechend den vom Anbieter bereitgestellten Informationen in den Betriebsanleitungen, im Werbe- oder Verkaufsmaterial und in diesbezüglichen Erklärungen sowie in der technischen Dokumentation;<br/>
13.\t„vernünftigerweise vorhersehbare Fehlanwendung“ die Verwendung eines KI-Systems in einer Weise, die nicht seiner Zweckbestimmung entspricht, die sich aber aus einem vernünftigerweise vorhersehbaren menschlichen Verhalten oder einer vernünftigerweise vorhersehbaren Interaktion mit anderen Systemen, auch anderen KI-Systemen, ergeben kann;<br/>
14.\t„Sicherheitsbauteil“ einen Bestandteil eines Produkts oder KI-Systems, der eine Sicherheitsfunktion für dieses Produkt oder KI-System erfüllt oder dessen Ausfall oder Störung die Gesundheit und Sicherheit von Personen oder Eigentum gefährdet;<br/>
15.\t„Betriebsanleitungen“ die Informationen, die der Anbieter bereitstellt, um den Betreiber insbesondere über die Zweckbestimmung und die ordnungsgemäße Verwendung eines KI-Systems zu informieren;<br/>
16.\t„Rückruf eines KI-Systems“ jede Maßnahme, die auf die Rückgabe an den Anbieter oder auf die Außerbetriebsetzung oder Abschaltung eines den Betreibern bereits zur Verfügung gestellten KI-Systems abzielt;<br/>
17.\t„Rücknahme eines KI-Systems“ jede Maßnahme, mit der die Bereitstellung eines in der Lieferkette befindlichen KI-Systems auf dem Markt verhindert werden soll;<br/>
18.\t„Leistung eines KI-Systems“ die Fähigkeit eines KI-Systems, seine Zweckbestimmung zu erfüllen;<br/>
19.\t„notifizierende Behörde“ die nationale Behörde, die für die Einrichtung und Durchführung der erforderlichen Verfahren für die Bewertung, Benennung und Notifizierung von Konformitätsbewertungsstellen und für deren Überwachung zuständig ist;<br/>
20.\t„Konformitätsbewertung“ ein Verfahren mit dem bewertet wird, ob die in Titel II Abschnitt 2 festgelegten Anforderungen an ein Hochrisiko-KI-System erfüllt wurden;<br/>
21.\t„Konformitätsbewertungsstelle“ eine Stelle, die Konformitätsbewertungstätigkeiten einschließlich Prüfungen, Zertifizierungen und Inspektionen durchführt und dabei als Dritte auftritt;<br/>
22.\t„notifizierte Stelle“ eine Konformitätsbewertungsstelle, die gemäß dieser Verordnung und den anderen einschlägigen Harmonisierungsrechtsvorschriften der Union notifiziert wurde;<br/>
23.\t„wesentliche Veränderung“ eine Veränderung eines KI-Systems nach dessen Inverkehrbringen oder Inbetriebnahme, die in der vom Anbieter durchgeführten ursprünglichen Konformitätsbewertung nicht vorgesehen oder geplant war und durch die die Konformität des KI-Systems mit den Anforderungen in Kapitel III Abschnitt 2 beeinträchtigt wird oder die zu einer Änderung der Zweckbestimmung führt, für die das KI-System bewertet wurde;<br/>
24.\t„CE-Kennzeichnung“ eine Kennzeichnung, durch die ein Anbieter erklärt, dass ein KI-System die Anforderungen erfüllt, die in Kapitel III Abschnitt 2 und in anderen anwendbaren Harmonisierungsrechtsvorschriften, die die Anbringung dieser Kennzeichnung vorsehen, festgelegt sind;<br/>
25.\t„System zur Beobachtung nach dem Inverkehrbringen“ alle Tätigkeiten, die Anbieter von KI-Systemen zurSammlung und Überprüfung von Erfahrungen mit der Verwendung der von ihnen in Verkehr gebrachten oder in Betrieb genommenen KI-Systeme durchführen, um festzustellen, ob unverzüglich nötige Korrektur- oder Präventivmaßnahmen zu ergreifen sind;<br/>
26.\t„Marktüberwachungsbehörde“ die nationale Behörde, die die Tätigkeiten durchführt und die Maßnahmen ergreift, die in der Verordnung (EU) 2019/1020 vorgesehen sind;<br/>
27.\t„harmonisierte Norm“ bezeichnet eine harmonisierte Norm im Sinne des Artikels 2 Absatz 1 Buchstabe c der Verordnung (EU) Nr. 1025/2012;<br/>
28.\t„gemeinsame Spezifikation“ eine Reihe technischer Spezifikationen im Sinne des Artikels 2 Nummer 4 der Verordnung (EU) Nr. 1025/2012, deren Befolgung es ermöglicht, bestimmte Anforderungender vorliegenden Verordnung zu erfüllen;<br/>
29.\t„Trainingsdaten“ Daten, die zum Trainieren eines KI-Systems verwendet werden, wobei dessen lernbare Parameterangepasst werden;<br/>
30.\t„Validierungsdaten“ Daten, die zur Evaluation des trainierten KI-Systems und zur Einstellung seiner nicht erlernbaren Parameter und seines Lernprozesses verwendet werden, um unter anderem eine Unter- oder Überanpassung zu vermeiden;<br/>
31.\t„Validierungsdatensatz“ einen separaten Datensatz oder einen Teil des Trainingsdatensatzes mit fester oder variabler Aufteilung;<br/>
32.\t„Testdaten“ Daten, die für eine unabhängige Bewertung desKI-Systems verwendet werden, um die erwartete Leistung dieses Systems vor dessen Inverkehrbringen oder Inbetriebnahme zu bestätigen;<br/>
33.\t„Eingabedaten“ die in ein KI-System eingespeisten oder von diesem direkt erfassten Daten, auf deren Grundlage das System eine Ausgabe hervorbringt;<br/>
34.\t„biometrische Daten“ mit speziellen technischen Verfahren gewonnene personenbezogene Daten zu den physischen, physiologischen oder verhaltenstypischen Merkmalen einer natürlichen Person, wie etwa Gesichtsbilder oder daktyloskopische Daten;<br/>
35.\t„biometrische Identifizierung“ die automatisierte Erkennung physischer, physiologischer, verhaltensbezogener oder psychologischer menschlicher Merkmale zum Zwecke der Feststellung der Identität einer natürlichen Person durch den Vergleich biometrischer Daten dieser Person mit biometrischen Daten von Personen, die in einer Datenbank gespeichert sind;<br/>
36.\t„biometrische Verifizierung“ die automatisierte Eins-zu-eins-Verifizierung, einschließlich Authentifizierung, der Identität natürlicher Personen durch den Vergleich ihrer biometrischen Daten mit zuvor bereitgestellten biometrischen Daten;<br/>
37.\t„besondere Kategorien personenbezogener Daten“ die in Artikel 9 Absatz 1der Verordnung (EU) 2016/679, Artikel 10 der Richtlinie (EU) 2016/680 und Artikel 10 Absatz 1 der Verordnung (EU) 2018/1725 aufgeführten Kategorien personenbezogener Daten;<br/>
38.\t„sensible operative Daten“ operative Daten im Zusammenhang mit Tätigkeiten zur Verhütung, Aufdeckung, Untersuchung oder Verfolgung von Straftaten, deren Offenlegung die Integrität von Strafverfahren gefährden könnte;<br/>
39.\t„Emotionserkennungssystem“ ein KI-System, das dem Zweck dient, Emotionen oder Absichten natürlicher Personen auf der Grundlage ihrer biometrischen Daten festzustellen oder daraus abzuleiten;<br/>
40.\t„System zur biometrischen Kategorisierung“ ein KI-System, das dem Zweck dient, natürliche Personen auf der Grundlage ihrer biometrischen Daten bestimmten Kategorienzuzuordnen, sofern es sich um eine Nebenfunktion eines anderen kommerziellen Dienstes handelt und aus objektiven technischen Gründen unbedingt erforderlich ist;<br/>
41.\t„biometrisches Fernidentifizierungssystem“ ein KI-System, das dem Zweck dient, natürliche Personen ohne ihre aktive Einbeziehung und in der Regel aus der Fernedurch Abgleich der biometrischen Daten einer Person mit den in einer Referenzdatenbank gespeicherten biometrischen Daten zu identifizieren;<br/>
42.\t„biometrisches Echtzeit-Fernidentifizierungssystem“ ein biometrisches Fernidentifizierungssystem, bei dem die Erfassung biometrischer Daten, der Abgleich und die Identifizierung ohne erhebliche Verzögerung erfolgen, und das zur Vermeidung einer Umgehung der Vorschriften nicht nur die sofortige Identifizierung, sondern auch eine Identifizierung mit begrenzten kurzen Verzögerungen umfasst;<br/>
43.\t„System zur nachträglichen biometrischen Fernidentifizierung“ ein biometrisches Fernidentifizierungssystem, das kein biometrisches Echtzeit-Fernidentifizierungssystem ist;<br/>
44.\t„öffentlich zugänglicher Raum“ einen einer unbestimmten Anzahl natürlicher Personen zugänglichen physischen Ort in privatem oder öffentlichem Eigentum, unabhängig davon, ob bestimmte Bedingungen für den Zugang gelten, und unabhängig von möglichen Kapazitätsbeschränkungen;<br/>
45.\t„Strafverfolgungsbehörde“<br/>
a)\teine Behörde, die für die Verhütung, Ermittlung, Aufdeckung oder Verfolgung von Straftaten oder die Strafvollstreckung, einschließlich des Schutzes vor und der Abwehr von Gefahren für die öffentliche Sicherheit, zuständig ist, oder<br/>
b)\teine andere Stelle oder Einrichtung, der durch nationales Recht die Ausübung öffentlicher Gewalt und hoheitlicher Befugnisse zur Verhütung, Ermittlung, Aufdeckung oder Verfolgung von Straftaten oder zur Strafvollstreckung, einschließlich des Schutzes vor und der Abwehr von Gefahren für die öffentliche Sicherheit, übertragen wurde;<br/>
46.\t„Strafverfolgung“ Tätigkeiten der Strafverfolgungsbehörden oder in deren Auftrag zur Verhütung, Ermittlung, Aufdeckung oder Verfolgung von Straftaten oder zur Strafvollstreckung, einschließlich des Schutzes vor und der Abwehr von Gefahren für die öffentliche Sicherheit;<br/>
47.\t„Büro für Künstliche Intelligenz“ die Aufgabe der Kommission, zur Umsetzung, Beobachtung und Überwachung von KI-Systemen und KI-Modellen mit allgemeinem Verwendungszweck und zu der im Beschluss der Kommission vom 24. Januar 2024 vorgesehenen KI-Governance beizutragen; Bezugnahmen in dieser Verordnung auf das Büro für Künstliche Intelligenz gelten als Bezugnahmen auf die Kommission;<br/>
48.\t„zuständige nationale Behörde“ eine notifizierende Behörde oder eine Marktüberwachungsbehörde; in Bezug auf KI-Systeme, die von Organen, Einrichtungen und sonstigen Stellen der Union in Betrieb genommen oder verwendet werden, sind Bezugnahmen auf die zuständigen nationalen Behörden oder Marktüberwachungsbehörden in dieser Verordnung als Bezugnahmen auf den Europäischen Datenschutzbeauftragten auszulegen;<br/>
49.\t„schwerwiegender Vorfall“ einen Vorfall oder eine Fehlfunktion bezüglich eines KI-Systems, das bzw. die direkt oder indirekt eine der nachstehenden Folgen hat:<br/>
a)\tden Tod oder die schwere gesundheitliche Schädigung einer Person;<br/>
b)\teine schwere und unumkehrbare Störung der Verwaltung oder des Betriebs kritischer Infrastrukturen;<br/>
c)\tdie Verletzung von Pflichten aus den Unionsrechtsvorschriften zum Schutz der Grundrechte;<br/>
d)\tschwere Sach- oder Umweltschäden;<br/>
50.\t„personenbezogene Daten“ personenbezogene Daten im Sinne von Artikel 4 Nummer 1 der Verordnung (EU) 2016/679;<br/>
51.\t„nicht personenbezogene Daten“ Daten, die keine personenbezogenen Daten im Sinne von Artikel 4 Nummer 1 der Verordnung (EU) 2016/679 sind;<br/>
52.\t„Profiling“ das Profiling im Sinne von Artikel 4 Nummer 4 der Verordnung (EU) 2016/679;<br/>
53.\t„Plan für einen Test unter Realbedingungen“ ein Dokument, in dem die Ziele, die Methodik, der geografische, bevölkerungsbezogene und zeitliche Umfang, die Überwachung, die Organisation und die Durchführung eines Tests unter Realbedingungen beschrieben werden;<br/>
54.\t„Plan für das Reallabor“ ein zwischen dem teilnehmenden Anbieter und der zuständigen Behörde vereinbartes Dokument, in dem die Ziele, die Bedingungen, der Zeitrahmen, die Methodik und die Anforderungen für die im Reallabor durchgeführten Tätigkeiten beschrieben werden;<br/>
55.\t„KI-Reallabor“ einen kontrollierten Rahmen, der von einer zuständigen Behörde geschaffen wird und den Anbieter oder zukünftige Anbieter von KI-Systemen nach einem Plan für das Reallabor einen begrenzten Zeitraum und unter regulatorischer Aufsicht nutzen können, um ein innovatives KI-System zu entwickeln, zu trainieren, zu validieren und – gegebenenfalls unter Realbedingungen – zu testen.<br/>
56.\t„KI-Kompetenz“ die Fähigkeiten, die Kenntnisse und das Verständnis, die es Anbietern, Betreibern und Betroffenen unter Berücksichtigung ihrer jeweiligen Rechte und Pflichten im Rahmen dieser Verordnung ermöglichen, KI-Systeme sachkundig einzusetzen sowie sich der Chancen und Risiken von KI und möglicher Schäden, die sie verursachen kann, bewusst zu werden.<br/>
57.\t„Test unter Realbedingungen“ den befristeten Test eines KI-Systems auf seine Zweckbestimmung, der unter Realbedingungen außerhalb eines Labors oder einer anderweitig simulierten Umgebung erfolgt, um zuverlässige und belastbare Daten zu erheben und die Konformität des KI-Systems mit den Anforderungen der vorliegenden Verordnung zu bewerten und zu überprüfen, wobei dieser Test nicht als Inverkehrbringen oder Inbetriebnahme des KI-Systems im Sinne dieser Verordnung gilt, sofern alle Bedingungen nach Artikel 57 oder Artikel 60 erfüllt sind;<br/>
58.\t„Testteilnehmer“ für die Zwecke eines Tests unter Realbedingungen eine natürliche Person, die an dem Test unter Realbedingungen teilnimmt;<br/>
59.\t„informierte Einwilligung“ eine aus freien Stücken erfolgende, spezifische, eindeutige und freiwillige Erklärung der Bereitschaft, an einem bestimmten Test unter Realbedingungen teilzunehmen, durch einen Testteilnehmer, nachdem dieser über alle Aspekte des Tests, die für die Entscheidungsfindung des Testteilnehmers bezüglich der Teilnahme relevant sind, aufgeklärt wurde;<br/>
60.\t„Deepfake“ einen durch KI erzeugten oder manipulierten Bild-, Ton- oder Videoinhalt, der wirklichen Personen, Gegenständen, Orten, Einrichtungen oder Ereignissen ähnelt und einer Person fälschlicherweise als echt oder wahrheitsgemäß erscheinen würde;<br/>
61.\t„weitverbreiteter Verstoß“ jede Handlung oder Unterlassung, die gegen das Unionsrecht verstößt, das die Interessen von Einzelpersonen schützt, und die<br/>
a)\tdie kollektiven Interessen von Einzelpersonen in mindestens zwei anderen Mitgliedstaaten als dem Mitgliedstaat schädigt oder zu schädigen droht, in dem<br/>
i)\tdie Handlung oder die Unterlassung ihren Ursprung hatte oder stattfand,<br/>
ii)\tder betreffende Anbieter oder gegebenenfalls sein Bevollmächtigter sich befindet oder niedergelassen ist oder<br/>
iii)\tder Betreiber niedergelassen ist, sofern der Verstoß vom Betreiber begangen wird,<br/>
b)\tdie kollektiven Interessen von Einzelpersonen geschädigt hat, schädigt oder schädigen könnte und allgemeine Merkmale aufweist, einschließlich derselben rechtswidrigen Praxis oder desselben verletzten Interesses, und gleichzeitig auftritt und von demselben Akteur in mindestens drei Mitgliedstaaten begangen wird;<br/>
62.\t„kritische Infrastrukturen“ kritische Infrastrukturen im Sinne von Artikel 2 Nummer 4 der Richtlinie (EU) 2022/2557;<br/>
63.\t„KI-Modell mit allgemeinem Verwendungszweck“ ein KI-Modell – einschließlich der Fälle, in denen ein solches KI-Modell mit einer großen Datenmenge unter umfassender Selbstüberwachung trainiert wird –, das eine erhebliche allgemeine Verwendbarkeit aufweist und in der Lage ist, unabhängig von der Art und Weise seines Inverkehrbringens ein breites Spektrum unterschiedlicher Aufgaben kompetent zu erfüllen, und das in eine Vielzahl nachgelagerter Systeme oder Anwendungen integriert werden kann, ausgenommen KI-Modelle, die vor ihrem Inverkehrbringen für Forschungs- und Entwicklungstätigkeiten oder die Konzipierung von Prototypen eingesetzt werden;<br/>
64.\t„Fähigkeiten mit hoher Wirkkraft“ bezeichnet Fähigkeiten, die den bei den fortschrittlichsten KI-Modellen mit allgemeinem Verwendungszweck festgestellten Fähigkeiten entsprechen oder diese übersteigen;<br/>
65.\t„systemisches Risiko“ ein Risiko, das für die Fähigkeiten mit hoher Wirkkraft von KI-Modellen mit allgemeinem Verwendungszweck spezifisch ist und aufgrund deren Reichweite oder aufgrund tatsächlicher oder vernünftigerweise vorhersehbarer negativer Folgen für die öffentliche Gesundheit, die Sicherheit, die öffentliche Sicherheit, die Grundrechte oder die Gesellschaft insgesamt erhebliche Auswirkungen auf den Unionsmarkt hat, die sich in großem Umfang über die gesamte Wertschöpfungskette hinweg verbreiten können;<br/>
66.\t„KI-System mit allgemeinem Verwendungszweck“ ein KI-System, das auf einem KI-Modell mit allgemeinem Verwendungszweck beruht und in der Lage ist, einer Vielzahl von Zwecken sowohl für die direkte Verwendung als auch für die Integration in andere KI-Systeme zu dienen;<br/>
67.\t„Gleitkommaoperation“ jede Rechenoperation oder jede Zuweisung mit Gleitkommazahlen, bei denen es sich um eine Teilmenge der reellen Zahlen handelt, die auf Computern typischerweise durch das Produkt aus einer ganzen Zahl mit fester Genauigkeit und einer festen Basis mit ganzzahligem Exponenten dargestellt wird;<br/>
68.\t„nachgelagerter Anbieter“ einen Anbieter eines KI-Systems, einschließlich eines KI-Systems mit allgemeinem Verwendungszweck, das ein KI-Modell integriert, unabhängig davon, ob das KI-Modell von ihm selbst bereitgestellt und vertikal integriert wird oder von einer anderen Einrichtung auf der Grundlage vertraglicher Beziehungen bereitgestellt wird.<br/>
<br/><br/>
Erwägungsgrund 134: Neben den technischen Lösungen, die von den Anbietern von KI-Systemen eingesetzt werden, sollten Betreiber, die ein KI-System zum Erzeugen oder Manipulieren von Bild-, Audio- oder Videoinhalte verwenden, die wirklichen Personen, Gegenständen, Orten, Einrichtungen oder Ereignissen merklich ähneln und einer Person fälschlicherweise echt oder wahr erscheinen würden (Deepfakes), auch klar und deutlich offenlegen, dass die Inhalte künstlich erzeugt oder manipuliert wurden, indem sie die Ausgaben von KI entsprechend kennzeichnen und auf ihren künstlichen Ursprung hinweisen. Die Einhaltung dieser Transparenzpflicht sollte nicht so ausgelegt werden, dass sie darauf hindeutet, dass die Verwendung des KI-Systems oder seiner Ausgabe das Recht auf freie Meinungsäußerung und das Recht auf Freiheit der Kunst und Wissenschaft, die in der Charta garantiert sind, behindern, insbesondere wenn der Inhalt Teil eines offensichtlich kreativen, satirischen, künstlerischen, fiktionalen oder analogen Werks oder Programms ist und geeignete Schutzvorkehrungen für die Rechte und Freiheiten Dritter bestehen. In diesen Fällen beschränkt sich die in dieser Verordnung festgelegte Transparenzpflicht für Deepfakes darauf, das Vorhandenseins solcher erzeugten oder manipulierten Inhalte in geeigneter Weise offenzulegen, die die Darstellung oder den Genuss des Werks, einschließlich seiner normalen Nutzung und Verwendung, nicht beeinträchtigt und gleichzeitig den Nutzen und die Qualität des Werks aufrechterhält. Darüber hinaus ist es angezeigt, eine ähnliche Offenlegungspflicht in Bezug auf durch KI erzeugte oder manipulierte Texte anzustreben, soweit diese veröffentlicht werden, um die Öffentlichkeit über Angelegenheiten von öffentlichem Interesse zu informieren, es sei denn, die durch KI erzeugten Inhalte wurden einem Verfahren der menschlichen Überprüfung oder redaktionellen Kontrolle unterzogen und eine natürliche oder juristische Person trägt die redaktionelle Verantwortung für die Veröffentlichung der Inhalte.
<br/><br/>
-----
<br/><br/>
Artikel 50: Transparenzpflichten für Anbieter und Betreiber bestimmter KI-Systeme<br/>
(1) Die Anbieter stellen sicher, dass KI-Systeme, die für die direkte Interaktion mit natürlichen Personen bestimmt sind, so konzipiert und entwickelt werden, dass die betreffenden natürlichen Personen informiert werden, dass sie mit einem KI-System interagieren, es sei denn, dies ist aus Sicht einer angemessen informierten, aufmerksamen und verständigen natürlichen Person aufgrund der Umstände und des Kontexts der Nutzung offensichtlich. Diese Pflicht gilt nicht für gesetzlich zur Aufdeckung, Verhütung, Ermittlung oder Verfolgung von Straftaten zugelassene KI-Systeme, wenn geeignete Schutzvorkehrungen für die Rechte und Freiheiten Dritter bestehen, es sei denn, diese Systeme stehen der Öffentlichkeit zur Anzeige einer Straftat zur Verfügung.<br/>
(2) Anbieter von KI-Systemen, einschließlich KI-Systemen mit allgemeinem Verwendungszweck, die synthetische Audio-, Bild-, Video- oder Textinhalte erzeugen, stellen sicher, dass die Ausgaben des KI-Systems in einem maschinenlesbaren Format gekennzeichnet und als künstlich erzeugt oder manipuliert erkennbar sind. Die Anbieter sorgen dafür, dass – soweit technisch möglich – ihre technischen Lösungen wirksam, interoperabel, belastbar und zuverlässig sind und berücksichtigen dabei die Besonderheiten und Beschränkungen der verschiedenen Arten von Inhalten, die Umsetzungskosten und den allgemein anerkannten Stand der Technik, wie er in den einschlägigen technischen Normen zum Ausdruck kommen kann. Diese Pflicht gilt nicht, soweit die KI-Systeme eine unterstützende Funktion für die Standardbearbeitung ausführen oder die vom Betreiber bereitgestellten Eingabedaten oder deren Semantik nicht wesentlich verändern oder wenn sie zur Aufdeckung, Verhütung, Ermittlung oder Verfolgung von Straftaten gesetzlich zugelassen sind.<br/>
(3) Die Betreiber eines Emotionserkennungssystems oder eines Systems zur biometrischen Kategorisierung informieren die davon betroffenen natürlichen Personen über den Betrieb des Systems und verarbeiten personenbezogene Daten gemäß den Verordnungen (EU) 2016/679 und (EU) 2016/1725 und der Richtlinie (EU) 2016/680. Diese Pflicht gilt nicht für gesetzlich zur Aufdeckung, Verhütung oder Ermittlung von Straftaten zugelassene KI-Systeme, die zur biometrischen Kategorisierung und Emotionserkennung im Einklang mit dem Unionsrecht verwendet werden, sofern geeignete Schutzvorkehrungen für die Rechte und Freiheiten Dritter bestehen.<br/>
(4) Betreiber eines KI-Systems, das Bild-, Ton- oder Videoinhalte erzeugt oder manipuliert, die ein Deepfake sind, müssen offenlegen, dass die Inhalte künstlich erzeugt oder manipuliert wurden. Diese Pflicht gilt nicht, wenn die Verwendung zur Aufdeckung, Verhütung, Ermittlung oder Verfolgung von Straftaten gesetzlich zugelassen ist. Ist der Inhalt Teil eines offensichtlich künstlerischen, kreativen, satirischen, fiktionalen oder analogen Werks oder Programms, so beschränken sich die in diesem Absatz festgelegten Transparenzpflichten darauf, das Vorhandensein solcher erzeugten oder manipulierten Inhalte in geeigneter Weise offenzulegen, die die Darstellung oder den Genuss des Werks nicht beeinträchtigt.<br/>
Betreiber eines KI-Systems, das Text erzeugt oder manipuliert, der veröffentlicht wird, um die Öffentlichkeit über Angelegenheiten von öffentlichem Interesse zu informieren, müssen offenlegen, dass der Text künstlich erzeugt oder manipuliert wurde. Diese Pflicht gilt nicht, wenn die Verwendung zur Aufdeckung, Verhütung, Ermittlung oder Verfolgung von Straftaten gesetzlich zugelassen ist oder wenn die durch KI erzeugten Inhalte einem Verfahren der menschlichen Überprüfung oder redaktionellen Kontrolle unterzogen wurden und wenn eine natürliche oder juristische Person die redaktionelle Verantwortung für die Veröffentlichung der Inhalte trägt.<br/>
(5) Die in den Absätzen 1 bis 4 genannten Informationen werden den betreffenden natürlichen Personen spätestens zum Zeitpunkt der ersten Interaktion oder Aussetzung in klarer und eindeutiger Weise bereitgestellt. Die Informationen müssen den geltenden Barrierefreiheitsanforderungen entsprechen.<br/>
(6) Die Absätze 1 bis 4 lassen die in Kapitel III festgelegten Anforderungen und Pflichten unberührt und berühren nicht andere Transparenzpflichten, die im Unionsrecht oder dem nationalen Recht für Betreiber von KI-Systemen festgelegt sind.<br/>
(7) Das Büro für Künstliche Intelligenz fördert und erleichtert die Ausarbeitung von Praxisleitfäden auf Unionsebene, um die wirksame Umsetzung der Pflichten in Bezug auf die Feststellung und Kennzeichnung künstlich erzeugter oder manipulierter Inhalte zu erleichtern. Die Kommission kann Durchführungsrechtsakte zur Genehmigung dieser Praxisleitfäden nach dem in Artikel 56 Absatz 6 festgelegten Verfahren erlassen. Hält sie einen Kodex für nicht angemessen, so kann die Kommission einen Durchführungsrechtsakt gemäß dem in Artikel 98 Absatz 2 genannten Prüfverfahren erlassen, in dem gemeinsame Vorschriften für die Umsetzung dieser Pflichten festgelegt werden.
<br/><br/>
-----
<br/><br/>
Quelle: Übersicht: Die Akteure im AI Act
<br/>Der AI Act sieht viele Rollen in der KI-Wertschöpfungskette vor. Die verschiedenen Akteure sind dabei keineswegs unbekannt, der Unionsgesetzgeber orientierte sich dabei in vielerlei Hinsicht an den EU-Produktrechtsnormen (siehe etwa die Produktsicherheitsverordnung, Medizinprodukteverordnung).
<br/>Zu den Akteuren im AI Act zählen gemäß Art. 3 Ziffer 8:
<br/>Anbieter („Provider“);
<br/>Produkthersteller („Product Manufacturer“);
<br/>Bevollmächtigter („Authorised Representative“);
<br/>Einführer („Importer“);
<br/>Händler („Distributor“);
<br/>Betreiber („Deployer“).
<br/>Ferner kommen auch noch Nutzer und „betroffene Personen“ vor. Diese werden aber nicht als Akteure im Sinne des AI Act bezeichnet.
<br/>Inverkehrbringen, Bereitstellen, Inbetriebnahme
<br/>Die verschiedenen Akteure übernehmen verschiedene Tätigkeiten in der KI-Wertschöpfungskette. Unterschieden wird dabei in „Inverkehrbringen“, „Bereitstellen“ und der „Inbetriebnahme“, die im AI Act auch legaldefiniert werden. Diese Begriffe sind nicht neu, kommen sie doch bereits im EU-Produktrecht vor.
<br/>Mit „Inverkehrbringen“ ist gemäß Art. 3 Ziffer 9 AIA „die erstmalige Bereitstellung eines KI-Systems oder eines GPAI-Modell auf dem Unionsmarkt“ gemeint. Laut Definition erfasst das Inverkehrbringen zugleich die „Bereitstellung auf dem Markt“, was wiederum „die entgeltliche oder unentgeltliche Bereitstellung eines KI-Systems oder eines KI-Modells mit allgemeinem Verwendungszweck zum Vertrieb oder zur Verwendung auf dem Unionsmarkt im Rahmen einer Geschäftstätigkeit“ bezeichnet (Art. 3 Ziffer 10 AIA).
<br/>Der Unterschied zwischen „Inverkehrbringen“ und „Bereitstellen“ liegt darin, dass beim Inverkehrbringen die Bereitstellung auf dem Markt erstmalig erfolgt. Das Inverkehrbringen übernimmt innerhalb der EU in der Regel der Hersteller des Produkts bzw. im Falle des KI-Systems/GPAI-Modell der Anbieter; bei Produkten bzw. KI-Systemen außerhalb der EU der Importeur. Ist die erstmalige Bereitstellung erfolgt, wird die weitere Bereitstellung (umgangssprachlich als „Vertrieb“ bezeichnet) für gewöhnlich vom Händler übernommen, die typische Tätigkeiten wie den Verkauf, die Lagerung, den Transport (etwa bei in physischen Produkten integrierte Hochrisiko-KI-Systeme), die Kundenbetreuung oder die Wartung übernehmen.
<br/>Diese Form der Lieferkette stellt vor allem den traditionellen Weg einer Lieferkette dar, wo das Produkt vom Hersteller über den Importeur und (Zwischen-)Händler ihren Weg zum Endkunden findet. Mit dem Fernabsatz haben sich auch neue Vertriebsformen entwickelt. Anbieter und Händler aus Drittstaaten können ihre Produkte durch Online-Schnittstellen am Unionsmarkt anbieten, was vor allem Anbieter auch das Ausklammern bestimmter Akteure (z. B. Händler) ermöglicht. Gerade bei digitalen Produkten wie Software-Anwendungen, welche durch einen simplen Download erworben werden können, spielt diese Form des Absatzes eine bedeutsame Rolle.
<br/>Auf die Veränderungen der Absatzformen hat auch der Unionsgesetzgeber in der Marktüberwachungsverordnung (Erwägungsgründe 15) reagiert: Wird ein Produkt online oder über eine andere Form des Fernabsatzes angeboten, so sollte das Produkt als auf dem Markt bereitgestellt gelten, wenn sich das Verkaufsangebot an Endnutzer in der Union richtet. Ob ein solches Verkaufsangebot an Endnutzer vorliegt, ist eine Einzelfallentscheidung und hat unter Berücksichtigung von Kriterien wie etwa die geografischen Gebiete, in die geliefert werden kann, die für das Angebot oder für die Bestellung verfügbaren Sprachen und die Zahlungsarten zu erfolgen. Die bloße Zugänglichkeit der Website des Akteurs reicht für sich alleine nicht aus, eine Bereitstellung auf dem Unionsmarkt anzunehmen.
<br/>Mit „Inbetriebnahme“ wird gemäß Art. 3 Ziffer 11 AIA „die Bereitstellung eines KI-Systems durch den Anbieter in der Union zum Erstgebrauch direkt an den Betreiber oder zum Eigengebrauch entsprechend seiner Zweckbestimmung“ bezeichnet. Mit „Zweckbestimmung“ wird kurzgefasst die Verwendung, für die ein KI-System laut Anbieter bestimmt oder propagiert wird (vgl. Art. 3 Ziffer 12 AIA).
<br/>Die einzelnen Akteure
<br/>Je nachdem, um welchen Akteur und welches KI-System oder GPAI-Modell es sich handelt, sind unterschiedlich weitreichende Verpflichtungen einzuhalten. Es ist daher von fundamentaler Bedeutung, in den einzelnen Verpflichtungsadressaten zu unterscheiden. In bestimmten Situationen kann ein Akteur auch mehrere Rollen gleichzeitig übernehmen. Die folgenden Erläuterungen und die Grafik sollen einen Überblick geben.
<br/>Die Infografik fasst den Fließtext zusammen und beschreibt die Rollen entlang der KI-Wertschöpfungskette
<br/>© RTR (CC BY 4.0)
<br/>Wer ist Anbieter?
<br/>Laut Art. 3 Ziffer 3 AIA ist ein Anbieter
<br/>eine natürliche oder juristische Person, Behörde, Einrichtung oder sonstige Stelle, die ein KI-System oder ein KI-Modell mit allgemeinem Verwendungszweck entwickelt oder entwickeln lässt und es unter ihrem eigenen Namen oder ihrer Handelsmarke in Verkehr bringt oder das KI-System unter ihrem eigenen Namen oder ihrer Handelsmarke in Betrieb nimmt, sei es entgeltlich oder unentgeltlich.
<br/>Beim Anbieter handelt es sich um jenes Glied in der KI-Wertschöpfungskette, das das KI-System oder GPAI-Modell entwickelt. Typischerweise handelt es sich dabei um Personen und Einrichtungen, die in den einzelnen Entwicklungsphasen – Datenvorbereitung, Modelltraining, Evaluierung und Optimierung – von KI-Systemen oder GPAI-Modellen beteiligt sind.
<br/>Da die Entwicklung eines KI-Systems oder GPAI-Modells meist mehrere Berufsdisziplinen umfasst, arbeiten oft mehrere Fachleute wie Datenwissenschaftler, Ingenieure, Domänenexperten und Designer zusammen. Von einem Anbieter wird daher auch dann ausgegangen, wenn diese das KI-System oder ein GPAI-Modell entwickeln lässt (mit anderen Worten „in Auftrag gibt“), um es in der Folge selbst in den Verkehr zu bringen oder das System unter dem eigenen Namen oder ihrer eigenen Marke – entgeltlich oder unentgeltlich in Betrieb zu nehmen. Anbieter können auch bestimmte Instrumente, Dienstleistungen, Komponenten oder Prozesse, wie z.B. Trainieren, Neutrainieren, Testen und Bewerten von Modellen, die Integration in Software oder andere Aspekte der Modellentwicklung auslagern. Die Verpflichtungen im Zusammenhang mit dem AI Act treffen allerdings weitergehend die Anbieter.
<br/>Hinweis: Um die Anwendung des AI Act auch in diesen Situationen sicherzustellen, gilt es die Pflichten vertraglich zu regeln. Das AI Office wird diesbezüglich ermächtigt, Mustervertragsbestimmungen zu erstellen und zur Verfügung zu stellen (Art. 25 Abs. 4 AI Act).
<br/>Von einem Anbieter ist auch dann die Rede, wenn diese ein KI-Modell in ihr KI-System oder GPAI-System integriert. Irrelevant ist dabei, ob das Modell von ihm selbst bereitgestellt und vertikal integriert wird oder von jemand anderem stammt. In diesem Fall wird von einem „nachgelagerten Anbieter“ gesprochen (siehe Art. 3 Ziffer 68 AIA)
<br/>Durch die Regel in Art. 25 Abs. 1 AIA werden auch Einführer, Händler, Betreiber und sonstige Dritte als Anbieter behandelt, wenn sie:
<br/>ein bereits in Verkehr gebrachtes oder in Betrieb genommenes Hochrisiko-KI-System mit ihrem Namen oder ihrer Handelsmarke versehen, unbeschadet vertraglicher Vereinbarungen, die eine andere Aufteilung der Pflichten vorsieht. Der jeweilige Akteur tritt somit als Anbieter eines KI-Systems auf obwohl dieses nicht selbst entwickelt wurde („Quasi-Hersteller“);
<br/>eine wesentliche Änderung an einem Hochrisiko-KI-System, das bereits in Verkehr gebracht oder in Betrieb genommen wurde, so vornehmen, dass es weiterhin ein Hochrisiko-KI-System im Sinne von Art. 6 AIA bleibt;
<br/>die Zweckbestimmung eines KI-Systems, einschließlich eines GPAI-Systems, das nicht als hochriskant eingestuft wurde und bereits in Verkehr gebracht oder in Betrieb genommen wurde, so verändern, dass das betreffende KI-System zu einem Hochrisiko-KI-System im Sinne von Art. 6 AIA wird.
<br/>Wer ist Produkthersteller?
<br/>Produkthersteller werden zwar als Akteure aufgezählt, eine entsprechende Definition fehlt allerdings im AI Act. Da im Anhang I des AI Acts auf unionsrechtliche Normen des Produktrechts verwiesen wird, ist als Produkthersteller im AI Act der Hersteller des jeweiligen Produkts gemeint.
<br/>Beispielshaft wird als Hersteller im Sinne der Aufzüge-Richtlinie „jede natürliche oder juristische Person, die ein Sicherheitsbauteil für Aufzüge herstellt bzw. entwickeln oder herstellen lässt und es unter ihrem eigenen Namen oder ihrer eigenen Handelsmarke vermarktet“ (Art. 2 Ziffer 8 Aufzüge-Richtlinie).
<br/>Wird ein KI-System als Sicherheitskomponente in ein Produkt eingebaut, hat der Produkthersteller die im AI Act festgelegten Pflichten eines Anbieters eines KI-Systems zu erfüllen. Der Produkthersteller wird in diesen Fällen als Anbieter behandelt.
<br/>
<br/>Wer ist Bevollmächtigter?
<br/>Gemäß Art. 3 Z 5 AIA ist ein Bevollmächtigter
<br/>eine in der Union befindliche oder niedergelassene natürliche oder juristische Person, die vom Anbieter eines KI-Systems oder eines KI-Modells mit allgemeinem Verwendungszweck schriftlich dazu bevollmächtigt wurde und sich damit einverstanden erklärt hat, in seinem Namen die in dieser Verordnung festgelegten Pflichten zu erfüllen bzw. Verfahren durchzuführen.
<br/>Ein Bevollmächtigter wird notwendig, wenn die Anbieter des KI-Systems bzw. des GPAI-Modells nicht innerhalb der Union niedergelassen ist. Damit die Einhaltung der unionsrechtlichen Anforderungen an KI-Systeme bzw. GPAI-Modelle sichergestellt wird, ist die Bestellung eines Bevollmächtigten vorgesehen, der im Namen der Anbieter des KI-Systems bzw. des GPAI-Modells für die Einhaltung der im AI Act festgelegten Pflichten sorgt und auch Verfahren führt. Diese Verpflichtung gilt nicht für Anbieter von ausgenommenen Open-Source-Modellen und -Systemen im Sinne des Art. 2 Abs. 12 AIA.
<br/>Wer ist Einführer?
<br/>Art 3 Z 6 AIA definiert einen Einführer als
<br/>eine in der Union befindliche oder niedergelassene natürliche oder juristische Person, die ein KI-System, das den Namen oder die Handelsmarke einer in einem Drittland niedergelassenen natürlichen oder juristischen Person trägt, in der Union in Verkehr bringt.
<br/>Der Einführer, auch als Importeur bezeichnet, stellt jenes Glied in der KI-Wertschöpfungskette dar, das ein KI-System eines ausländischen Anbieters in der Union in Verkehr bringt. Der Importeur spielt also nur eine Rolle bei KI-Systemen aus Drittländern. In gewissen Situationen kann die Rolle des Einführers mit jener des Händlers zusammenfallen, und zwar dann, wenn der Einführer das KI-System vom Anbieter bezieht und gleichzeitig bereitstellt.
<br/>Unter Umständen kann der Einführer auch als Anbieter behandelt werden (siehe Art. 25 Abs. 1 AIA).
<br/>
<br/>Wer ist Händler?
<br/>Gemäß Art 3 Z 7 AIA wird ein Händler wie folgt legaldefiniert:
<br/>Eine natürliche oder juristische Person in der Lieferkette, die ein KI-System auf dem Unionsmarkt bereitstellt, mit Ausnahme des Anbieters oder des Einführers.
<br/>Beim Händler handelt es sich um jene Person in der KI-Wertschöpfungskette, die ein KI-System auf dem Unionsmarkt bereitstellt. Die reine Bereitstellung kommt in zeitlicher Hinsicht nach dem Inverkehrbringen.
<br/>Unter Umständen kann der Händler auch als Anbieter behandelt werden (siehe Art. 25 Abs. 1 AIA).
<br/>
<br/>Wer ist Betreiber?
<br/>Gemäß Art. 3 Ziffer 4 AIA ist ein Betreiber
<br/>eine natürliche oder juristische Person, Behörde, Einrichtung oder sonstige Stelle, die ein KI-System in eigener Verantwortung verwendet, es sei denn, das KI-System wird im Rahmen einer persönlichen und nicht beruflichen Tätigkeit verwendet.
<br/>Als Betreiber wird jenes Glied in der KI-Wertschöpfungskette bezeichnet, das ein KI-System in eigener Verantwortung verwendet. Beispielhaft werden die Organe, Einrichtungen und sonstigen Stellen der Union genannt (Erwägungsgründe 23). In der KI-Wertschöpfungskette sind sie den Anbietern nachgelagert, sie führen das KI-System in der Praxis aus. Betreiber ist jene Person, Behörde, etc. die entscheidet, ob und wie ein KI-System eingesetzt wird und trägt dafür auch die Verantwortung. Ausgenommen ist vom Betreiber-Begriff die rein private Nutzung von KI-Systemen.
<br/>Unter Umständen kann der Betreiber auch als Anbieter behandelt werden (siehe Art. 25 Abs. 1 AIA).
<br/>
<br/>Wer ist Nutzer?
<br/>Der Begriff „Nutzer“ kommt im AI Act zwar vor, wird aber nicht legaldefiniert. Der Begriff Nutzer wird an verschiedenen Stellten des AI Act genannt, z. B. im Anhang XIII zu finden als „Endnutzer“ und „gewerblicher Nutzer“ oder in verschiedenen Erwägungsgründen (siehe Erwägungsgründe 16: „um es den Nutzern zu ermöglichen“; Erwägungsgründe 102: „Software und Daten, einschließlich Modellen […] die Nutzer kostenlos abrufen, nutzen, verändern und weiter verteilen können“, „wenn sie es den Nutzern ermöglicht“). In der vom Parlament abgestimmten Fassung wurde dieser Begriff teilweise mit dem Betreiber gleichgestellt.
<br/>
<br/> „Betroffene“ Personen
<br/>Je nach Art des KI-Systems kann sich dessen Verwendung auf andere Personen als den Betreiber auswirken (Erwägungsgründe 13 AIA). Damit sind jene Personen gemeint, die Gegenstand des Einsatzes des KI-Systems sind oder in anderweitiger Weise von der Nutzung eines KI-Systems tangiert werden.
<br/>Beispiele hierfür sind auch im AI Act zu finden, wie z. B. die Nutzung eines Chatbot oder die Herstellung künstlicher Audio-, Bild-, Video- oder Textinhalte wie Deepfakes (siehe Art. 50 Abs. 1 und 2 AIA), die Nutzung eines Emotionserkennungssystems oder eines Systems zur biometrischen Kategorisierung (siehe Art. 50 Abs. 3 AIA), die Verwendung eines biometrischen Echtzeit-Fernidentifizierungssystems (Art. 5 Abs. 2 AIA) oder die Inbetriebnahme oder Verwendung eines Hochrisiko-KI-Systems am Arbeitsplatz (Art. 26 Abs. 7 AIA).
<br/>
<br/><br/>
-----
<br/><br/>
Quelle: Betreiberverpflichtungen für Systeme mit begrenztem Risiko\n\n
KI-Systeme mit „begrenztem“ Risiko:<br/>
In Art 50 AIA werden bestimmte KI-Systeme aufgelistet, welche ein begrenztes Risiko bergen, da das Risiko mittels bestimmter Transparenzpflichten minimiert werden kann. Die Betreiber treffen bei folgenden KI-Systemen folgende Transparenzpflichten:
<br/>
Emotionserkennungssysteme oder KI-Systeme zur biometrischen Kategorisierung
<br/>
Unberührt von anderen Transparenzpflichten, welche aus dem Unionsrecht oder dem nationalen Recht resultieren, sind betroffene Personen über den Betrieb eines Emotionserkennungssystems oder eines KI-Systems zur biometrischen Kategorisierung zu informieren (siehe Art. 50 Abs. 3 AIA). Personenbezogene Daten dürfen nur im Einklang mit den Datenschutzbestimmungen verarbeitet werden. Ausgenommen sind zugelassene KI-Systeme, zur Aufdeckung, Verhütung und Ermittlung von Straftaten, sofern geeignete Schutzvorkehrungen für die Rechte und Freiheiten Dritter bestehen.
<br/>
Die Information ist spätestens zum Zeitpunkt der ersten Interaktion oder Aussetzung in klarer und eindeutiger Weise bereitzustellen und müssen den geltenden Barrierefreiheitsanforderungen entsprechen (siehe Art. 50 Abs. 5 AIA).
<br/>
KI-Systeme, die Text-, Bild-, Ton- oder Videoinhalte erzeugen oder manipulieren:
<br/>
Unberührt von anderen unionsrechtlichen oder nationalen Transparenzpflichten, müssen Betreiber eines KI-Systems, das Text-, Bild-, Ton- oder Videoinhalte erzeugt oder manipuliert, die ein Deep-Fake sind, gemäß Art. 50 Abs. 4 AIA offenlegen, dass die Inhalte künstlich erzeugt oder manipuliert wurden. Ausgenommen ist die Verwendung zur Aufdeckung, Verhütung, Ermittlung und Verfolgung von Straftaten.
<br/>
Ein „Deep Fake“ im Sinne des AI Acts ist ein durch ein KI erzeugter oder manipulierter Bild-, Ton- oder Videoinhalt, der wirklichen Personen, Gegenständen, Orten, Einrichtungen oder Ereignissen ähnelt und einer Person fälschlicherweise als echt oder wahrheitsgemäß erscheinen würde (siehe Art. 3 Ziffer 60 AIA).
<br/>
Ist offensichtlich, dass der künstlich erzeugte oder manipulierte Bild-, Ton- oder Videoinhalt Teil eines künstlerischen, kreativen, satirischen, fiktionalen oder analogen Werks oder Programms ist, beschränkt sich die Transparenzpflicht darauf, das Vorhandensein von künstlich erzeugten und manipulierten Inhalten derart offenzulegen, dass die Darstellung oder der Genuss des Werkes nicht beeinträchtigt wird.
<br/>
Bei erzeugten und manipulierten Texten gelten die Transparenzpflichten nicht, wenn dieser Text von einem Menschen überprüft wurde und es einen redaktionellen Verantwortlichen gibt.
<br/>
Die Information ist spätestens zum Zeitpunkt der ersten Interaktion oder Aussetzung in klarer und eindeutiger Weise bereitzustellen und müssen den geltenden Barrierefreiheitsanforderungen entsprechen (siehe Art. 50 Abs. 5 AIA).\n\n<br/><br/>
` + `Sie führen Quellen als Endnote an, Quellen werden mit Nummer referenziert, in der Form [1].`,
    answer: "Bei einem KI-System, das Textinhalte erzeugt oder manipuliert, handelt es sich um KI-Systeme mit „begrenztem Risiko“ [1] [4] und als Betreiber von solchen KI-Systemen unterliegen Sie grundsätzlich der Offenlegungspflicht, dass der Text von einem KI-System erzeugt oder manipuliert wurde [4][6].\n\n" +
      "Ausnahmen davon gelten in folgenden Fällen: \n" +
      "* Das KI-System wird nur privat eingesetzt [2][5] \n" +
      "* Es handelt sich um keine Texte, die veröffentlicht werden, um die Öffentlichkeit über Angelegenheiten von öffentlichem Interesse zu informieren [1] [3] [6]\n " +
      "* Es gibt ein Verfahren der menschlichen Überprüfung oder der Text wird einer redaktionellen Kontrolle unterzogen und es gibt eine natürliche oder juristische Person, die die redaktionelle Verantwortung für die Veröffentlichung der Inhalte trägt [1][3][6]\n " +
      "Bei der Beantwortung von E-Mails handelt es sich regelmäßig um keine Texte, die veröffentlicht werden, um die Öffentlichkeit über Angelegenheiten von öffentlichem Interesse zu informieren. Es ist allerdings empfehlenswert, einen allgemeinen Hinweis oder eine kleine Fußnote hinzuzufügen, wie etwa: \"Dieses E-Mail wurde von einer KI verfasst.\" Dies stellt Transparenz sicher und lässt dem Empfänger die Möglichkeit, nachvollziehen zu können, wie die Antwort generiert wurde. Offene und ehrliche Kommunikation fördert Vertrauen.\n " +
      "[1] Art 50 AIA; [2] Art 3 Z 4 AIA; [3] ErwGr 134; [4] Risikostufen KI-Systeme; [5] Akteure; [6] Betreiberverpflichtungen"
}
